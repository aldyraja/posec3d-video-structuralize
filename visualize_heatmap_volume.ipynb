{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "speaking-algebra",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import os.path as osp\n",
    "import decord\n",
    "import copy as cp\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "import urllib\n",
    "import moviepy.editor as mpy\n",
    "# import random as rd\n",
    "\n",
    "# from mmpose.apis import vis_pose_result\n",
    "# from mmpose.models import TopDown\n",
    "# from mmpose.models.pose_estimators import TopdownPoseEstimator as TopDown\n",
    "\n",
    "from mmengine import load #, dump\n",
    "\n",
    "from mmaction.datasets import (CenterCrop,\n",
    "                               GeneratePoseTarget,\n",
    "                               PoseCompact, PoseDecode,\n",
    "                               Resize)\n",
    "\n",
    "# We assume the annotation is already prepared\n",
    "gym_ann_file = '../data/gym/gym_hrnet.pkl'  # https://download.openmmlab.com/mmaction/pyskl/data/gym/gym_hrnet.pkl\n",
    "ntu60_ann_file = '../data/nturgbd/ntu60_hrnet.pkl'  # https://download.openmmlab.com/mmaction/pyskl/data/nturgbd/ntu60_hrnet.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "alive-consolidation",
   "metadata": {},
   "outputs": [],
   "source": [
    "FONTFACE = cv2.FONT_HERSHEY_DUPLEX\n",
    "FONTSCALE = 0.6\n",
    "FONTCOLOR = (255, 255, 255)\n",
    "BGBLUE = (0, 119, 182)\n",
    "THICKNESS = 1\n",
    "LINETYPE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ranging-conjunction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def vis_pose_result(frame,\n",
    "#                     result,\n",
    "#                     skeleton,\n",
    "#                     kpt_score_thr=0.3,\n",
    "#                     pose_kpt_color=None,\n",
    "#                     pose_limb_color=None,\n",
    "#                     radius=4,\n",
    "#                     thickness=1):\n",
    "#     pose_result = []\n",
    "#     for res in result:\n",
    "#         pose_result.append(res['keypoints'])\n",
    "#     img_h, img_w, _ = frame.shape\n",
    "\n",
    "#     for kpts in pose_result:\n",
    "#         # draw each point on image\n",
    "#         if pose_kpt_color is not None:\n",
    "#             assert len(pose_kpt_color) == len(kpts)\n",
    "#             for kid, kpt in enumerate(kpts):\n",
    "#                 x_coord, y_coord, kpt_score = int(kpt[0]), int(kpt[1]), kpt[2]\n",
    "#                 if kpt_score > kpt_score_thr:\n",
    "#                     r, g, b = pose_kpt_color[kid]\n",
    "#                     cv2.circle(frame, (int(x_coord), int(y_coord)), radius,\n",
    "#                                (int(r), int(g), int(b)), -1)\n",
    "\n",
    "#         # draw limbs\n",
    "#         if skeleton is not None and pose_limb_color is not None:\n",
    "#             assert len(pose_limb_color) == len(skeleton)\n",
    "#             for sk_id, sk in enumerate(skeleton):\n",
    "#                 pos1 = (int(kpts[sk[0] - 1, 0]), int(kpts[sk[0] - 1, 1]))\n",
    "#                 pos2 = (int(kpts[sk[1] - 1, 0]), int(kpts[sk[1] - 1, 1]))\n",
    "#                 if (pos1[0] > 0 and pos1[0] < img_w and pos1[1] > 0\n",
    "#                         and pos1[1] < img_h and pos2[0] > 0 and pos2[0] < img_w\n",
    "#                         and pos2[1] > 0 and pos2[1] < img_h\n",
    "#                         and kpts[sk[0] - 1, 2] > kpt_score_thr\n",
    "#                         and kpts[sk[1] - 1, 2] > kpt_score_thr):\n",
    "#                     r, g, b = pose_limb_color[sk_id]\n",
    "#                     cv2.line(\n",
    "#                         frame,\n",
    "#                         pos1,\n",
    "#                         pos2, (int(r), int(g), int(b)),\n",
    "#                         thickness=thickness)\n",
    "\n",
    "\n",
    "def add_label(frame, label, BGCOLOR=BGBLUE):\n",
    "    threshold = 30\n",
    "    def split_label(label):\n",
    "        label = label.split()\n",
    "        lines, cline = [], ''\n",
    "        for word in label:\n",
    "            if len(cline) + len(word) < threshold:\n",
    "                cline = cline + ' ' + word\n",
    "            else:\n",
    "                lines.append(cline)\n",
    "                cline = word\n",
    "        if cline != '':\n",
    "            lines += [cline]\n",
    "        return lines\n",
    "    \n",
    "    if len(label) > 30:\n",
    "        label = split_label(label)\n",
    "    else:\n",
    "        label = [label]\n",
    "    label = ['Action: '] + label\n",
    "    \n",
    "    sizes = []\n",
    "    for line in label:\n",
    "        sizes.append(cv2.getTextSize(line, FONTFACE, FONTSCALE, THICKNESS)[0])\n",
    "    box_width = max([x[0] for x in sizes]) + 10\n",
    "    text_height = sizes[0][1]\n",
    "    box_height = len(sizes) * (text_height + 6)\n",
    "    \n",
    "    cv2.rectangle(frame, (0, 0), (box_width, box_height), BGCOLOR, -1)\n",
    "    for i, line in enumerate(label):\n",
    "        location = (5, (text_height + 6) * i + text_height + 3)\n",
    "        cv2.putText(frame, line, location, FONTFACE, FONTSCALE, FONTCOLOR, THICKNESS, LINETYPE)\n",
    "    return frame\n",
    "    \n",
    "\n",
    "# def vis_skeleton(vid_path, anno, category_name=None, ratio=0.5):\n",
    "#     vid = decord.VideoReader(vid_path)\n",
    "#     frames = [x.asnumpy() for x in vid]\n",
    "    \n",
    "#     h, w, _ = frames[0].shape\n",
    "#     new_shape = (int(w * ratio), int(h * ratio))\n",
    "#     frames = [cv2.resize(f, new_shape) for f in frames]\n",
    "    \n",
    "#     assert len(frames) == anno['total_frames']\n",
    "#     # The shape is N x T x K x 3\n",
    "#     kps = np.concatenate([anno['keypoint'], anno['keypoint_score'][..., None]], axis=-1)\n",
    "#     kps[..., :2] *= ratio\n",
    "#     # Convert to T x N x K x 3\n",
    "#     kps = kps.transpose([1, 0, 2, 3])\n",
    "#     vis_frames = []\n",
    "\n",
    "#     # we need an instance of TopDown model, so build a minimal one\n",
    "#     model = TopDown(backbone=dict(type='ShuffleNetV1'))\n",
    "\n",
    "#     for f, kp in zip(frames, kps):\n",
    "#         bbox = np.zeros([0, 4], dtype=np.float32)\n",
    "#         result = [dict(bbox=bbox, keypoints=k) for k in kp]\n",
    "#         vis_frame = vis_pose_result(model, f, result)\n",
    "        \n",
    "#         if category_name is not None:\n",
    "#             vis_frame = add_label(vis_frame, category_name)\n",
    "        \n",
    "#         vis_frames.append(vis_frame)\n",
    "#     return vis_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "applied-humanity",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoint_pipeline = [\n",
    "    dict(type=PoseDecode),\n",
    "    dict(type=PoseCompact, hw_ratio=1., allow_imgpad=True),\n",
    "    dict(type=Resize, scale=(-1, 64)),\n",
    "    dict(type=CenterCrop, crop_size=64),\n",
    "    dict(type=GeneratePoseTarget, sigma=0.6, use_score=True, with_kp=True, with_limb=False)\n",
    "]\n",
    "\n",
    "limb_pipeline = [\n",
    "    dict(type=PoseDecode),\n",
    "    dict(type=PoseCompact, hw_ratio=1., allow_imgpad=True),\n",
    "    dict(type=Resize, scale=(-1, 64)),\n",
    "    dict(type=CenterCrop, crop_size=64),\n",
    "    dict(type=GeneratePoseTarget, sigma=0.6, use_score=True, with_kp=False, with_limb=True)\n",
    "]\n",
    "\n",
    "from mmengine.dataset import Compose\n",
    "def get_pseudo_heatmap(anno, flag='keypoint'):  # maybe related to class GeneratePoseTarget: def generate_a_heatmap()\n",
    "    assert flag in ['keypoint', 'limb']\n",
    "    pipeline = Compose(keypoint_pipeline if flag == 'keypoint' else limb_pipeline)\n",
    "    return pipeline(anno)['imgs']\n",
    "\n",
    "def vis_heatmaps(heatmaps, channel=-1, ratio=8):\n",
    "    import matplotlib.cm as cm\n",
    "    \n",
    "    if ( 0 <= channel <= heatmaps.shape[1]-1 ):\n",
    "        heatmaps = [heatmaps[x][channel] for x in range(heatmaps.shape[0])]\n",
    "    else:  # draw all keypoints / limbs on the same map\n",
    "        heatmaps = [np.max(x, axis=0) for x in heatmaps]\n",
    "    \n",
    "    h, w = heatmaps[0].shape    \n",
    "    newh, neww = int(h * ratio), int(w * ratio)\n",
    "    \n",
    "    cmap = cm.viridis\n",
    "    heatmaps = [(cmap(x)[..., :3] * 255).astype(np.uint8) for x in heatmaps]\n",
    "\n",
    "    heatmaps = [cv2.resize(x, (neww, newh)) for x in heatmaps]\n",
    "    return heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0493fa82-873a-4fec-8acc-85e96fb14a5f",
   "metadata": {},
   "source": [
    "## GYM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-commons",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GYM annotations\n",
    "lines = list(urllib.request.urlopen('https://sdolivia.github.io/FineGym/resources/dataset/gym99_categories.txt'))\n",
    "gym_categories = [x.decode().strip().split('; ')[-1] for x in lines]\n",
    "gym_annos = load(gym_ann_file)['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-bristol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download sample videos of GYM\n",
    "!wget https://download.openmmlab.com/mmaction/posec3d/gym_samples.tar\n",
    "!tar -xf gym_samples.tar\n",
    "!rm gym_samples.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-harrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "gym_root = 'gym_samples/'\n",
    "gym_vids = os.listdir(gym_root)\n",
    "# visualize pose of which video? index in 0 - 50.\n",
    "idx = 1\n",
    "vid = gym_vids[idx]\n",
    "\n",
    "frame_dir = vid.split('.')[0]\n",
    "vid_path = osp.join(gym_root, vid)\n",
    "anno = [x for x in gym_annos if x['frame_dir'] == frame_dir][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79899ee9-216f-479e-9743-e3893dc0d94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-courage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Skeleton\n",
    "# vis_frames = vis_skeleton(vid_path, anno, gym_categories[anno['label']])\n",
    "# vid = mpy.ImageSequenceClip(vis_frames, fps=24)\n",
    "# vid.ipython_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-logging",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoint_heatmap = get_pseudo_heatmap(anno)\n",
    "keypoint_mapvis = vis_heatmaps(keypoint_heatmap)\n",
    "keypoint_mapvis = [add_label(f, gym_categories[anno['label']]) for f in keypoint_mapvis]\n",
    "vid = mpy.ImageSequenceClip(keypoint_mapvis, fps=24)\n",
    "vid.ipython_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-conjunction",
   "metadata": {},
   "outputs": [],
   "source": [
    "limb_heatmap = get_pseudo_heatmap(anno, 'limb')\n",
    "limb_mapvis = vis_heatmaps(limb_heatmap)\n",
    "limb_mapvis = [add_label(f, gym_categories[anno['label']]) for f in limb_mapvis]\n",
    "vid = mpy.ImageSequenceClip(limb_mapvis, fps=24)\n",
    "vid.ipython_display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e2c030-8d27-428d-a333-6b5fe36f7a5f",
   "metadata": {},
   "source": [
    "## NTU60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coupled-stranger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The name list of \n",
    "ntu_categories = ['drink water', 'eat meal/snack', 'brushing teeth', 'brushing hair', 'drop', 'pickup', \n",
    "                  'throw', 'sitting down', 'standing up (from sitting position)', 'clapping', 'reading', \n",
    "                  'writing', 'tear up paper', 'wear jacket', 'take off jacket', 'wear a shoe', \n",
    "                  'take off a shoe', 'wear on glasses', 'take off glasses', 'put on a hat/cap', \n",
    "                  'take off a hat/cap', 'cheer up', 'hand waving', 'kicking something', \n",
    "                  'reach into pocket', 'hopping (one foot jumping)', 'jump up', \n",
    "                  'make a phone call/answer phone', 'playing with phone/tablet', 'typing on a keyboard', \n",
    "                  'pointing to something with finger', 'taking a selfie', 'check time (from watch)', \n",
    "                  'rub two hands together', 'nod head/bow', 'shake head', 'wipe face', 'salute', \n",
    "                  'put the palms together', 'cross hands in front (say stop)', 'sneeze/cough', \n",
    "                  'staggering', 'falling', 'touch head (headache)', 'touch chest (stomachache/heart pain)', \n",
    "                  'touch back (backache)', 'touch neck (neckache)', 'nausea or vomiting condition', \n",
    "                  'use a fan (with hand or paper)/feeling warm', 'punching/slapping other person', \n",
    "                  'kicking other person', 'pushing other person', 'pat on back of other person', \n",
    "                  'point finger at the other person', 'hugging other person', \n",
    "                  'giving something to other person', \"touch other person's pocket\", 'handshaking', \n",
    "                  'walking towards each other', 'walking apart from each other']\n",
    "ntu_annos = load(ntu60_ann_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448fbfbf-94cc-46c5-8536-e083436c0046",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ntu_annos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download sample videos of NTU-60\n",
    "# !wget https://download.openmmlab.com/mmaction/posec3d/ntu_samples.tar\n",
    "!tar -xf ntu_samples.tar\n",
    "!rm ntu_samples.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-review",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntu_root = 'ntu_samples/'\n",
    "ntu_vids = os.listdir(ntu_root)\n",
    "# visualize pose of which video? index in 0 - 50.\n",
    "idx = 20\n",
    "vid = ntu_vids[idx]\n",
    "\n",
    "frame_dir = vid.split('.')[0]\n",
    "vid_path = osp.join(ntu_root, vid)\n",
    "anno = [x for x in ntu_annos if x['frame_dir'] == frame_dir.split('_')[0]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c136283-4924-4e09-b630-43d6d2b41d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef42063-b38e-46e3-94f5-28a8e7e5be3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-invitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis_frames = vis_skeleton(vid_path, anno, ntu_categories[anno['label']])\n",
    "# vid = mpy.ImageSequenceClip(vis_frames, fps=24)\n",
    "# vid.ipython_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-conclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoint_heatmap = get_pseudo_heatmap(anno)\n",
    "keypoint_mapvis = vis_heatmaps(keypoint_heatmap)\n",
    "keypoint_mapvis = [add_label(f, gym_categories[anno['label']]) for f in keypoint_mapvis]\n",
    "vid = mpy.ImageSequenceClip(keypoint_mapvis, fps=24)\n",
    "vid.ipython_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-vancouver",
   "metadata": {},
   "outputs": [],
   "source": [
    "limb_heatmap = get_pseudo_heatmap(anno, 'limb')\n",
    "limb_mapvis = vis_heatmaps(limb_heatmap)\n",
    "limb_mapvis = [add_label(f, gym_categories[anno['label']]) for f in limb_mapvis]\n",
    "vid = mpy.ImageSequenceClip(limb_mapvis, fps=24)\n",
    "vid.ipython_display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca84b7de-d525-4681-bacc-336d43af45a3",
   "metadata": {},
   "source": [
    "# NTU60_2D_Single_Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a074707-1855-4c0c-be3a-3ac949f331cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntu60_2d_ann_file = 'mmaction2/tools/data/skeleton/S001C001P001R001A001_rgb.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db8935b-3d4d-4dfe-99a0-6f0b51ffb79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntu_categories = ['drink water', 'eat meal/snack', 'brushing teeth', 'brushing hair', 'drop', 'pickup', \n",
    "                  'throw', 'sitting down', 'standing up (from sitting position)', 'clapping', 'reading', \n",
    "                  'writing', 'tear up paper', 'wear jacket', 'take off jacket', 'wear a shoe', \n",
    "                  'take off a shoe', 'wear on glasses', 'take off glasses', 'put on a hat/cap', \n",
    "                  'take off a hat/cap', 'cheer up', 'hand waving', 'kicking something', \n",
    "                  'reach into pocket', 'hopping (one foot jumping)', 'jump up', \n",
    "                  'make a phone call/answer phone', 'playing with phone/tablet', 'typing on a keyboard', \n",
    "                  'pointing to something with finger', 'taking a selfie', 'check time (from watch)', \n",
    "                  'rub two hands together', 'nod head/bow', 'shake head', 'wipe face', 'salute', \n",
    "                  'put the palms together', 'cross hands in front (say stop)', 'sneeze/cough', \n",
    "                  'staggering', 'falling', 'touch head (headache)', 'touch chest (stomachache/heart pain)', \n",
    "                  'touch back (backache)', 'touch neck (neckache)', 'nausea or vomiting condition', \n",
    "                  'use a fan (with hand or paper)/feeling warm', 'punching/slapping other person', \n",
    "                  'kicking other person', 'pushing other person', 'pat on back of other person', \n",
    "                  'point finger at the other person', 'hugging other person', \n",
    "                  'giving something to other person', \"touch other person's pocket\", 'handshaking', \n",
    "                  'walking towards each other', 'walking apart from each other']\n",
    "# ntu2d_annos = load(ntu60_2d_ann_file)['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1428c2f2-00a4-4ef2-9f4b-ce07a0967984",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntu2d_root = 'mmaction2/tools/data/skeleton/'\n",
    "vid = 'S001C001P001R001A001_rgb.avi'\n",
    "\n",
    "# frame_dir = vid.split('.')[0]\n",
    "vid_path = osp.join(ntu2d_root, vid)\n",
    "# anno = [x for x in ntu2d_annos if x['frame_dir'] == frame_dir.split('_')[0]][0]\n",
    "anno = load(ntu60_2d_ann_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823a78c5-1ae5-44d3-9bd6-5695cd06bf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b514b7a-37c3-4460-a68e-02719ece30fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoint_heatmap = get_pseudo_heatmap(anno)\n",
    "keypoint_mapvis = vis_heatmaps(keypoint_heatmap, channel=-1)\n",
    "keypoint_mapvis = [add_label(f, ntu_categories[anno['label']]) for f in keypoint_mapvis]\n",
    "vid = mpy.ImageSequenceClip(keypoint_mapvis, fps=24)\n",
    "\n",
    "# CHECK ndarray.shape, RESTART KERNEL if ERROR!\n",
    "print(keypoint_heatmap.shape)  # frames X kpts X width X heighs\n",
    "\n",
    "vid.write_videofile(\"S001C001P001R001A001_rgb_heatmap.mp4\", remove_temp=True)\n",
    "vid.ipython_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5788f5eb-6cca-40b0-8d8f-3de0806354d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "limb_heatmap = get_pseudo_heatmap(anno, 'limb')\n",
    "limb_mapvis = vis_heatmaps(limb_heatmap)\n",
    "limb_mapvis = [add_label(f, ntu_categories[anno['label']]) for f in limb_mapvis]\n",
    "vid = mpy.ImageSequenceClip(limb_mapvis, fps=24)\n",
    "\n",
    "# CHECK ndarray.shape, RESTART KERNEL if ERROR!\n",
    "print(limb_heatmap.shape[0])  # frames X kpts X width X heighs\n",
    "\n",
    "vid.ipython_display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf26ec3c-f82b-4861-b8b6-242524e8f30f",
   "metadata": {},
   "source": [
    "# NTU60_2D_Multi_Persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f61fc3-526a-4c50-8a2d-fbad12af5ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntu60_2d_ann_file = 'mmaction2/tools/data/skeleton/S013C002P018R001A060_rgb.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5f7b9f-c1ea-4810-90a9-1f2be6560946",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntu_categories = ['drink water', 'eat meal/snack', 'brushing teeth', 'brushing hair', 'drop', 'pickup', \n",
    "                  'throw', 'sitting down', 'standing up (from sitting position)', 'clapping', 'reading', \n",
    "                  'writing', 'tear up paper', 'wear jacket', 'take off jacket', 'wear a shoe', \n",
    "                  'take off a shoe', 'wear on glasses', 'take off glasses', 'put on a hat/cap', \n",
    "                  'take off a hat/cap', 'cheer up', 'hand waving', 'kicking something', \n",
    "                  'reach into pocket', 'hopping (one foot jumping)', 'jump up', \n",
    "                  'make a phone call/answer phone', 'playing with phone/tablet', 'typing on a keyboard', \n",
    "                  'pointing to something with finger', 'taking a selfie', 'check time (from watch)', \n",
    "                  'rub two hands together', 'nod head/bow', 'shake head', 'wipe face', 'salute', \n",
    "                  'put the palms together', 'cross hands in front (say stop)', 'sneeze/cough', \n",
    "                  'staggering', 'falling', 'touch head (headache)', 'touch chest (stomachache/heart pain)', \n",
    "                  'touch back (backache)', 'touch neck (neckache)', 'nausea or vomiting condition', \n",
    "                  'use a fan (with hand or paper)/feeling warm', 'punching/slapping other person', \n",
    "                  'kicking other person', 'pushing other person', 'pat on back of other person', \n",
    "                  'point finger at the other person', 'hugging other person', \n",
    "                  'giving something to other person', \"touch other person's pocket\", 'handshaking', \n",
    "                  'walking towards each other', 'walking apart from each other']\n",
    "# ntu2d_annos = load(ntu60_2d_ann_file)['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bea25ea-cdd1-4f52-9b55-8c473012b31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntu2d_root = '../cut'\n",
    "vid = 'DJI_0013_12r_10s_2.mp4'\n",
    "out_filename = 'data/DJI_0013_12r_10s_2_heatmap_17.MP4'\n",
    "\n",
    "# frame_dir = vid.split('.')[0]\n",
    "vid_path = osp.join(ntu2d_root, vid)\n",
    "# anno = [x for x in ntu2d_annos if x['frame_dir'] == frame_dir.split('_')[0]][0]\n",
    "anno = load(ntu60_2d_ann_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b6d8d3-750a-4e37-b1c2-c71264908141",
   "metadata": {},
   "outputs": [],
   "source": [
    "anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7e07f2-c6ac-439d-ae83-f13e26cfbb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('S013C002P018R001A060_rgb.txt','w') as data:  \n",
    "      data.write(str(anno))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e112311-703b-466b-903d-a908ff12a41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoint_heatmap = get_pseudo_heatmap(anno)\n",
    "keypoint_mapvis = vis_heatmaps(keypoint_heatmap, channel=16)\n",
    "# keypoint_mapvis = [add_label(f, ntu_categories[anno['label']]) for f in keypoint_mapvis]\n",
    "vid = mpy.ImageSequenceClip(keypoint_mapvis, fps=12)\n",
    "\n",
    "# CHECK ndarray.shape, RESTART KERNEL if ERROR!\n",
    "print(keypoint_heatmap.shape)  # frames X kpts X width X heighs\n",
    "\n",
    "vid.write_videofile(out_filename, remove_temp=True)\n",
    "# vid.ipython_display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb49dfc-6be0-4971-99eb-863c212adf11",
   "metadata": {},
   "source": [
    "# CIIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3a2065b-a5d4-4266-a1f0-e4880f275d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciis_ann_file = '../../../Downloads/k400_2d.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb38d373-c31e-4307-aa5d-430f94b575b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ciis_categories = ['berdiri', 'berjalan', 'berjongkok', 'merayap', 'melempar', 'membidik (l. panjang)', \n",
    "#                   'membidik (l. pendek)', 'memukul', 'menendang', 'menusuk']\n",
    "ciis_annos = load(ciis_ann_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dd7767-0627-47e2-8368-856cda3483dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciis_annos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc0ab0b-e41d-4c15-adc3-c47d7d5aaf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciis_annos[1000:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccc9392-596b-4a6d-9d41-3bfc402dc85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciis_annos[2000:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079a8a62-0c14-4b3a-afcd-14fa3286c5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciis_annos[3000:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2ac35a-08f5-44c6-bade-4a12f5ff9e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciis_annos[4000:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3d8775-9730-444a-9701-3f09db216826",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciis_annos[5000:6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3285d61b-ff95-4779-acaf-8a1ae7438c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciis_annos[6000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93316a0c-32cf-4cf7-8e80-6a4f8b0077ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ciis_root = 'data/video'\n",
    "# ciis_vids = os.listdir(ciis_root)\n",
    "# visualize pose of which video? index in 0 - 50.\n",
    "# idx = 0\n",
    "# vid = ciis_vids[idx]\n",
    "\n",
    "frame_dir = '30d_1s1_206.002_2'\n",
    "# vid_path = osp.join(ciis_root, vid)\n",
    "anno = [x for x in ciis_annos if x['frame_dir'] == frame_dir][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dbc3fa-e0c2-45ed-963d-80d9027d697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e342ea6-8a74-466e-b34d-7682d6e27ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoint_heatmap = get_pseudo_heatmap(anno)\n",
    "keypoint_mapvis = vis_heatmaps(keypoint_heatmap)\n",
    "keypoint_mapvis = [add_label(f, ciis_categories[anno['label']]) for f in keypoint_mapvis]\n",
    "vid = mpy.ImageSequenceClip(keypoint_mapvis, fps=24)\n",
    "vid.ipython_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b673c594-4b52-4083-820a-0bba1f83aba6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3459f0-9199-4020-9907-5d6a2c0a1168",
   "metadata": {},
   "source": [
    "# ntu60_2d.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77234bfe-ace0-4b1e-91c4-10dbf0b89f14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "load('data/skeleton/ntu60_2d.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecd6d56-a453-4afb-9e37-e4ab3723c9ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
