{
 "cells": [
  {
   "cell_type": "raw",
   "id": "bd74c732-0200-4057-9806-59383229aaf0",
   "metadata": {},
   "source": [
    "visualize_heatmap_volume.ipynb\n",
    "- last found in https://github.com/open-mmlab/mmaction2/blob/4e50a824d3abb708619978de65a30eee2daf81bd/demo/visualize_heatmap_volume.ipynb\n",
    "- deleted in https://github.com/open-mmlab/mmaction2/commit/7a9371bd54e6e47065851459f3c6dd67a0775084 (Aug 29, 2022)\n",
    "\n",
    "from mmpose.apis import vis_pose_result\n",
    "- last found in https://github.com/open-mmlab/mmpose/blob/269e2f199d59ef7d2819e61d489d0e3789d95ad9/mmpose/apis/legacy/__init__.py\n",
    "- deleted in mmpose/apis/legacy/inference.py https://github.com/open-mmlab/mmpose/commit/6be61ce0a074d050f08a877afb17d23bb7218cca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-algebra",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import mmcv\n",
    "import os.path as osp\n",
    "import decord\n",
    "import copy as cp\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "import urllib\n",
    "import moviepy.editor as mpy\n",
    "# import random as rd\n",
    "\n",
    "import warnings\n",
    "\n",
    "\n",
    "import mmengine\n",
    "import math\n",
    "\n",
    "# from mmpose.apis import vis_pose_result\n",
    "# from mmpose.models import TopDown\n",
    "# from mmpose.models.pose_estimators import TopdownPoseEstimator\n",
    "\n",
    "from mmengine import load #, dump\n",
    "\n",
    "from mmaction.datasets import (CenterCrop,\n",
    "                               GeneratePoseTarget,\n",
    "                               PoseCompact, PoseDecode,\n",
    "                               Resize)\n",
    "\n",
    "# We assume the annotation is already prepared\n",
    "gym_ann_file = '../data/gym/gym_hrnet.pkl'  # https://download.openmmlab.com/mmaction/pyskl/data/gym/gym_hrnet.pkl\n",
    "ntu60_ann_file = '../data/nturgbd/ntu60_hrnet.pkl'  # https://download.openmmlab.com/mmaction/pyskl/data/nturgbd/ntu60_hrnet.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-consolidation",
   "metadata": {},
   "outputs": [],
   "source": [
    "FONTFACE = cv2.FONT_HERSHEY_DUPLEX\n",
    "FONTSCALE = 0.6\n",
    "FONTCOLOR = (255, 255, 255)\n",
    "BGBLUE = (0, 119, 182)\n",
    "THICKNESS = 1\n",
    "LINETYPE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada8e87e-1c58-4fce-9209-7a75bbe36365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_pose_result(model,\n",
    "                    img,\n",
    "                    result,\n",
    "                    radius=4,\n",
    "                    thickness=1,\n",
    "                    kpt_score_thr=0.3,\n",
    "                    bbox_color='green',\n",
    "                    dataset='TopDownCocoDataset',\n",
    "                    dataset_info=None,\n",
    "                    show=False,\n",
    "                    out_file=None):\n",
    "    \"\"\"Visualize the detection results on the image.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The loaded detector.\n",
    "        img (str | np.ndarray): Image filename or loaded image.\n",
    "        result (list[dict]): The results to draw over `img`\n",
    "                (bbox_result, pose_result).\n",
    "        radius (int): Radius of circles.\n",
    "        thickness (int): Thickness of lines.\n",
    "        kpt_score_thr (float): The threshold to visualize the keypoints.\n",
    "        skeleton (list[tuple()]): Default None.\n",
    "        show (bool):  Whether to show the image. Default True.\n",
    "        out_file (str|None): The filename of the output visualization image.\n",
    "    \"\"\"\n",
    "\n",
    "    warnings.warn(\n",
    "        'dataset is deprecated.'\n",
    "        'Please set `dataset_info` in the config.'\n",
    "        'Check https://github.com/open-mmlab/mmpose/pull/663 for details.',\n",
    "        DeprecationWarning)\n",
    "    # TODO: These will be removed in the later versions.\n",
    "    palette = np.array([[255, 128, 0], [255, 153, 51], [255, 178, 102],\n",
    "                        [230, 230, 0], [255, 153, 255], [153, 204, 255],\n",
    "                        [255, 102, 255], [255, 51, 255], [102, 178, 255],\n",
    "                        [51, 153, 255], [255, 153, 153], [255, 102, 102],\n",
    "                        [255, 51, 51], [153, 255, 153], [102, 255, 102],\n",
    "                        [51, 255, 51], [0, 255, 0], [0, 0, 255],\n",
    "                        [255, 0, 0], [255, 255, 255]])\n",
    "\n",
    "    if dataset in ('TopDownCocoDataset', 'BottomUpCocoDataset',\n",
    "                   'TopDownOCHumanDataset', 'AnimalMacaqueDataset'):\n",
    "        # show the results\n",
    "        # skeleton = [[15, 13], [13, 11], [16, 14], [14, 12], [11, 12],\n",
    "        #             [5, 11], [6, 12], [5, 6], [5, 7], [6, 8], [7, 9],\n",
    "        #             [8, 10], [1, 2], [0, 1], [0, 2], [1, 3], [2, 4],\n",
    "        #             [3, 5], [4, 6]]\n",
    "        # skeleton = [[16, 14], [14, 12], [17, 15], [15, 13], [12, 13],\n",
    "        #             [6, 12], [7, 13], [6, 7], [6, 8], [7, 9], [8, 10],\n",
    "        #             [9, 11], [2, 3], [1, 2], [1, 3], [2, 4], [3, 5],\n",
    "        #             [4, 6], [5, 7]]\n",
    "        # pose_link_color = palette[[\n",
    "        #     0, 0, 0, 0, 7, 7, 7, 9, 9, 9, 9, 9, 16, 16, 16, 16, 16, 16, 16\n",
    "        # ]]\n",
    "        # pose_kpt_color = palette[[\n",
    "        #     16, 16, 16, 16, 16, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0\n",
    "        # ]]\n",
    "        \n",
    "        skeleton = [[16, 14], [14, 12], [6, 8], [8, 10],\n",
    "                    [12, 13], [6, 12], [7, 13], [6, 7],\n",
    "                    [0, 15], [15, 13], [7, 9], [9, 11],\n",
    "                    [2, 3], [1, 2], [1, 3],\n",
    "                    [2, 4], [4, 6], [3, 5], [5, 7]\n",
    "                   ]\n",
    "        pose_link_color = palette[[\n",
    "            16, 16, 16, 16, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9\n",
    "        ]]\n",
    "        pose_kpt_color = palette[[\n",
    "            9, 9, 9, 9, 9, 16, 0, 16, 0, 16, 0, 16, 0, 16, 0, 16, 0\n",
    "        ]]\n",
    "\n",
    "    else:\n",
    "        NotImplementedError()\n",
    "\n",
    "    img = show_result(\n",
    "        img,\n",
    "        result,\n",
    "        skeleton,\n",
    "        kpt_score_thr=kpt_score_thr,\n",
    "        bbox_color=bbox_color,\n",
    "        pose_kpt_color=pose_kpt_color,\n",
    "        pose_limb_color=pose_link_color,\n",
    "        radius=radius,\n",
    "        thickness=thickness,\n",
    "        show=show,\n",
    "        out_file=out_file)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def show_result(img,\n",
    "                result,\n",
    "                skeleton=None,\n",
    "                kpt_score_thr=0.3,\n",
    "                bbox_color='green',\n",
    "                pose_kpt_color=None,\n",
    "                pose_limb_color=None,\n",
    "                radius=4,\n",
    "                text_color=(255, 0, 0),\n",
    "                thickness=1,\n",
    "                font_scale=0.5,\n",
    "                win_name='',\n",
    "                show=False,\n",
    "                wait_time=0,\n",
    "                out_file=None):\n",
    "    \"\"\"Draw `result` over `img`.\n",
    "\n",
    "    Args:\n",
    "        img (str or Tensor): The image to be displayed.\n",
    "        result (list[dict]): The results to draw over `img`\n",
    "            (bbox_result, pose_result).\n",
    "        kpt_score_thr (float, optional): Minimum score of keypoints\n",
    "            to be shown. Default: 0.3.\n",
    "        bbox_color (str or tuple or :obj:`Color`): Color of bbox lines.\n",
    "        pose_kpt_color (np.array[Nx3]`): Color of N keypoints.\n",
    "            If None, do not draw keypoints.\n",
    "        pose_limb_color (np.array[Mx3]): Color of M limbs.\n",
    "            If None, do not draw limbs.\n",
    "        text_color (str or tuple or :obj:`Color`): Color of texts.\n",
    "        thickness (int): Thickness of lines.\n",
    "        font_scale (float): Font scales of texts.\n",
    "        win_name (str): The window name.\n",
    "        wait_time (int): Value of waitKey param.\n",
    "            Default: 0.\n",
    "        out_file (str or None): The filename to write the image.\n",
    "            Default: None.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Visualized img, only if not `show` or `out_file`.\n",
    "    \"\"\"\n",
    "\n",
    "    img = mmcv.imread(img)\n",
    "    img = img.copy()\n",
    "    img_h, img_w, _ = img.shape\n",
    "\n",
    "    bbox_result = []\n",
    "    pose_result = []\n",
    "    for res in result:\n",
    "        bbox_result.append(res['bbox'])\n",
    "        pose_result.append(res['keypoints'])\n",
    "\n",
    "    if len(bbox_result) > 0:\n",
    "        bboxes = np.vstack(bbox_result)\n",
    "        # draw bounding boxes\n",
    "        mmcv.imshow_bboxes(\n",
    "            img,\n",
    "            bboxes,\n",
    "            colors=bbox_color,\n",
    "            top_k=-1,\n",
    "            thickness=thickness,\n",
    "            show=False,\n",
    "            win_name=win_name,\n",
    "            wait_time=wait_time,\n",
    "            out_file=None)\n",
    "\n",
    "        for person_id, kpts in enumerate(pose_result):\n",
    "            # draw each point on image\n",
    "            if pose_kpt_color is not None:\n",
    "                assert len(pose_kpt_color) == len(kpts), (\n",
    "                    len(pose_kpt_color), len(kpts))\n",
    "                for kid, kpt in enumerate(kpts):\n",
    "                    x_coord, y_coord, kpt_score = int(kpt[0]), int(\n",
    "                        kpt[1]), kpt[2]\n",
    "                    if kpt_score > kpt_score_thr:\n",
    "                        img_copy = img.copy()\n",
    "                        r, g, b = pose_kpt_color[kid]\n",
    "                        cv2.circle(img_copy, (int(x_coord), int(y_coord)),\n",
    "                                   radius, (int(r), int(g), int(b)), -1)\n",
    "                        transparency = max(0, min(1, kpt_score))\n",
    "                        cv2.addWeighted(\n",
    "                            img_copy,\n",
    "                            transparency,\n",
    "                            img,\n",
    "                            1 - transparency,\n",
    "                            0,\n",
    "                            dst=img)\n",
    "\n",
    "            # draw limbs\n",
    "            if skeleton is not None and pose_limb_color is not None:\n",
    "                assert len(pose_limb_color) == len(skeleton)\n",
    "                for sk_id, sk in enumerate(skeleton):\n",
    "                    pos1 = (int(kpts[sk[0] - 1, 0]), int(kpts[sk[0] - 1,\n",
    "                                                              1]))\n",
    "                    pos2 = (int(kpts[sk[1] - 1, 0]), int(kpts[sk[1] - 1,\n",
    "                                                              1]))\n",
    "                    if (0 < pos1[0] < img_w and 0 < pos1[1] < img_h\n",
    "                            and 0 < pos2[0] < img_w and 0 < pos2[1] < img_h\n",
    "                            and kpts[sk[0] - 1, 2] > kpt_score_thr\n",
    "                            and kpts[sk[1] - 1, 2] > kpt_score_thr):\n",
    "                        img_copy = img.copy()\n",
    "                        X = (pos1[0], pos2[0])\n",
    "                        Y = (pos1[1], pos2[1])\n",
    "                        mX = np.mean(X)\n",
    "                        mY = np.mean(Y)\n",
    "                        length = ((Y[0] - Y[1])**2 + (X[0] - X[1])**2)**0.5\n",
    "                        angle = math.degrees(\n",
    "                            math.atan2(Y[0] - Y[1], X[0] - X[1]))\n",
    "                        stickwidth = 2\n",
    "                        polygon = cv2.ellipse2Poly(\n",
    "                            (int(mX), int(mY)),\n",
    "                            (int(length / 2), int(stickwidth)), int(angle),\n",
    "                            0, 360, 1)\n",
    "\n",
    "                        r, g, b = pose_limb_color[sk_id]\n",
    "                        cv2.fillConvexPoly(img_copy, polygon,\n",
    "                                           (int(r), int(g), int(b)))\n",
    "                        transparency = max(\n",
    "                            0,\n",
    "                            min(\n",
    "                                1, 0.5 *\n",
    "                                (kpts[sk[0] - 1, 2] + kpts[sk[1] - 1, 2])))\n",
    "                        cv2.addWeighted(\n",
    "                            img_copy,\n",
    "                            transparency,\n",
    "                            img,\n",
    "                            1 - transparency,\n",
    "                            0,\n",
    "                            dst=img)\n",
    "\n",
    "    show, wait_time = show, 1\n",
    "    if show:\n",
    "        height, width = img.shape[:2]\n",
    "        max_ = max(height, width)\n",
    "\n",
    "        factor = min(1, 800 / max_)\n",
    "        enlarge = cv2.resize(\n",
    "            img, (0, 0),\n",
    "            fx=factor,\n",
    "            fy=factor,\n",
    "            interpolation=cv2.INTER_CUBIC)\n",
    "        mmcv.imshow(enlarge, win_name, wait_time)\n",
    "\n",
    "    if out_file is not None:\n",
    "        mmcv.imwrite(img, out_file)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-conjunction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_label(frame, label, BGCOLOR=BGBLUE):\n",
    "    threshold = 30\n",
    "    def split_label(label):\n",
    "        label = label.split()\n",
    "        lines, cline = [], ''\n",
    "        for word in label:\n",
    "            if len(cline) + len(word) < threshold:\n",
    "                cline = cline + ' ' + word\n",
    "            else:\n",
    "                lines.append(cline)\n",
    "                cline = word\n",
    "        if cline != '':\n",
    "            lines += [cline]\n",
    "        return lines\n",
    "    \n",
    "    if len(label) > 30:\n",
    "        label = split_label(label)\n",
    "    else:\n",
    "        label = [label]\n",
    "    label = ['Action: '] + label\n",
    "    \n",
    "    sizes = []\n",
    "    for line in label:\n",
    "        sizes.append(cv2.getTextSize(line, FONTFACE, FONTSCALE, THICKNESS)[0])\n",
    "    box_width = max([x[0] for x in sizes]) + 10\n",
    "    text_height = sizes[0][1]\n",
    "    box_height = len(sizes) * (text_height + 6)\n",
    "    \n",
    "    cv2.rectangle(frame, (0, 0), (box_width, box_height), BGCOLOR, -1)\n",
    "    for i, line in enumerate(label):\n",
    "        location = (5, (text_height + 6) * i + text_height + 3)\n",
    "        cv2.putText(frame, line, location, FONTFACE, FONTSCALE, FONTCOLOR, THICKNESS, LINETYPE)\n",
    "    return frame\n",
    "    \n",
    "\n",
    "def vis_skeleton(vid_path, anno, category_name=None, ratio=0.5):\n",
    "    vid = decord.VideoReader(vid_path)\n",
    "    frames = [x.asnumpy() for x in vid]\n",
    "    \n",
    "    h, w, _ = frames[0].shape\n",
    "    new_shape = (int(w * ratio), int(h * ratio))\n",
    "    frames = [cv2.resize(f, new_shape) for f in frames]\n",
    "    \n",
    "    assert len(frames) == anno['total_frames']\n",
    "    # The shape is N x T x K x 3\n",
    "    kps = np.concatenate([anno['keypoint'], anno['keypoint_score'][..., None]], axis=-1)\n",
    "    kps[..., :2] *= ratio\n",
    "    # Convert to T x N x K x 3\n",
    "    kps = kps.transpose([1, 0, 2, 3])\n",
    "    vis_frames = []\n",
    "\n",
    "    # we need an instance of TopDown model, so build a minimal one\n",
    "    # model = TopDown(backbone=dict(type='ShuffleNetV1'))\n",
    "    model = dict(\n",
    "        type='TopdownPoseEstimator',\n",
    "        _scope_='mmpose',\n",
    "        backbone=dict(type='HRNet')\n",
    "    )\n",
    "    \n",
    "    for f, kp in zip(frames, kps):\n",
    "        bbox = np.zeros([0, 4], dtype=np.float32)\n",
    "        result = [dict(bbox=bbox, keypoints=k) for k in kp]\n",
    "        vis_frame = vis_pose_result(model, f, result)\n",
    "\n",
    "        if category_name is not None:\n",
    "            vis_frame = add_label(vis_frame, category_name)\n",
    "        \n",
    "        vis_frames.append(vis_frame)\n",
    "    return vis_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-humanity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# left_kp = [1, 3, 5, 7, 9, 11, 13, 15]\n",
    "# right_kp = [2, 4, 6, 8, 10, 12, 14, 16]\n",
    "\n",
    "keypoint_pipeline = [\n",
    "    dict(type=PoseDecode),\n",
    "    dict(type=PoseCompact, hw_ratio=1., allow_imgpad=True),\n",
    "    dict(type=Resize, scale=(-1, 64)),\n",
    "    dict(type=CenterCrop, crop_size=64),\n",
    "    dict(type=GeneratePoseTarget, sigma=0.6, use_score=True, with_kp=True, with_limb=False\n",
    "         # , left_kp=left_kp, right_kp=right_kp\n",
    "        )\n",
    "]\n",
    "\n",
    "limb_pipeline = [\n",
    "    dict(type=PoseDecode),\n",
    "    dict(type=PoseCompact, hw_ratio=1., allow_imgpad=True),\n",
    "    dict(type=Resize, scale=(-1, 64)),\n",
    "    dict(type=CenterCrop, crop_size=64),\n",
    "    dict(type=GeneratePoseTarget, sigma=0.6, use_score=True, with_kp=False, with_limb=True\n",
    "         # , left_kp=left_kp, right_kp=right_kp\n",
    "        )\n",
    "]\n",
    "\n",
    "from mmengine.dataset import Compose\n",
    "def get_pseudo_heatmap(anno, flag='keypoint'):  # maybe related to class GeneratePoseTarget: def generate_a_heatmap()\n",
    "    assert flag in ['keypoint', 'limb']\n",
    "    pipeline = Compose(keypoint_pipeline if flag == 'keypoint' else limb_pipeline)\n",
    "    return pipeline(anno)['imgs']\n",
    "\n",
    "def vis_heatmaps(heatmaps, channel=-1, ratio=8):\n",
    "    import matplotlib.cm as cm\n",
    "    \n",
    "    if ( 0 <= channel <= heatmaps.shape[1]-1 ):\n",
    "        heatmaps = [heatmaps[x][channel] for x in range(heatmaps.shape[0])]\n",
    "    else:  # draw all keypoints / limbs on the same map\n",
    "        heatmaps = [np.max(x, axis=0) for x in heatmaps]\n",
    "    \n",
    "    h, w = heatmaps[0].shape    \n",
    "    newh, neww = int(h * ratio), int(w * ratio)\n",
    "    \n",
    "    cmap = cm.viridis\n",
    "    heatmaps = [(cmap(x)[..., :3] * 255).astype(np.uint8) for x in heatmaps]\n",
    "\n",
    "    heatmaps = [cv2.resize(x, (neww, newh)) for x in heatmaps]\n",
    "    return heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0493fa82-873a-4fec-8acc-85e96fb14a5f",
   "metadata": {},
   "source": [
    "## GYM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-commons",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GYM annotations\n",
    "lines = list(urllib.request.urlopen('https://sdolivia.github.io/FineGym/resources/dataset/gym99_categories.txt'))\n",
    "gym_categories = [x.decode().strip().split('; ')[-1] for x in lines]\n",
    "gym_annos = load(gym_ann_file)['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-bristol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download sample videos of GYM\n",
    "!wget https://download.openmmlab.com/mmaction/posec3d/gym_samples.tar\n",
    "!tar -xf gym_samples.tar\n",
    "!rm gym_samples.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-harrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "gym_root = 'gym_samples/'\n",
    "gym_vids = os.listdir(gym_root)\n",
    "# visualize pose of which video? index in 0 - 50.\n",
    "idx = 1\n",
    "vid = gym_vids[idx]\n",
    "\n",
    "frame_dir = vid.split('.')[0]\n",
    "vid_path = osp.join(gym_root, vid)\n",
    "anno = [x for x in gym_annos if x['frame_dir'] == frame_dir][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79899ee9-216f-479e-9743-e3893dc0d94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-courage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Skeleton\n",
    "# vis_frames = vis_skeleton(vid_path, anno, gym_categories[anno['label']])\n",
    "# vid = mpy.ImageSequenceClip(vis_frames, fps=24)\n",
    "# vid.ipython_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-logging",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoint_heatmap = get_pseudo_heatmap(anno)\n",
    "keypoint_mapvis = vis_heatmaps(keypoint_heatmap)\n",
    "keypoint_mapvis = [add_label(f, gym_categories[anno['label']]) for f in keypoint_mapvis]\n",
    "vid = mpy.ImageSequenceClip(keypoint_mapvis, fps=24)\n",
    "vid.ipython_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-conjunction",
   "metadata": {},
   "outputs": [],
   "source": [
    "limb_heatmap = get_pseudo_heatmap(anno, 'keypoint')\n",
    "limb_mapvis = vis_heatmaps(limb_heatmap)\n",
    "limb_mapvis = [add_label(f, gym_categories[anno['label']]) for f in limb_mapvis]\n",
    "vid = mpy.ImageSequenceClip(limb_mapvis, fps=24)\n",
    "vid.ipython_display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e2c030-8d27-428d-a333-6b5fe36f7a5f",
   "metadata": {},
   "source": [
    "## NTU60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coupled-stranger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The name list of \n",
    "ntu_categories = ['drink water', 'eat meal/snack', 'brushing teeth', 'brushing hair', 'drop', 'pickup', \n",
    "                  'throw', 'sitting down', 'standing up (from sitting position)', 'clapping', 'reading', \n",
    "                  'writing', 'tear up paper', 'wear jacket', 'take off jacket', 'wear a shoe', \n",
    "                  'take off a shoe', 'wear on glasses', 'take off glasses', 'put on a hat/cap', \n",
    "                  'take off a hat/cap', 'cheer up', 'hand waving', 'kicking something', \n",
    "                  'reach into pocket', 'hopping (one foot jumping)', 'jump up', \n",
    "                  'make a phone call/answer phone', 'playing with phone/tablet', 'typing on a keyboard', \n",
    "                  'pointing to something with finger', 'taking a selfie', 'check time (from watch)', \n",
    "                  'rub two hands together', 'nod head/bow', 'shake head', 'wipe face', 'salute', \n",
    "                  'put the palms together', 'cross hands in front (say stop)', 'sneeze/cough', \n",
    "                  'staggering', 'falling', 'touch head (headache)', 'touch chest (stomachache/heart pain)', \n",
    "                  'touch back (backache)', 'touch neck (neckache)', 'nausea or vomiting condition', \n",
    "                  'use a fan (with hand or paper)/feeling warm', 'punching/slapping other person', \n",
    "                  'kicking other person', 'pushing other person', 'pat on back of other person', \n",
    "                  'point finger at the other person', 'hugging other person', \n",
    "                  'giving something to other person', \"touch other person's pocket\", 'handshaking', \n",
    "                  'walking towards each other', 'walking apart from each other']\n",
    "ntu_annos = load(ntu60_ann_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448fbfbf-94cc-46c5-8536-e083436c0046",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ntu_annos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download sample videos of NTU-60\n",
    "# !wget https://download.openmmlab.com/mmaction/posec3d/ntu_samples.tar\n",
    "!tar -xf ntu_samples.tar\n",
    "!rm ntu_samples.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-review",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntu_root = 'ntu_samples/'\n",
    "ntu_vids = os.listdir(ntu_root)\n",
    "# visualize pose of which video? index in 0 - 50.\n",
    "idx = 20\n",
    "vid = ntu_vids[idx]\n",
    "\n",
    "frame_dir = vid.split('.')[0]\n",
    "vid_path = osp.join(ntu_root, vid)\n",
    "anno = [x for x in ntu_annos if x['frame_dir'] == frame_dir.split('_')[0]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c136283-4924-4e09-b630-43d6d2b41d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef42063-b38e-46e3-94f5-28a8e7e5be3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-invitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis_frames = vis_skeleton(vid_path, anno, ntu_categories[anno['label']])\n",
    "# vid = mpy.ImageSequenceClip(vis_frames, fps=24)\n",
    "# vid.ipython_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-conclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoint_heatmap = get_pseudo_heatmap(anno)\n",
    "keypoint_mapvis = vis_heatmaps(keypoint_heatmap)\n",
    "keypoint_mapvis = [add_label(f, gym_categories[anno['label']]) for f in keypoint_mapvis]\n",
    "vid = mpy.ImageSequenceClip(keypoint_mapvis, fps=24)\n",
    "vid.ipython_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-vancouver",
   "metadata": {},
   "outputs": [],
   "source": [
    "limb_heatmap = get_pseudo_heatmap(anno, 'keypoint')\n",
    "limb_mapvis = vis_heatmaps(limb_heatmap)\n",
    "limb_mapvis = [add_label(f, gym_categories[anno['label']]) for f in limb_mapvis]\n",
    "vid = mpy.ImageSequenceClip(limb_mapvis, fps=24)\n",
    "vid.ipython_display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca84b7de-d525-4681-bacc-336d43af45a3",
   "metadata": {},
   "source": [
    "# NTU60_2D_Single_Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a074707-1855-4c0c-be3a-3ac949f331cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntu60_2d_ann_file = 'mmaction2/tools/data/skeleton/S001C001P001R001A001_rgb.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db8935b-3d4d-4dfe-99a0-6f0b51ffb79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntu_categories = ['drink water', 'eat meal/snack', 'brushing teeth', 'brushing hair', 'drop', 'pickup', \n",
    "                  'throw', 'sitting down', 'standing up (from sitting position)', 'clapping', 'reading', \n",
    "                  'writing', 'tear up paper', 'wear jacket', 'take off jacket', 'wear a shoe', \n",
    "                  'take off a shoe', 'wear on glasses', 'take off glasses', 'put on a hat/cap', \n",
    "                  'take off a hat/cap', 'cheer up', 'hand waving', 'kicking something', \n",
    "                  'reach into pocket', 'hopping (one foot jumping)', 'jump up', \n",
    "                  'make a phone call/answer phone', 'playing with phone/tablet', 'typing on a keyboard', \n",
    "                  'pointing to something with finger', 'taking a selfie', 'check time (from watch)', \n",
    "                  'rub two hands together', 'nod head/bow', 'shake head', 'wipe face', 'salute', \n",
    "                  'put the palms together', 'cross hands in front (say stop)', 'sneeze/cough', \n",
    "                  'staggering', 'falling', 'touch head (headache)', 'touch chest (stomachache/heart pain)', \n",
    "                  'touch back (backache)', 'touch neck (neckache)', 'nausea or vomiting condition', \n",
    "                  'use a fan (with hand or paper)/feeling warm', 'punching/slapping other person', \n",
    "                  'kicking other person', 'pushing other person', 'pat on back of other person', \n",
    "                  'point finger at the other person', 'hugging other person', \n",
    "                  'giving something to other person', \"touch other person's pocket\", 'handshaking', \n",
    "                  'walking towards each other', 'walking apart from each other']\n",
    "# ntu2d_annos = load(ntu60_2d_ann_file)['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1428c2f2-00a4-4ef2-9f4b-ce07a0967984",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntu2d_root = 'mmaction2/tools/data/skeleton/'\n",
    "vid = 'S001C001P001R001A001_rgb.avi'\n",
    "\n",
    "# frame_dir = vid.split('.')[0]\n",
    "vid_path = osp.join(ntu2d_root, vid)\n",
    "# anno = [x for x in ntu2d_annos if x['frame_dir'] == frame_dir.split('_')[0]][0]\n",
    "anno = load(ntu60_2d_ann_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823a78c5-1ae5-44d3-9bd6-5695cd06bf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec87761e-4874-4643-9b72-ac171a3e8c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Skeleton\n",
    "vis_frames = vis_skeleton(vid_path, anno, ntu_categories[anno['label']])\n",
    "vid = mpy.ImageSequenceClip(vis_frames, fps=24)\n",
    "vid.ipython_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b514b7a-37c3-4460-a68e-02719ece30fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoint_heatmap = get_pseudo_heatmap(anno)\n",
    "keypoint_mapvis = vis_heatmaps(keypoint_heatmap, channel=-1)\n",
    "keypoint_mapvis = [add_label(f, ntu_categories[anno['label']]) for f in keypoint_mapvis]\n",
    "vid = mpy.ImageSequenceClip(keypoint_mapvis, fps=24)\n",
    "\n",
    "# CHECK ndarray.shape, RESTART KERNEL if ERROR!\n",
    "print(keypoint_heatmap.shape)  # frames X kpts X width X heighs\n",
    "\n",
    "vid.write_videofile(\"S001C001P001R001A001_rgb_heatmap.mp4\", remove_temp=True)\n",
    "vid.ipython_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5788f5eb-6cca-40b0-8d8f-3de0806354d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "limb_heatmap = get_pseudo_heatmap(anno, 'limb')\n",
    "limb_mapvis = vis_heatmaps(limb_heatmap)\n",
    "limb_mapvis = [add_label(f, ntu_categories[anno['label']]) for f in limb_mapvis]\n",
    "vid = mpy.ImageSequenceClip(limb_mapvis, fps=24)\n",
    "\n",
    "# CHECK ndarray.shape, RESTART KERNEL if ERROR!\n",
    "print(limb_heatmap.shape[0])  # frames X kpts X width X heighs\n",
    "\n",
    "vid.ipython_display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf26ec3c-f82b-4861-b8b6-242524e8f30f",
   "metadata": {},
   "source": [
    "# NTU60_2D_Multi_Persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f61fc3-526a-4c50-8a2d-fbad12af5ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ntu60_2d_ann_file = 'mmaction2/tools/data/skeleton/S013C002P018R001A060_rgb.pkl'\n",
    "ntu60_2d_ann_file = 'data/anno/DJI_0011_12r_10s_1.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5f7b9f-c1ea-4810-90a9-1f2be6560946",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntu_categories = ['drink water', 'eat meal/snack', 'brushing teeth', 'brushing hair', 'drop', 'pickup', \n",
    "                  'throw', 'sitting down', 'standing up (from sitting position)', 'clapping', 'reading', \n",
    "                  'writing', 'tear up paper', 'wear jacket', 'take off jacket', 'wear a shoe', \n",
    "                  'take off a shoe', 'wear on glasses', 'take off glasses', 'put on a hat/cap', \n",
    "                  'take off a hat/cap', 'cheer up', 'hand waving', 'kicking something', \n",
    "                  'reach into pocket', 'hopping (one foot jumping)', 'jump up', \n",
    "                  'make a phone call/answer phone', 'playing with phone/tablet', 'typing on a keyboard', \n",
    "                  'pointing to something with finger', 'taking a selfie', 'check time (from watch)', \n",
    "                  'rub two hands together', 'nod head/bow', 'shake head', 'wipe face', 'salute', \n",
    "                  'put the palms together', 'cross hands in front (say stop)', 'sneeze/cough', \n",
    "                  'staggering', 'falling', 'touch head (headache)', 'touch chest (stomachache/heart pain)', \n",
    "                  'touch back (backache)', 'touch neck (neckache)', 'nausea or vomiting condition', \n",
    "                  'use a fan (with hand or paper)/feeling warm', 'punching/slapping other person', \n",
    "                  'kicking other person', 'pushing other person', 'pat on back of other person', \n",
    "                  'point finger at the other person', 'hugging other person', \n",
    "                  'giving something to other person', \"touch other person's pocket\", 'handshaking', \n",
    "                  'walking towards each other', 'walking apart from each other']\n",
    "# ntu2d_annos = load(ntu60_2d_ann_file)['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bea25ea-cdd1-4f52-9b55-8c473012b31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntu2d_root = '../cut'\n",
    "vid = 'DJI_0011_12r_10s_1.mp4'\n",
    "out_filename = 'data/DJI_0011_12r_10s_1_heatmap_17.MP4'\n",
    "\n",
    "# frame_dir = vid.split('.')[0]\n",
    "vid_path = osp.join(ntu2d_root, vid)\n",
    "# anno = [x for x in ntu2d_annos if x['frame_dir'] == frame_dir.split('_')[0]][0]\n",
    "anno = load(ntu60_2d_ann_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b6d8d3-750a-4e37-b1c2-c71264908141",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7e07f2-c6ac-439d-ae83-f13e26cfbb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('S013C002P018R001A060_rgb.txt','w') as data:  \n",
    "#       data.write(str(anno))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62ff613-478d-4c85-9852-b40e5578b14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Skeleton\n",
    "# vis_frames = vis_skeleton(vid_path, anno[0], ntu_categories[anno[0]['label']])\n",
    "# vid = mpy.ImageSequenceClip(vis_frames, fps=24)\n",
    "# vid.ipython_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e112311-703b-466b-903d-a908ff12a41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoint_heatmap = get_pseudo_heatmap(anno[0])\n",
    "keypoint_mapvis = vis_heatmaps(keypoint_heatmap, channel=16)\n",
    "# keypoint_mapvis = [add_label(f, ntu_categories[anno['label']]) for f in keypoint_mapvis]\n",
    "vid = mpy.ImageSequenceClip(keypoint_mapvis, fps=12)\n",
    "\n",
    "# CHECK ndarray.shape, RESTART KERNEL if ERROR!\n",
    "print(keypoint_heatmap.shape)  # frames X kpts X width X heighs\n",
    "\n",
    "vid.write_videofile(out_filename, remove_temp=True)\n",
    "# vid.ipython_display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb49dfc-6be0-4971-99eb-863c212adf11",
   "metadata": {},
   "source": [
    "# CIIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a2065b-a5d4-4266-a1f0-e4880f275d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciis_ann_file = 'data/skeleton/ciis_0s7_v2.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb38d373-c31e-4307-aa5d-430f94b575b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciis_categories = ['berjalan', 'berjongkok', 'merayap', 'melempar', 'membidik (l. panjang)', \n",
    "                  'membidik (l. pendek)', 'memukul', 'menendang', 'menusuk']\n",
    "ciis_annos = load(ciis_ann_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dd7767-0627-47e2-8368-856cda3483dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ciis_annos['split']['xsub_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5341a4-148f-4a0b-89f6-f39758d52269",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ciis_annos['split']['xsub_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93316a0c-32cf-4cf7-8e80-6a4f8b0077ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciis_root = 'data/video'\n",
    "ciis_vids = os.listdir(ciis_root)\n",
    "# visualize pose of which video? index in 0 - 50.\n",
    "idx = 0\n",
    "vid = ciis_vids[idx]\n",
    "\n",
    "frame_dir = '30d_1s1_806.002_282'  # video_id frame_id.person_id data_id\n",
    "vid_path = osp.join(ciis_root, vid)\n",
    "anno = [x for x in ciis_annos['annotations'] if x['frame_dir'] == frame_dir][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e342ea6-8a74-466e-b34d-7682d6e27ba6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keypoint_heatmap = get_pseudo_heatmap(anno)\n",
    "keypoint_mapvis = vis_heatmaps(keypoint_heatmap)\n",
    "keypoint_mapvis = [add_label(f, ciis_categories[anno['label']]) for f in keypoint_mapvis]\n",
    "vid = mpy.ImageSequenceClip(keypoint_mapvis, fps=24)\n",
    "vid.ipython_display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4947018f-1099-4ac5-a585-dbe51c590c2c",
   "metadata": {},
   "source": [
    "## HITUNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1284c6bb-808f-4972-9ced-6a6bd2e9e8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mmengine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "735015e3-dd5d-42f0-a47b-af0f9c7c94e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciis_categories = ['berdiri', 'berjalan', 'berjongkok', 'merayap', 'melempar', 'membidik (l. panjang)', \n",
    "                  'membidik (l. pendek)', 'memukul', 'menendang', 'menusuk']\n",
    "\n",
    "pickles_path = 'data/train'\n",
    "combined_pkl = 'data/skeleton/ciis_0s7_v3.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f806bfea-86d5-42be-8656-ed2cd55e8c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = np.zeros((len(os.listdir(pickles_path)), len(ciis_categories)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d677eaf7-3d95-4945-b012-fffc87b06f41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50d_2s2.pkl\n",
      "70d_1s1.pkl\n",
      "50d_1s2.pkl\n",
      "50d_2s1.pkl\n",
      "70d_1s3.pkl\n",
      "70d_1s2.pkl\n",
      "30d_2s2.pkl\n",
      "30d_1s2.pkl\n",
      "30d_1s3.pkl\n",
      "50d_1s3.pkl\n",
      "30d_2s3.pkl\n",
      "50d_1s1.pkl\n",
      "30d_2s1.pkl\n",
      "30d_1s1.pkl\n"
     ]
    }
   ],
   "source": [
    "for i, file in enumerate(os.listdir(pickles_path)):\n",
    "    print(file)\n",
    "    if not file.endswith('.pkl'):\n",
    "        continue\n",
    "    dataset = mmengine.load(os.path.join(pickles_path, file))\n",
    "    for j, data in enumerate(dataset):\n",
    "        count[i][data['label']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e907d5e-4952-4c7a-8139-c2c4ead62a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = np.zeros(len(ciis_categories))\n",
    "for anno in ciis_annos['annotations']:\n",
    "    count[anno['label']] += 1\n",
    "for i, category in enumerate(ciis_categories):\n",
    "    print(category + ' = ' + str(int(count[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc0ab0b-e41d-4c15-adc3-c47d7d5aaf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciis_annos['split']['xsub_train'][3000:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9a1d74-d645-46dd-9599-8a1b7f67c752",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciis_annos['split']['xsub_val'][0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8df64e-ad18-4103-8249-0052b4f9c077",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ciis_annos['annotations'][:1000]:\n",
    "    print(i['frame_dir'] + \" => \" + str(i['label']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccc9392-596b-4a6d-9d41-3bfc402dc85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciis_annos['annotations'][2000:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079a8a62-0c14-4b3a-afcd-14fa3286c5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciis_annos['annotations'][3000:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2ac35a-08f5-44c6-bade-4a12f5ff9e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciis_annos['annotations'][4000:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3d8775-9730-444a-9701-3f09db216826",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciis_annos['annotations'][5000:6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3285d61b-ff95-4779-acaf-8a1ae7438c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciis_annos['annotations'][6000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3dbc3fa-e0c2-45ed-963d-80d9027d697e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0.,   0.,  54.,   0.,   0., 133.,  83.,   0.],\n",
       "       [ 36.,  27.,  26.,  35.,   0.,  22.,  32.,   0.,   0.,  40.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0., 145.,  48.,  58.],\n",
       "       [ 49.,  99., 124.,  48.,   0., 102.,  96.,   0.,   0.,  62.],\n",
       "       [  0.,   0.,   0.,   0.,  32.,   0.,   0.,   0.,  28.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,  70.,  27.,  41.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0., 112.,   0.,  72.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0., 142.,  52.,  83.],\n",
       "       [  0.,   0.,   0.,   0.,  47.,   0.,   0.,   0.,  77.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,  40.,   0.,   0.,   0.,  57.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,  64.,   0.,   0.,   0.,  49.,   0.],\n",
       "       [ 81.,  45., 151.,  70.,   0., 134., 126.,   0.,   0.,  39.],\n",
       "       [ 85.,  74., 163.,  84.,   0., 176., 147.,   0.,   0.,   0.],\n",
       "       [173., 107., 142., 139.,   0.,  91., 147.,   0.,   0.,  42.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3459f0-9199-4020-9907-5d6a2c0a1168",
   "metadata": {},
   "source": [
    "# Experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77234bfe-ace0-4b1e-91c4-10dbf0b89f14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ann_file = 'data/train/70d_1s1.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecd6d56-a453-4afb-9e37-e4ab3723c9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "_annos = load(_ann_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7263243e-1306-480e-8f73-2208fe906df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for anno in _annos['annotations']\n",
    "switch anno['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12b8172-3936-4ea4-a2cd-19c0f8a19fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "_annos[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298513c3-8db1-47e6-a15a-bccbb36fa167",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
