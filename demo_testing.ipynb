{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7df9318-3492-43a9-9f19-5a589a6e57f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a83e8aa-9403-42e3-ab17-07b34e1e49fa",
   "metadata": {},
   "source": [
    "## Testing recognition from bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bdfe89-b1e2-4238-940d-7586d302535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python mmaction2/demo/demo_skeleton.py data/uji_jalan.mp4 data/uji_jalan_out.mp4 \\\n",
    "    --config mmaction2/configs/skeleton/posec3d/slowonly_r50_8xb16-u48-240e_ntu60-xsub-keypoint.py \\\n",
    "    --checkpoint https://download.openmmlab.com/mmaction/skeleton/posec3d/slowonly_r50_u48_240e_ntu60_xsub_keypoint/slowonly_r50_u48_240e_ntu60_xsub_keypoint-f3adabf1.pth \\\n",
    "    --det-config mmaction2/demo/demo_configs/faster-rcnn_r50_fpn_2x_coco_infer.py \\\n",
    "    --det-checkpoint http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth \\\n",
    "    --det-score-thr 0.9 \\\n",
    "    --det-cat-id 0 \\\n",
    "    --pose-config mmaction2/demo/demo_configs/td-hm_hrnet-w32_8xb64-210e_coco-256x192_infer.py \\\n",
    "    --pose-checkpoint https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w32_coco_256x192-c78dce93_20200708.pth \\\n",
    "    --label-map mmaction2/tools/data/skeleton/label_map_ntu60.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241d889f-adf2-443f-8922-ed99ed002070",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML('<video width=50% controls autoplay loop><source src=\"data/uji_jalan.mp4\"></video>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fad1db3-acd5-4dd2-84e3-f8a7a67d5aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML('<video width=50% controls autoplay loop><source src=\"data/uji_jalan_out.mp4\"></video>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6244f32-9406-4f93-b9c6-6cdc7557dccf",
   "metadata": {},
   "source": [
    "## Testing from python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65aae07f-cdab-480b-b8ab-34882bf3dda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "import cv2\n",
    "import mmcv\n",
    "import mmengine\n",
    "import torch\n",
    "from mmengine.utils import track_iter_progress\n",
    "\n",
    "from mmaction.apis import (detection_inference, inference_skeleton,\n",
    "                           init_recognizer, pose_inference)\n",
    "from mmaction.registry import VISUALIZERS\n",
    "from mmaction.utils import frame_extract\n",
    "\n",
    "import moviepy.editor as mpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0f48c9-a98a-4742-86d8-e4bfc65dbe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FONTFACE = cv2.FONT_HERSHEY_DUPLEX\n",
    "FONTSCALE = 0.75\n",
    "FONTCOLOR = (255, 255, 255)  # BGR, white\n",
    "THICKNESS = 1\n",
    "LINETYPE = 1\n",
    "\n",
    "def visualize(pose_config, out_filename, frames, data_samples, action_label):\n",
    "    pose_config = mmengine.Config.fromfile(pose_config)\n",
    "    visualizer = VISUALIZERS.build(pose_config.visualizer)\n",
    "    visualizer.set_dataset_meta(data_samples[0].dataset_meta)\n",
    "\n",
    "    vis_frames = []\n",
    "    print('Drawing skeleton for each frame')\n",
    "    for d, f in track_iter_progress(list(zip(data_samples, frames))):\n",
    "        f = mmcv.imconvert(f, 'bgr', 'rgb')\n",
    "        visualizer.add_datasample(\n",
    "            'result',\n",
    "            f,\n",
    "            data_sample=d,\n",
    "            draw_gt=False,\n",
    "            draw_heatmap=False,\n",
    "            draw_bbox=True,\n",
    "            show=False,\n",
    "            wait_time=0,\n",
    "            out_file=None,\n",
    "            kpt_thr=0.3)\n",
    "        vis_frame = visualizer.get_image()\n",
    "        cv2.putText(vis_frame, action_label, (10, 30), FONTFACE, FONTSCALE,\n",
    "                    FONTCOLOR, THICKNESS, LINETYPE)\n",
    "        vis_frames.append(vis_frame)\n",
    "\n",
    "    vid = mpy.ImageSequenceClip(vis_frames, fps=24)\n",
    "    vid.write_videofile(out_filename, remove_temp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2361e83b-ea17-425f-be37-ff9737c1c480",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = 'data/uji_jalan.mp4'\n",
    "out_filename = 'data/uji_jalan_out.mp4'\n",
    "\n",
    "# Choose to use an action classification config\n",
    "config = 'mmaction2/configs/skeleton/posec3d/slowonly_r50_8xb16-u48-240e_ntu60-xsub-keypoint.py'\n",
    "# Setup a checkpoint file to load\n",
    "checkpoint = 'https://download.openmmlab.com/mmaction/skeleton/posec3d/slowonly_r50_u48_240e_ntu60_xsub_keypoint/slowonly_r50_u48_240e_ntu60_xsub_keypoint-f3adabf1.pth'\n",
    "\n",
    "# human detection config\n",
    "det_config = 'mmaction2/demo/demo_configs/faster-rcnn_r50_fpn_2x_coco_infer.py'\n",
    "det_checkpoint = 'http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth'\n",
    "det_score_thr = 0.9\n",
    "det_cat_id = 0\n",
    "\n",
    "# pose estimation config\n",
    "pose_config = 'mmaction2/demo/demo_configs/td-hm_hrnet-w32_8xb64-210e_coco-256x192_infer.py'\n",
    "pose_checkpoint = 'https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w32_coco_256x192-c78dce93_20200708.pth'\n",
    "label_map = 'mmaction2/tools/data/skeleton/label_map_ntu60.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4a8fb4-15d2-4877-9486-c4c365b47a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "short_side = 480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3007172d-6374-483a-8902-6781e9a7119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir = tempfile.TemporaryDirectory()\n",
    "frame_paths, frames = frame_extract(video, short_side,\n",
    "                                    tmp_dir.name)\n",
    "\n",
    "h, w, _ = frames[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce84a3f-cec2-49bc-9295-e256de6ba1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Human detection results.\n",
    "det_results, _ = detection_inference(det_config, det_checkpoint,\n",
    "                                     frame_paths, det_score_thr,\n",
    "                                     det_cat_id, device)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad15062f-e2f6-420b-8254-14f21c1607b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Pose estimation results.\n",
    "pose_results, pose_data_samples = pose_inference(pose_config,\n",
    "                                                 pose_checkpoint,\n",
    "                                                 frame_paths, det_results,\n",
    "                                                 device)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733874cf-67e2-49fd-be59-b1ff44b4303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the recognizer\n",
    "config = mmengine.Config.fromfile(config)\n",
    "# build the model from a config file and a checkpoint file\n",
    "model = init_recognizer(config, checkpoint, device)\n",
    "\n",
    "# Get Action classification results.\n",
    "result = inference_skeleton(model, pose_results, (h, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5749f941-b6f4-4161-8314-9ce8e0705872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the index of highest predicted score on result\n",
    "max_pred_index = result.pred_score.argmax().item()\n",
    "\n",
    "label_map = [x.strip() for x in open(label_map).readlines()]\n",
    "\n",
    "# set the highest predicted label as action_label\n",
    "action_label = label_map[max_pred_index]\n",
    "print(action_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f1ad4f-bbad-4bdf-8132-7e77e18044cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(pose_config, out_filename, frames, pose_data_samples, action_label)\n",
    "\n",
    "tmp_dir.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa4a081-a5a2-4a1f-9397-1348491673e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML('<video width=50% controls autoplay loop><source src=\"data/uji_jalan.mp4\"></video>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628f1dd4-5ade-4d36-8885-735f9c41acb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML('<video width=50% controls autoplay loop><source src=\"data/uji_jalan_out.mp4\"></video>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f232e4e6-c864-4e1b-b731-5572c316b614",
   "metadata": {},
   "source": [
    "##TESTING MANDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db1f70ed-737b-4612-9591-3d99766ff2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth\n",
      "Performing Human Detection for each frame\n",
      "[                                                  ] 0/297, elapsed: 0s, ETA:01/04 14:08:02 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "01/04 14:08:02 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 297/297, 3.9 task/s, elapsed: 76s, ETA:     0s\n",
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w32_coco_256x192-c78dce93_20200708.pth\n",
      "Performing Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 297/297, 14.5 task/s, elapsed: 20s, ETA:     0s\n",
      "Loads checkpoint by local backend from path: work_dirs/slowonly_r50_u48_240e_ntu120_xsub_keypoint/best_top1_acc_epoch_90_8.pth\n",
      "Traceback (most recent call last):\n",
      "  File \"mmaction2/demo/demo_skeleton.py\", line 165, in <module>\n",
      "    main()\n",
      "  File \"mmaction2/demo/demo_skeleton.py\", line 153, in main\n",
      "    result = inference_skeleton(model, pose_results, (h, w))\n",
      "  File \"/home/aldy/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmaction/apis/inference.py\", line 140, in inference_skeleton\n",
      "    test_pipeline = Compose(test_pipeline_cfg)\n",
      "  File \"/home/aldy/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/dataset/base_dataset.py\", line 38, in __init__\n",
      "    transform = TRANSFORMS.build(transform)\n",
      "  File \"/home/aldy/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/registry/registry.py\", line 570, in build\n",
      "    return self.build_func(cfg, *args, **kwargs, registry=self)\n",
      "  File \"/home/aldy/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/registry/build_functions.py\", line 100, in build_from_cfg\n",
      "    raise KeyError(\n",
      "KeyError: 'Collect is not in the mmaction::transform registry. Please check whether the value of `Collect` is correct or it was registered as expected. More details can be found at https://mmengine.readthedocs.io/en/latest/advanced_tutorials/config.html#import-the-custom-module'\n"
     ]
    }
   ],
   "source": [
    "!python mmaction2/demo/demo_skeleton.py data/uji_duduk_drone_25.mp4 data/uji_duduk_drone_25_out.mp4 \\\n",
    "    --config mmaction2/configs/skeleton/posec3d/slowonly_r50_u48_240e_ntu120_xsub_keypoint.py \\\n",
    "    --checkpoint work_dirs/slowonly_r50_u48_240e_ntu120_xsub_keypoint/best_top1_acc_epoch_90_8.pth \\\n",
    "    --det-config mmaction2/demo/demo_configs/faster-rcnn_r50_fpn_2x_coco_infer.py \\\n",
    "    --det-checkpoint http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth \\\n",
    "    --det-score-thr 0.9 \\\n",
    "    --det-cat-id 0 \\\n",
    "    --pose-config mmaction2/demo/demo_configs/td-hm_hrnet-w32_8xb64-210e_coco-256x192_infer.py \\\n",
    "    --pose-checkpoint https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w32_coco_256x192-c78dce93_20200708.pth \\\n",
    "    --label-map mmaction2/tools/data/skeleton/label_5.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d38b7ee-309c-4c34-9156-1ab51ffdac00",
   "metadata": {},
   "source": [
    "##MANIPULASI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0209fee4-5945-4519-9d69-bbda6c076184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(pose_config, out_filename, frames, data_samples, action_label):\n",
    "    pose_config = mmengine.Config.fromfile(pose_config)\n",
    "    visualizer = VISUALIZERS.build(pose_config.visualizer)\n",
    "    visualizer.set_dataset_meta(data_samples[0].dataset_meta)\n",
    "\n",
    "    vis_frames = []\n",
    "    print('Drawing skeleton for each frame')\n",
    "    for d, f in track_iter_progress(list(zip(data_samples, frames))):\n",
    "        f = mmcv.imconvert(f, 'bgr', 'rgb')\n",
    "        visualizer.add_datasample(\n",
    "            'result',\n",
    "            f,\n",
    "            data_sample=d,\n",
    "            draw_gt=False,\n",
    "            draw_heatmap=False,\n",
    "            draw_bbox=True,\n",
    "            show=False,\n",
    "            wait_time=0,\n",
    "            out_file=None,\n",
    "            kpt_thr=0.3)\n",
    "        vis_frame = visualizer.get_image()\n",
    "        cv2.putText(vis_frame, action_label, (10, 30), FONTFACE, FONTSCALE,\n",
    "                    FONTCOLOR, THICKNESS, LINETYPE)\n",
    "        vis_frames.append(vis_frame)\n",
    "\n",
    "    vid = mpy.ImageSequenceClip(vis_frames, fps=24)\n",
    "    vid.write_videofile(out_filename, remove_temp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75a9c591-0fa9-4269-b82b-c34cff2b6470",
   "metadata": {},
   "outputs": [],
   "source": [
    "FONTFACE = cv2.FONT_HERSHEY_DUPLEX\n",
    "FONTSCALE = 0.75\n",
    "FONTCOLOR = (255, 255, 255)  # BGR, white\n",
    "THICKNESS = 1\n",
    "LINETYPE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "161763e5-54b7-46d4-a7f6-c2c5bdceb362",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = 'data/30m-50_duduk_drone_bd.mp4'\n",
    "out_filename = 'data/manipulasi6.mp4'\n",
    "\n",
    "# Choose to use an action classification config\n",
    "config = 'mmaction2/configs/skeleton/posec3d/slowonly_r50_8xb16-u48-240e_ntu60-xsub-keypoint.py'\n",
    "# Setup a checkpoint file to load\n",
    "checkpoint = 'https://download.openmmlab.com/mmaction/skeleton/posec3d/slowonly_r50_u48_240e_ntu60_xsub_keypoint/slowonly_r50_u48_240e_ntu60_xsub_keypoint-f3adabf1.pth'\n",
    "\n",
    "# human detection config\n",
    "det_config = 'mmaction2/demo/demo_configs/faster-rcnn_r50_fpn_2x_coco_infer.py'\n",
    "det_checkpoint = 'http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth'\n",
    "det_score_thr = 0.9\n",
    "det_cat_id = 0\n",
    "\n",
    "# pose estimation config\n",
    "pose_config = 'mmaction2/demo/demo_configs/td-hm_hrnet-w32_8xb64-210e_coco-256x192_infer.py'\n",
    "pose_checkpoint = 'https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w32_coco_256x192-c78dce93_20200708.pth'\n",
    "label_map = 'mmaction2/tools/data/skeleton/label_map_ntu60.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "692dbfa0-773c-4630-9266-4fdbb1614887",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "short_side = 480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80a88ba2-b35a-4b5c-b4da-edafcddc6789",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir = tempfile.TemporaryDirectory()\n",
    "frame_paths, frames = frame_extract(video, short_side,\n",
    "                                    tmp_dir.name)\n",
    "\n",
    "h, w, _ = frames[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2300462-6796-4921-a04f-27c4da85f37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth\n",
      "Performing Human Detection for each frame\n",
      "[                                                  ] 0/301, elapsed: 0s, ETA:01/04 23:49:40 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "01/04 23:49:40 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 301/301, 5.0 task/s, elapsed: 60s, ETA:     0s\n"
     ]
    }
   ],
   "source": [
    "# Get Human detection results.\n",
    "det_results, _ = detection_inference(det_config, det_checkpoint,\n",
    "                                     frame_paths, det_score_thr,\n",
    "                                     det_cat_id, device)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02b40730-9de2-46b9-b547-6f1821009529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w32_coco_256x192-c78dce93_20200708.pth\n",
      "Performing Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 301/301, 15.8 task/s, elapsed: 19s, ETA:     0s\n"
     ]
    }
   ],
   "source": [
    "# Get Pose estimation results.\n",
    "pose_results, pose_data_samples = pose_inference(pose_config,\n",
    "                                                 pose_checkpoint,\n",
    "                                                 frame_paths, det_results,\n",
    "                                                 device)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f2d05f-d66c-4ee8-90bb-aa22fb5afea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5658e56b-b691-4576-ad68-da48b4f9deb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drawing skeleton for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 301/301, 343.1 task/s, elapsed: 1s, ETA:     0s\n",
      "Moviepy - Building video data/manipulasi6.mp4.\n",
      "Moviepy - Writing video data/manipulasi6.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready data/manipulasi6.mp4\n"
     ]
    }
   ],
   "source": [
    "visualize(pose_config, out_filename, frames, pose_data_samples, \"pistol\")\n",
    "\n",
    "tmp_dir.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16e67272-bce0-4b5f-bc13-eb7f27c31ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=50% controls autoplay loop><source src=\"data/manipulasi6.mp4\"></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<video width=50% controls autoplay loop><source src=\"data/manipulasi6.mp4\"></video>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ebca12-2f2e-4bcb-9e10-f23c26706fcb",
   "metadata": {},
   "source": [
    "## Testing recognition + detection from bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d541ce2f-026e-4c1e-aedf-4b41180467c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth\n",
      "Performing Human Detection for each frame\n",
      "[                                                  ] 0/300, elapsed: 0s, ETA:02/05 13:42:50 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "02/05 13:42:50 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 300/300, 5.2 task/s, elapsed: 58s, ETA:     0s\n",
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w32_coco_256x192-c78dce93_20200708.pth\n",
      "Performing Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 300/300, 15.1 task/s, elapsed: 20s, ETA:     0s\n",
      "Use skeleton-based recognition\n",
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmaction/skeleton/posec3d/posec3d_k400.pth\n",
      "Use skeleton-based SpatioTemporal Action Detection\n",
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmaction/skeleton/posec3d/posec3d_ava.pth\n",
      "Performing SpatioTemporal Action Detection for each clip\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 34/34, 0.5 task/s, elapsed: 70s, ETA:     0sMoviepy - Building video mmaction2/demo/test_stdet_recognition_output.mp4.\n",
      "Moviepy - Writing video mmaction2/demo/test_stdet_recognition_output.mp4\n",
      "\n",
      "Moviepy - Done !                                                                \n",
      "Moviepy - video ready mmaction2/demo/test_stdet_recognition_output.mp4\n"
     ]
    }
   ],
   "source": [
    "!python mmaction2/demo/demo_video_structuralize.py \\\n",
    "    --video mmaction2/demo/test_video_structuralize.mp4 \\\n",
    "    --out-filename mmaction2/demo/test_stdet_recognition_output.mp4 \\\n",
    "\\\n",
    "    --rgb-stdet-config mmaction2/configs/detection/slowonly/slowonly_kinetics400-pretrained-r101_8xb16-8x8x1-20e_ava21-rgb.py \\\n",
    "    --skeleton-stdet-checkpoint https://download.openmmlab.com/mmaction/skeleton/posec3d/posec3d_ava.pth \\\n",
    "\\\n",
    "    --det-config mmaction2/demo/demo_configs/faster-rcnn_r50_fpn_2x_coco_infer.py \\\n",
    "    --det-checkpoint http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth \\\n",
    "\\\n",
    "    --pose-config mmaction2/demo/demo_configs/td-hm_hrnet-w32_8xb64-210e_coco-256x192_infer.py \\\n",
    "    --pose-checkpoint https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w32_coco_256x192-c78dce93_20200708.pth \\\n",
    "\\\n",
    "    --skeleton-config mmaction2/configs/skeleton/posec3d/slowonly_r50_8xb16-u48-240e_ntu60-xsub-keypoint.py \\\n",
    "    --skeleton-checkpoint https://download.openmmlab.com/mmaction/skeleton/posec3d/posec3d_k400.pth \\\n",
    "\\\n",
    "    --use-skeleton-stdet \\\n",
    "    --use-skeleton-recog \\\n",
    "\\\n",
    "    --label-map-stdet mmaction2/tools/data/ava/label_map.txt \\\n",
    "    --label-map mmaction2/tools/data/kinetics/label_map_k400.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad587218-846b-4b5b-b016-083302936b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=50% controls autoplay loop><source src=\"mmaction2/demo/test_video_structuralize.mp4\"></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<video width=50% controls autoplay loop><source src=\"mmaction2/demo/test_video_structuralize.mp4\"></video>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f98e148-3cf2-46a8-a265-f8aa7c65649f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=50% controls autoplay loop><source src=\"mmaction2/demo/test_stdet_recognition_output.mp4\"></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<video width=50% controls autoplay loop><source src=\"mmaction2/demo/test_stdet_recognition_output.mp4\"></video>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a283883-e7c5-49c7-830a-9b3c0c73b1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth\n",
      "Performing Human Detection for each frame\n",
      "[                                                  ] 0/72, elapsed: 0s, ETA:02/05 13:23:35 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "02/05 13:23:35 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 72/72, 3.7 task/s, elapsed: 19s, ETA:     0s\n",
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w32_coco_256x192-c78dce93_20200708.pth\n",
      "Performing Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 72/72, 10.8 task/s, elapsed: 7s, ETA:     0s\n",
      "Use skeleton-based recognition\n",
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmaction/skeleton/posec3d/posec3d_k400.pth\n",
      "Use skeleton-based SpatioTemporal Action Detection\n",
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmaction/skeleton/posec3d/posec3d_ava.pth\n",
      "Performing SpatioTemporal Action Detection for each clip\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 6/6, 0.4 task/s, elapsed: 15s, ETA:     0sMoviepy - Building video mmaction2/demo/demo_skeleton_vs_out.mp4.\n",
      "Moviepy - Writing video mmaction2/demo/demo_skeleton_vs_out.mp4\n",
      "\n",
      "Moviepy - Done !                                                                \n",
      "Moviepy - video ready mmaction2/demo/demo_skeleton_vs_out.mp4\n"
     ]
    }
   ],
   "source": [
    "!python mmaction2/demo/demo_video_structuralize.py \\\n",
    "    --video mmaction2/demo/demo_skeleton.mp4 \\\n",
    "    --out-filename mmaction2/demo/demo_skeleton_vs_out.mp4 \\\n",
    "    --rgb-stdet-config mmaction2/configs/detection/slowonly/slowonly_kinetics400-pretrained-r101_8xb16-8x8x1-20e_ava21-rgb.py \\\n",
    "    --skeleton-stdet-checkpoint https://download.openmmlab.com/mmaction/skeleton/posec3d/posec3d_ava.pth \\\n",
    "    --det-config mmaction2/demo/demo_configs/faster-rcnn_r50_fpn_2x_coco_infer.py \\\n",
    "    --det-checkpoint http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth \\\n",
    "    --pose-config mmaction2/demo/demo_configs/td-hm_hrnet-w32_8xb64-210e_coco-256x192_infer.py \\\n",
    "    --pose-checkpoint https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w32_coco_256x192-c78dce93_20200708.pth \\\n",
    "    --skeleton-config mmaction2/configs/skeleton/posec3d/slowonly_r50_8xb16-u48-240e_ntu60-xsub-keypoint.py \\\n",
    "    --skeleton-checkpoint https://download.openmmlab.com/mmaction/skeleton/posec3d/posec3d_k400.pth \\\n",
    "    --use-skeleton-stdet \\\n",
    "    --use-skeleton-recog \\\n",
    "    --label-map-stdet mmaction2/tools/data/ava/label_map.txt \\\n",
    "    --label-map mmaction2/tools/data/kinetics/label_map_k400.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9339752f-e382-4ca7-baa8-e3f69978157b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=50% controls autoplay loop><source src=\"mmaction2/demo/demo_skeleton.mp4\"></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<video width=50% controls autoplay loop><source src=\"mmaction2/demo/demo_skeleton.mp4\"></video>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3318144-3cc6-40ff-8c40-0d3afca7b00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=50% controls autoplay loop><source src=\"mmaction2/demo/demo_skeleton_vs_out.mp4\"></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<video width=50% controls autoplay loop><source src=\"mmaction2/demo/demo_skeleton_vs_out.mp4\"></video>')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
