{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7df9318-3492-43a9-9f19-5a589a6e57f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a83e8aa-9403-42e3-ab17-07b34e1e49fa",
   "metadata": {},
   "source": [
    "## Testing from bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bdfe89-b1e2-4238-940d-7586d302535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python mmaction2/demo/demo_skeleton.py dataset/uji_jalan.mp4 dataset/uji_jalan_out.mp4 \\\n",
    "    --config mmaction2/configs/skeleton/posec3d/slowonly_r50_8xb16-u48-240e_ntu60-xsub-keypoint.py \\\n",
    "    --checkpoint https://download.openmmlab.com/mmaction/skeleton/posec3d/slowonly_r50_u48_240e_ntu60_xsub_keypoint/slowonly_r50_u48_240e_ntu60_xsub_keypoint-f3adabf1.pth \\\n",
    "    --det-config mmaction2/demo/demo_configs/faster-rcnn_r50_fpn_2x_coco_infer.py \\\n",
    "    --det-checkpoint http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth \\\n",
    "    --det-score-thr 0.9 \\\n",
    "    --det-cat-id 0 \\\n",
    "    --pose-config mmaction2/demo/demo_configs/td-hm_hrnet-w32_8xb64-210e_coco-256x192_infer.py \\\n",
    "    --pose-checkpoint https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w32_coco_256x192-c78dce93_20200708.pth \\\n",
    "    --label-map mmaction2/tools/data/skeleton/label_map_ntu60.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241d889f-adf2-443f-8922-ed99ed002070",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML('<video width=50% controls autoplay loop><source src=\"dataset/uji_jalan.mp4\"></video>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fad1db3-acd5-4dd2-84e3-f8a7a67d5aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML('<video width=50% controls autoplay loop><source src=\"dataset/uji_jalan_out.mp4\"></video>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6244f32-9406-4f93-b9c6-6cdc7557dccf",
   "metadata": {},
   "source": [
    "## Testing from python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aae07f-cdab-480b-b8ab-34882bf3dda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "import cv2\n",
    "import mmcv\n",
    "import mmengine\n",
    "import torch\n",
    "from mmengine.utils import track_iter_progress\n",
    "\n",
    "from mmaction.apis import (detection_inference, inference_skeleton,\n",
    "                           init_recognizer, pose_inference)\n",
    "from mmaction.registry import VISUALIZERS\n",
    "from mmaction.utils import frame_extract\n",
    "\n",
    "import moviepy.editor as mpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0f48c9-a98a-4742-86d8-e4bfc65dbe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FONTFACE = cv2.FONT_HERSHEY_DUPLEX\n",
    "FONTSCALE = 0.75\n",
    "FONTCOLOR = (255, 255, 255)  # BGR, white\n",
    "THICKNESS = 1\n",
    "LINETYPE = 1\n",
    "\n",
    "def visualize(pose_config, out_filename, frames, data_samples, action_label):\n",
    "    pose_config = mmengine.Config.fromfile(pose_config)\n",
    "    visualizer = VISUALIZERS.build(pose_config.visualizer)\n",
    "    visualizer.set_dataset_meta(data_samples[0].dataset_meta)\n",
    "\n",
    "    vis_frames = []\n",
    "    print('Drawing skeleton for each frame')\n",
    "    for d, f in track_iter_progress(list(zip(data_samples, frames))):\n",
    "        f = mmcv.imconvert(f, 'bgr', 'rgb')\n",
    "        visualizer.add_datasample(\n",
    "            'result',\n",
    "            f,\n",
    "            data_sample=d,\n",
    "            draw_gt=False,\n",
    "            draw_heatmap=False,\n",
    "            draw_bbox=True,\n",
    "            show=False,\n",
    "            wait_time=0,\n",
    "            out_file=None,\n",
    "            kpt_thr=0.3)\n",
    "        vis_frame = visualizer.get_image()\n",
    "        cv2.putText(vis_frame, action_label, (10, 30), FONTFACE, FONTSCALE,\n",
    "                    FONTCOLOR, THICKNESS, LINETYPE)\n",
    "        vis_frames.append(vis_frame)\n",
    "\n",
    "    vid = mpy.ImageSequenceClip(vis_frames, fps=24)\n",
    "    vid.write_videofile(out_filename, remove_temp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2361e83b-ea17-425f-be37-ff9737c1c480",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = 'dataset/uji_jalan.mp4'\n",
    "out_filename = 'dataset/uji_jalan_out.mp4'\n",
    "\n",
    "# Choose to use a config\n",
    "config = 'mmaction2/configs/skeleton/posec3d/slowonly_r50_8xb16-u48-240e_ntu60-xsub-keypoint.py'\n",
    "# Setup a checkpoint file to load\n",
    "checkpoint = 'https://download.openmmlab.com/mmaction/skeleton/posec3d/slowonly_r50_u48_240e_ntu60_xsub_keypoint/slowonly_r50_u48_240e_ntu60_xsub_keypoint-f3adabf1.pth'\n",
    "\n",
    "# human detection config\n",
    "det_config = 'mmaction2/demo/demo_configs/faster-rcnn_r50_fpn_2x_coco_infer.py'\n",
    "det_checkpoint = 'http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth'\n",
    "det_score_thr = 0.9\n",
    "det_cat_id = 0\n",
    "\n",
    "# pose estimation config\n",
    "pose_config = 'mmaction2/demo/demo_configs/td-hm_hrnet-w32_8xb64-210e_coco-256x192_infer.py'\n",
    "pose_checkpoint = 'https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w32_coco_256x192-c78dce93_20200708.pth'\n",
    "label_map = 'mmaction2/tools/data/skeleton/label_map_ntu60.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4a8fb4-15d2-4877-9486-c4c365b47a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "short_side = 480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3007172d-6374-483a-8902-6781e9a7119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir = tempfile.TemporaryDirectory()\n",
    "frame_paths, frames = frame_extract(video, short_side,\n",
    "                                    tmp_dir.name)\n",
    "\n",
    "h, w, _ = frames[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce84a3f-cec2-49bc-9295-e256de6ba1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Human detection results.\n",
    "det_results, _ = detection_inference(det_config, det_checkpoint,\n",
    "                                     frame_paths, det_score_thr,\n",
    "                                     det_cat_id, device)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad15062f-e2f6-420b-8254-14f21c1607b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Pose estimation results.\n",
    "pose_results, pose_data_samples = pose_inference(pose_config,\n",
    "                                                 pose_checkpoint,\n",
    "                                                 frame_paths, det_results,\n",
    "                                                 device)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733874cf-67e2-49fd-be59-b1ff44b4303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the recognizer\n",
    "config = mmengine.Config.fromfile(config)\n",
    "# build the model from a config file and a checkpoint file\n",
    "model = init_recognizer(config, checkpoint, device)\n",
    "\n",
    "# Get Action classification results.\n",
    "result = inference_skeleton(model, pose_results, (h, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5749f941-b6f4-4161-8314-9ce8e0705872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the index of highest predicted score on result\n",
    "max_pred_index = result.pred_score.argmax().item()\n",
    "\n",
    "label_map = [x.strip() for x in open(label_map).readlines()]\n",
    "\n",
    "# set the highest predicted label as action_label\n",
    "action_label = label_map[max_pred_index]\n",
    "print(action_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f1ad4f-bbad-4bdf-8132-7e77e18044cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(pose_config, out_filename, frames, pose_data_samples, action_label)\n",
    "\n",
    "tmp_dir.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa4a081-a5a2-4a1f-9397-1348491673e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML('<video width=50% controls autoplay loop><source src=\"dataset/uji_jalan.mp4\"></video>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628f1dd4-5ade-4d36-8885-735f9c41acb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML('<video width=50% controls autoplay loop><source src=\"dataset/uji_jalan_out.mp4\"></video>')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
