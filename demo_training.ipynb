{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a83e8aa-9403-42e3-ab17-07b34e1e49fa",
   "metadata": {},
   "source": [
    "## Training from bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7bdfe89-b1e2-4238-940d-7586d302535a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/03 23:08:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.8.18 (default, Sep 11 2023, 13:40:15) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 0\n",
      "    GPU 0: NVIDIA GeForce GTX 1650 Ti\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 12.3, V12.3.107\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
      "    PyTorch: 2.1.2+cu121\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 12.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.9.2\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.16.2\n",
      "    OpenCV: 4.9.0\n",
      "    MMEngine: 0.10.2\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 0\n",
      "    diff_rank_seed: False\n",
      "    deterministic: False\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "01/03 23:08:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "ann_file = 'data/skeleton/ntu60_2d.pkl'\n",
      "dataset_type = 'PoseDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, save_best='auto', type='CheckpointHook'),\n",
      "    logger=dict(ignore_last=False, interval=20, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    runtime_info=dict(type='RuntimeInfoHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    sync_buffers=dict(type='SyncBuffersHook'),\n",
      "    timer=dict(type='IterTimerHook'))\n",
      "default_scope = 'mmaction'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "launcher = 'none'\n",
      "left_kp = [\n",
      "    1,\n",
      "    3,\n",
      "    5,\n",
      "    7,\n",
      "    9,\n",
      "    11,\n",
      "    13,\n",
      "    15,\n",
      "]\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=20)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        base_channels=32,\n",
      "        conv1_stride_s=1,\n",
      "        depth=50,\n",
      "        dilations=(\n",
      "            1,\n",
      "            1,\n",
      "            1,\n",
      "        ),\n",
      "        in_channels=17,\n",
      "        inflate=(\n",
      "            0,\n",
      "            1,\n",
      "            1,\n",
      "        ),\n",
      "        num_stages=3,\n",
      "        out_indices=(2, ),\n",
      "        pool1_stride_s=1,\n",
      "        pretrained=None,\n",
      "        spatial_strides=(\n",
      "            2,\n",
      "            2,\n",
      "            2,\n",
      "        ),\n",
      "        stage_blocks=(\n",
      "            4,\n",
      "            6,\n",
      "            3,\n",
      "        ),\n",
      "        temporal_strides=(\n",
      "            1,\n",
      "            1,\n",
      "            2,\n",
      "        ),\n",
      "        type='ResNet3dSlowOnly'),\n",
      "    cls_head=dict(\n",
      "        average_clips='prob',\n",
      "        dropout_ratio=0.5,\n",
      "        in_channels=512,\n",
      "        num_classes=60,\n",
      "        type='I3DHead'),\n",
      "    type='Recognizer3D')\n",
      "optim_wrapper = dict(\n",
      "    clip_grad=dict(max_norm=40, norm_type=2),\n",
      "    optimizer=dict(lr=0.2, momentum=0.9, type='SGD', weight_decay=0.0003))\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        T_max=24,\n",
      "        by_epoch=True,\n",
      "        convert_to_iter_based=True,\n",
      "        eta_min=0,\n",
      "        type='CosineAnnealingLR'),\n",
      "]\n",
      "randomness = dict(deterministic=False, diff_rank_seed=False, seed=0)\n",
      "resume = False\n",
      "right_kp = [\n",
      "    2,\n",
      "    4,\n",
      "    6,\n",
      "    8,\n",
      "    10,\n",
      "    12,\n",
      "    14,\n",
      "    16,\n",
      "]\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='data/skeleton/ntu60_2d.pkl',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                clip_len=48,\n",
      "                num_clips=10,\n",
      "                test_mode=True,\n",
      "                type='UniformSampleFrames'),\n",
      "            dict(type='PoseDecode'),\n",
      "            dict(allow_imgpad=True, hw_ratio=1.0, type='PoseCompact'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                64,\n",
      "            ), type='Resize'),\n",
      "            dict(crop_size=64, type='CenterCrop'),\n",
      "            dict(\n",
      "                double=True,\n",
      "                left_kp=[\n",
      "                    1,\n",
      "                    3,\n",
      "                    5,\n",
      "                    7,\n",
      "                    9,\n",
      "                    11,\n",
      "                    13,\n",
      "                    15,\n",
      "                ],\n",
      "                right_kp=[\n",
      "                    2,\n",
      "                    4,\n",
      "                    6,\n",
      "                    8,\n",
      "                    10,\n",
      "                    12,\n",
      "                    14,\n",
      "                    16,\n",
      "                ],\n",
      "                sigma=0.6,\n",
      "                type='GeneratePoseTarget',\n",
      "                use_score=True,\n",
      "                with_kp=True,\n",
      "                with_limb=False),\n",
      "            dict(input_format='NCTHW_Heatmap', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        split='xsub_val',\n",
      "        test_mode=True,\n",
      "        type='PoseDataset'),\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = [\n",
      "    dict(type='AccMetric'),\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(\n",
      "        clip_len=48, num_clips=10, test_mode=True, type='UniformSampleFrames'),\n",
      "    dict(type='PoseDecode'),\n",
      "    dict(allow_imgpad=True, hw_ratio=1.0, type='PoseCompact'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        64,\n",
      "    ), type='Resize'),\n",
      "    dict(crop_size=64, type='CenterCrop'),\n",
      "    dict(\n",
      "        double=True,\n",
      "        left_kp=[\n",
      "            1,\n",
      "            3,\n",
      "            5,\n",
      "            7,\n",
      "            9,\n",
      "            11,\n",
      "            13,\n",
      "            15,\n",
      "        ],\n",
      "        right_kp=[\n",
      "            2,\n",
      "            4,\n",
      "            6,\n",
      "            8,\n",
      "            10,\n",
      "            12,\n",
      "            14,\n",
      "            16,\n",
      "        ],\n",
      "        sigma=0.6,\n",
      "        type='GeneratePoseTarget',\n",
      "        use_score=True,\n",
      "        with_kp=True,\n",
      "        with_limb=False),\n",
      "    dict(input_format='NCTHW_Heatmap', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "train_cfg = dict(\n",
      "    max_epochs=24, type='EpochBasedTrainLoop', val_begin=1, val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_size=4,\n",
      "    dataset=dict(\n",
      "        dataset=dict(\n",
      "            ann_file='data/skeleton/ntu60_2d.pkl',\n",
      "            pipeline=[\n",
      "                dict(clip_len=48, type='UniformSampleFrames'),\n",
      "                dict(type='PoseDecode'),\n",
      "                dict(allow_imgpad=True, hw_ratio=1.0, type='PoseCompact'),\n",
      "                dict(scale=(\n",
      "                    -1,\n",
      "                    64,\n",
      "                ), type='Resize'),\n",
      "                dict(area_range=(\n",
      "                    0.56,\n",
      "                    1.0,\n",
      "                ), type='RandomResizedCrop'),\n",
      "                dict(keep_ratio=False, scale=(\n",
      "                    56,\n",
      "                    56,\n",
      "                ), type='Resize'),\n",
      "                dict(\n",
      "                    flip_ratio=0.5,\n",
      "                    left_kp=[\n",
      "                        1,\n",
      "                        3,\n",
      "                        5,\n",
      "                        7,\n",
      "                        9,\n",
      "                        11,\n",
      "                        13,\n",
      "                        15,\n",
      "                    ],\n",
      "                    right_kp=[\n",
      "                        2,\n",
      "                        4,\n",
      "                        6,\n",
      "                        8,\n",
      "                        10,\n",
      "                        12,\n",
      "                        14,\n",
      "                        16,\n",
      "                    ],\n",
      "                    type='Flip'),\n",
      "                dict(\n",
      "                    sigma=0.6,\n",
      "                    type='GeneratePoseTarget',\n",
      "                    use_score=True,\n",
      "                    with_kp=True,\n",
      "                    with_limb=False),\n",
      "                dict(input_format='NCTHW_Heatmap', type='FormatShape'),\n",
      "                dict(type='PackActionInputs'),\n",
      "            ],\n",
      "            split='xsub_train',\n",
      "            type='PoseDataset'),\n",
      "        times=10,\n",
      "        type='RepeatDataset'),\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(clip_len=48, type='UniformSampleFrames'),\n",
      "    dict(type='PoseDecode'),\n",
      "    dict(allow_imgpad=True, hw_ratio=1.0, type='PoseCompact'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        64,\n",
      "    ), type='Resize'),\n",
      "    dict(area_range=(\n",
      "        0.56,\n",
      "        1.0,\n",
      "    ), type='RandomResizedCrop'),\n",
      "    dict(keep_ratio=False, scale=(\n",
      "        56,\n",
      "        56,\n",
      "    ), type='Resize'),\n",
      "    dict(\n",
      "        flip_ratio=0.5,\n",
      "        left_kp=[\n",
      "            1,\n",
      "            3,\n",
      "            5,\n",
      "            7,\n",
      "            9,\n",
      "            11,\n",
      "            13,\n",
      "            15,\n",
      "        ],\n",
      "        right_kp=[\n",
      "            2,\n",
      "            4,\n",
      "            6,\n",
      "            8,\n",
      "            10,\n",
      "            12,\n",
      "            14,\n",
      "            16,\n",
      "        ],\n",
      "        type='Flip'),\n",
      "    dict(\n",
      "        sigma=0.6,\n",
      "        type='GeneratePoseTarget',\n",
      "        use_score=True,\n",
      "        with_kp=True,\n",
      "        with_limb=False),\n",
      "    dict(input_format='NCTHW_Heatmap', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=4,\n",
      "    dataset=dict(\n",
      "        ann_file='data/skeleton/ntu60_2d.pkl',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                clip_len=48,\n",
      "                num_clips=1,\n",
      "                test_mode=True,\n",
      "                type='UniformSampleFrames'),\n",
      "            dict(type='PoseDecode'),\n",
      "            dict(allow_imgpad=True, hw_ratio=1.0, type='PoseCompact'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                64,\n",
      "            ), type='Resize'),\n",
      "            dict(crop_size=64, type='CenterCrop'),\n",
      "            dict(\n",
      "                sigma=0.6,\n",
      "                type='GeneratePoseTarget',\n",
      "                use_score=True,\n",
      "                with_kp=True,\n",
      "                with_limb=False),\n",
      "            dict(input_format='NCTHW_Heatmap', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        split='xsub_val',\n",
      "        test_mode=True,\n",
      "        type='PoseDataset'),\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = [\n",
      "    dict(type='AccMetric'),\n",
      "]\n",
      "val_pipeline = [\n",
      "    dict(clip_len=48, num_clips=1, test_mode=True, type='UniformSampleFrames'),\n",
      "    dict(type='PoseDecode'),\n",
      "    dict(allow_imgpad=True, hw_ratio=1.0, type='PoseCompact'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        64,\n",
      "    ), type='Resize'),\n",
      "    dict(crop_size=64, type='CenterCrop'),\n",
      "    dict(\n",
      "        sigma=0.6,\n",
      "        type='GeneratePoseTarget',\n",
      "        use_score=True,\n",
      "        with_kp=True,\n",
      "        with_limb=False),\n",
      "    dict(input_format='NCTHW_Heatmap', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    type='ActionVisualizer', vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = 'work_dirs/slowonly_r50_8xb16-u48-240e_ntu60-xsub-keypoint'\n",
      "\n",
      "01/03 23:08:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "01/03 23:08:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "01/03 23:08:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 40091 videos remain after valid thresholding\n",
      "01/03 23:08:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 16487 videos remain after valid thresholding\n",
      "01/03 23:08:42 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "01/03 23:08:42 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "01/03 23:08:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /home/aldy/Documents/skripsi/posec3d-video-structuralize/work_dirs/slowonly_r50_8xb16-u48-240e_ntu60-xsub-keypoint.\n",
      "01/03 23:08:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][    20/100228]  lr: 2.0000e-01  eta: 19 days, 4:13:37  time: 0.6888  data_time: 0.0358  memory: 2524  grad_norm: 3.1621  loss: 4.7462  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.7462\n",
      "01/03 23:09:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][    40/100228]  lr: 2.0000e-01  eta: 18 days, 11:31:11  time: 0.6388  data_time: 0.0073  memory: 2524  grad_norm: 1.0159  loss: 4.3411  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.3411\n",
      "01/03 23:09:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][    60/100228]  lr: 2.0000e-01  eta: 18 days, 6:37:13  time: 0.6418  data_time: 0.0080  memory: 2524  grad_norm: 0.7906  loss: 4.1978  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1978\n",
      "01/03 23:09:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][    80/100228]  lr: 2.0000e-01  eta: 18 days, 4:19:23  time: 0.6427  data_time: 0.0074  memory: 2524  grad_norm: 0.7883  loss: 4.2459  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 4.2459\n",
      "01/03 23:09:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   100/100228]  lr: 2.0000e-01  eta: 18 days, 3:19:26  time: 0.6456  data_time: 0.0082  memory: 2524  grad_norm: 0.6919  loss: 4.2021  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2021\n",
      "01/03 23:10:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   120/100228]  lr: 2.0000e-01  eta: 18 days, 2:38:39  time: 0.6455  data_time: 0.0071  memory: 2524  grad_norm: 0.6018  loss: 4.1896  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1896\n",
      "01/03 23:10:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   140/100228]  lr: 2.0000e-01  eta: 18 days, 2:10:14  time: 0.6456  data_time: 0.0073  memory: 2524  grad_norm: 0.6234  loss: 4.1672  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1672\n",
      "01/03 23:10:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   160/100228]  lr: 2.0000e-01  eta: 18 days, 1:57:11  time: 0.6473  data_time: 0.0075  memory: 2524  grad_norm: 0.6502  loss: 4.2569  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2569\n",
      "01/03 23:10:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   180/100228]  lr: 2.0000e-01  eta: 18 days, 1:55:13  time: 0.6491  data_time: 0.0072  memory: 2524  grad_norm: 0.6301  loss: 4.2187  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2187\n",
      "01/03 23:10:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   200/100228]  lr: 2.0000e-01  eta: 18 days, 1:53:52  time: 0.6492  data_time: 0.0072  memory: 2524  grad_norm: 0.6036  loss: 4.2025  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.2025\n",
      "01/03 23:11:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   220/100228]  lr: 2.0000e-01  eta: 18 days, 2:04:22  time: 0.6524  data_time: 0.0080  memory: 2524  grad_norm: 0.6425  loss: 4.2069  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2069\n",
      "01/03 23:11:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   240/100228]  lr: 2.0000e-01  eta: 18 days, 2:14:13  time: 0.6527  data_time: 0.0081  memory: 2524  grad_norm: 0.5853  loss: 4.3092  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.3092\n",
      "01/03 23:11:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   260/100228]  lr: 2.0000e-01  eta: 18 days, 2:17:41  time: 0.6511  data_time: 0.0071  memory: 2524  grad_norm: 0.5756  loss: 4.1223  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.1223\n",
      "01/03 23:11:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   280/100228]  lr: 2.0000e-01  eta: 18 days, 2:26:17  time: 0.6531  data_time: 0.0075  memory: 2524  grad_norm: 0.5886  loss: 4.1778  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.1778\n",
      "01/03 23:11:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   300/100228]  lr: 2.0000e-01  eta: 18 days, 2:39:46  time: 0.6554  data_time: 0.0079  memory: 2524  grad_norm: 0.6139  loss: 4.2043  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2043\n",
      "01/03 23:12:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   320/100228]  lr: 2.0000e-01  eta: 18 days, 2:49:49  time: 0.6547  data_time: 0.0071  memory: 2524  grad_norm: 0.6213  loss: 4.2577  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2577\n",
      "01/03 23:12:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   340/100228]  lr: 2.0000e-01  eta: 18 days, 2:59:26  time: 0.6550  data_time: 0.0074  memory: 2524  grad_norm: 0.5637  loss: 4.0759  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0759\n",
      "01/03 23:12:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   360/100228]  lr: 2.0000e-01  eta: 18 days, 3:07:17  time: 0.6547  data_time: 0.0074  memory: 2524  grad_norm: 0.5905  loss: 4.2767  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.2767\n",
      "01/03 23:12:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   380/100228]  lr: 2.0000e-01  eta: 18 days, 3:12:34  time: 0.6539  data_time: 0.0072  memory: 2524  grad_norm: 0.5643  loss: 4.2230  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2230\n",
      "01/03 23:13:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   400/100228]  lr: 2.0000e-01  eta: 18 days, 3:20:46  time: 0.6556  data_time: 0.0076  memory: 2524  grad_norm: 0.5626  loss: 4.2184  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2184\n",
      "01/03 23:13:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   420/100228]  lr: 2.0000e-01  eta: 18 days, 3:31:08  time: 0.6572  data_time: 0.0073  memory: 2524  grad_norm: 0.5594  loss: 4.2923  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2923\n",
      "01/03 23:13:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   440/100228]  lr: 2.0000e-01  eta: 18 days, 3:50:49  time: 0.6628  data_time: 0.0083  memory: 2524  grad_norm: 0.5822  loss: 4.2303  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2303\n",
      "01/03 23:13:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   460/100228]  lr: 2.0000e-01  eta: 18 days, 4:23:06  time: 0.6711  data_time: 0.0096  memory: 2524  grad_norm: 0.6028  loss: 4.2292  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2292\n",
      "01/03 23:13:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   480/100228]  lr: 2.0000e-01  eta: 18 days, 4:37:36  time: 0.6620  data_time: 0.0081  memory: 2524  grad_norm: 0.6271  loss: 4.1959  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.1959\n",
      "01/03 23:14:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   500/100228]  lr: 2.0000e-01  eta: 18 days, 4:46:19  time: 0.6592  data_time: 0.0077  memory: 2524  grad_norm: 0.5801  loss: 4.2208  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.2208\n",
      "01/03 23:14:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   520/100228]  lr: 2.0000e-01  eta: 18 days, 4:53:32  time: 0.6586  data_time: 0.0076  memory: 2524  grad_norm: 0.6830  loss: 4.2384  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2384\n",
      "01/03 23:14:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   540/100228]  lr: 2.0000e-01  eta: 18 days, 5:01:30  time: 0.6595  data_time: 0.0077  memory: 2524  grad_norm: 0.5521  loss: 4.1630  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1630\n",
      "01/03 23:14:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   560/100228]  lr: 2.0000e-01  eta: 18 days, 5:10:06  time: 0.6604  data_time: 0.0082  memory: 2524  grad_norm: 0.5710  loss: 4.1092  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 4.1092\n",
      "01/03 23:15:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   580/100228]  lr: 2.0000e-01  eta: 18 days, 5:24:32  time: 0.6650  data_time: 0.0084  memory: 2524  grad_norm: 0.5647  loss: 4.2478  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2478\n",
      "01/03 23:15:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   600/100228]  lr: 2.0000e-01  eta: 18 days, 5:37:18  time: 0.6645  data_time: 0.0091  memory: 2524  grad_norm: 0.5305  loss: 4.1155  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1155\n",
      "01/03 23:15:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   620/100228]  lr: 2.0000e-01  eta: 18 days, 5:41:57  time: 0.6589  data_time: 0.0085  memory: 2524  grad_norm: 0.5721  loss: 4.2662  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2662\n",
      "01/03 23:15:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   640/100228]  lr: 2.0000e-01  eta: 18 days, 5:46:25  time: 0.6590  data_time: 0.0084  memory: 2524  grad_norm: 0.6162  loss: 4.2034  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2034\n",
      "01/03 23:15:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   660/100228]  lr: 2.0000e-01  eta: 18 days, 5:52:41  time: 0.6607  data_time: 0.0083  memory: 2524  grad_norm: 0.6287  loss: 4.1680  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1680\n",
      "01/03 23:16:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   680/100228]  lr: 2.0000e-01  eta: 18 days, 5:57:30  time: 0.6598  data_time: 0.0083  memory: 2524  grad_norm: 0.6379  loss: 4.2225  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2225\n",
      "01/03 23:16:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   700/100228]  lr: 2.0000e-01  eta: 18 days, 6:05:03  time: 0.6624  data_time: 0.0089  memory: 2524  grad_norm: 0.5402  loss: 4.3704  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.3704\n",
      "01/03 23:16:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   720/100228]  lr: 2.0000e-01  eta: 18 days, 6:09:45  time: 0.6602  data_time: 0.0087  memory: 2524  grad_norm: 0.6162  loss: 4.1605  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 4.1605\n",
      "01/03 23:16:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   740/100228]  lr: 2.0000e-01  eta: 18 days, 6:13:04  time: 0.6592  data_time: 0.0083  memory: 2524  grad_norm: 0.5583  loss: 4.2818  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.2818\n",
      "01/03 23:17:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   760/100228]  lr: 2.0000e-01  eta: 18 days, 6:16:32  time: 0.6595  data_time: 0.0084  memory: 2524  grad_norm: 0.5378  loss: 4.1147  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.1147\n",
      "01/03 23:17:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   780/100228]  lr: 2.0000e-01  eta: 18 days, 6:19:02  time: 0.6588  data_time: 0.0078  memory: 2524  grad_norm: 0.6409  loss: 4.2239  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2239\n",
      "01/03 23:17:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   800/100228]  lr: 2.0000e-01  eta: 18 days, 6:22:28  time: 0.6598  data_time: 0.0088  memory: 2524  grad_norm: 0.8976  loss: 4.1730  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.1730\n",
      "01/03 23:17:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   820/100228]  lr: 2.0000e-01  eta: 18 days, 6:25:02  time: 0.6591  data_time: 0.0077  memory: 2524  grad_norm: 0.7645  loss: 4.1246  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1246\n",
      "01/03 23:17:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   840/100228]  lr: 2.0000e-01  eta: 18 days, 6:27:15  time: 0.6589  data_time: 0.0080  memory: 2524  grad_norm: 0.5631  loss: 4.1889  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1889\n",
      "01/03 23:18:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   860/100228]  lr: 2.0000e-01  eta: 18 days, 6:31:25  time: 0.6611  data_time: 0.0102  memory: 2524  grad_norm: 0.6098  loss: 4.0908  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 4.0908\n",
      "01/03 23:18:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   880/100228]  lr: 2.0000e-01  eta: 18 days, 6:33:29  time: 0.6590  data_time: 0.0081  memory: 2524  grad_norm: 0.8345  loss: 4.2034  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2034\n",
      "01/03 23:18:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   900/100228]  lr: 2.0000e-01  eta: 18 days, 6:35:15  time: 0.6588  data_time: 0.0078  memory: 2524  grad_norm: 0.6094  loss: 4.2200  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2200\n",
      "01/03 23:18:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   920/100228]  lr: 2.0000e-01  eta: 18 days, 6:38:04  time: 0.6601  data_time: 0.0088  memory: 2524  grad_norm: 0.5912  loss: 4.2113  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.2113\n",
      "01/03 23:19:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   940/100228]  lr: 2.0000e-01  eta: 18 days, 6:40:59  time: 0.6604  data_time: 0.0081  memory: 2524  grad_norm: 0.5771  loss: 4.1134  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1134\n",
      "01/03 23:19:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   960/100228]  lr: 2.0000e-01  eta: 18 days, 6:43:54  time: 0.6605  data_time: 0.0078  memory: 2524  grad_norm: 0.6877  loss: 4.1797  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.1797\n",
      "01/03 23:19:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   980/100228]  lr: 2.0000e-01  eta: 18 days, 6:46:41  time: 0.6605  data_time: 0.0078  memory: 2524  grad_norm: 0.7604  loss: 4.1115  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.1115\n",
      "01/03 23:19:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowonly_r50_8xb16-u48-240e_ntu60-xsub-keypoint_20240103_230834\n",
      "01/03 23:19:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1000/100228]  lr: 2.0000e-01  eta: 18 days, 6:49:39  time: 0.6609  data_time: 0.0084  memory: 2524  grad_norm: 0.7457  loss: 4.1583  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.1583\n",
      "01/03 23:19:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1020/100228]  lr: 2.0000e-01  eta: 18 days, 6:52:29  time: 0.6609  data_time: 0.0082  memory: 2524  grad_norm: 0.7861  loss: 4.0231  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0231\n",
      "01/03 23:20:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1040/100228]  lr: 2.0000e-01  eta: 18 days, 6:54:38  time: 0.6602  data_time: 0.0082  memory: 2524  grad_norm: 0.6598  loss: 4.2486  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.2486\n",
      "01/03 23:20:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1060/100228]  lr: 2.0000e-01  eta: 18 days, 6:57:27  time: 0.6612  data_time: 0.0082  memory: 2524  grad_norm: 0.6641  loss: 4.1804  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 4.1804\n",
      "01/03 23:20:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1080/100228]  lr: 2.0000e-01  eta: 18 days, 7:00:09  time: 0.6611  data_time: 0.0082  memory: 2524  grad_norm: 0.7916  loss: 4.1648  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 4.1648\n",
      "01/03 23:20:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1100/100228]  lr: 2.0000e-01  eta: 18 days, 7:01:50  time: 0.6599  data_time: 0.0082  memory: 2524  grad_norm: 0.8661  loss: 4.2108  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 4.2108\n",
      "01/03 23:20:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1120/100228]  lr: 2.0000e-01  eta: 18 days, 7:04:59  time: 0.6621  data_time: 0.0085  memory: 2524  grad_norm: 1.1644  loss: 4.2540  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2540\n",
      "01/03 23:21:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1140/100228]  lr: 2.0000e-01  eta: 18 days, 7:12:19  time: 0.6682  data_time: 0.0087  memory: 2524  grad_norm: 0.7158  loss: 4.1743  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1743\n",
      "01/03 23:21:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1160/100228]  lr: 2.0000e-01  eta: 18 days, 7:25:16  time: 0.6767  data_time: 0.0100  memory: 2524  grad_norm: 0.7986  loss: 4.2548  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2548\n",
      "01/03 23:21:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1180/100228]  lr: 2.0000e-01  eta: 18 days, 7:27:46  time: 0.6620  data_time: 0.0086  memory: 2524  grad_norm: 0.7044  loss: 4.1068  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1068\n",
      "01/03 23:21:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1200/100228]  lr: 2.0000e-01  eta: 18 days, 7:31:16  time: 0.6636  data_time: 0.0099  memory: 2524  grad_norm: 0.7592  loss: 4.3732  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.3732\n",
      "01/03 23:22:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1220/100228]  lr: 2.0000e-01  eta: 18 days, 7:34:14  time: 0.6630  data_time: 0.0091  memory: 2524  grad_norm: 0.6260  loss: 4.1624  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1624\n",
      "01/03 23:22:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1240/100228]  lr: 2.0000e-01  eta: 18 days, 7:36:33  time: 0.6621  data_time: 0.0081  memory: 2524  grad_norm: 0.6882  loss: 4.1937  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1937\n",
      "01/03 23:22:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1260/100228]  lr: 2.0000e-01  eta: 18 days, 7:38:44  time: 0.6620  data_time: 0.0083  memory: 2524  grad_norm: 0.6317  loss: 4.1303  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1303\n",
      "01/03 23:22:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1280/100228]  lr: 2.0000e-01  eta: 18 days, 7:40:14  time: 0.6611  data_time: 0.0079  memory: 2524  grad_norm: 0.7136  loss: 4.2393  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2393\n",
      "01/03 23:22:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1300/100228]  lr: 2.0000e-01  eta: 18 days, 7:41:26  time: 0.6607  data_time: 0.0078  memory: 2524  grad_norm: 0.6643  loss: 4.1940  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1940\n",
      "01/03 23:23:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1320/100228]  lr: 2.0000e-01  eta: 18 days, 7:42:32  time: 0.6606  data_time: 0.0078  memory: 2524  grad_norm: 0.6814  loss: 4.0906  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0906\n",
      "01/03 23:23:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1340/100228]  lr: 2.0000e-01  eta: 18 days, 7:43:50  time: 0.6610  data_time: 0.0077  memory: 2524  grad_norm: 0.7017  loss: 4.2010  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 4.2010\n",
      "01/03 23:23:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1360/100228]  lr: 2.0000e-01  eta: 18 days, 7:45:12  time: 0.6611  data_time: 0.0080  memory: 2524  grad_norm: 0.8296  loss: 4.0240  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0240\n",
      "01/03 23:23:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1380/100228]  lr: 2.0000e-01  eta: 18 days, 7:46:46  time: 0.6616  data_time: 0.0080  memory: 2524  grad_norm: 0.7229  loss: 4.1628  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1628\n",
      "01/03 23:24:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1400/100228]  lr: 2.0000e-01  eta: 18 days, 7:48:08  time: 0.6613  data_time: 0.0078  memory: 2524  grad_norm: 0.7360  loss: 4.2520  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.2520\n",
      "01/03 23:24:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1420/100228]  lr: 2.0000e-01  eta: 18 days, 7:49:46  time: 0.6619  data_time: 0.0081  memory: 2524  grad_norm: 0.8235  loss: 4.2430  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.2430\n",
      "01/03 23:24:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1440/100228]  lr: 2.0000e-01  eta: 18 days, 7:53:04  time: 0.6650  data_time: 0.0088  memory: 2524  grad_norm: 0.6835  loss: 4.1885  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1885\n",
      "01/03 23:24:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1460/100228]  lr: 2.0000e-01  eta: 18 days, 7:56:07  time: 0.6647  data_time: 0.0081  memory: 2524  grad_norm: 0.8112  loss: 4.2654  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2654\n",
      "01/03 23:24:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1480/100228]  lr: 2.0000e-01  eta: 18 days, 7:57:48  time: 0.6623  data_time: 0.0078  memory: 2524  grad_norm: 0.7185  loss: 4.2195  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2195\n",
      "01/03 23:25:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1500/100228]  lr: 2.0000e-01  eta: 18 days, 7:59:37  time: 0.6626  data_time: 0.0078  memory: 2524  grad_norm: 0.7337  loss: 4.1940  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1940\n",
      "01/03 23:25:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1520/100228]  lr: 2.0000e-01  eta: 18 days, 8:01:01  time: 0.6620  data_time: 0.0082  memory: 2524  grad_norm: 0.6721  loss: 4.1437  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1437\n",
      "01/03 23:25:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1540/100228]  lr: 2.0000e-01  eta: 18 days, 8:02:24  time: 0.6620  data_time: 0.0079  memory: 2524  grad_norm: 0.7231  loss: 4.1641  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1641\n",
      "01/03 23:25:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1560/100228]  lr: 2.0000e-01  eta: 18 days, 8:04:00  time: 0.6625  data_time: 0.0081  memory: 2524  grad_norm: 0.7436  loss: 4.1091  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.1091\n",
      "01/03 23:26:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1580/100228]  lr: 2.0000e-01  eta: 18 days, 8:06:24  time: 0.6642  data_time: 0.0082  memory: 2524  grad_norm: 0.7878  loss: 4.0155  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0155\n",
      "01/03 23:26:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1600/100228]  lr: 2.0000e-01  eta: 18 days, 8:07:58  time: 0.6626  data_time: 0.0085  memory: 2524  grad_norm: 0.6922  loss: 4.1179  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1179\n",
      "01/03 23:26:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1620/100228]  lr: 2.0000e-01  eta: 18 days, 8:08:55  time: 0.6615  data_time: 0.0079  memory: 2524  grad_norm: 0.6921  loss: 4.1872  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.1872\n",
      "01/03 23:26:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1640/100228]  lr: 2.0000e-01  eta: 18 days, 8:10:27  time: 0.6627  data_time: 0.0087  memory: 2524  grad_norm: 0.7288  loss: 4.0164  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0164\n",
      "01/03 23:26:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1660/100228]  lr: 2.0000e-01  eta: 18 days, 8:11:33  time: 0.6619  data_time: 0.0079  memory: 2524  grad_norm: 0.6949  loss: 4.3269  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.3269\n",
      "01/03 23:27:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1680/100228]  lr: 2.0000e-01  eta: 18 days, 8:12:29  time: 0.6617  data_time: 0.0078  memory: 2524  grad_norm: 0.6053  loss: 4.0848  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0848\n",
      "01/03 23:27:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1700/100228]  lr: 2.0000e-01  eta: 18 days, 8:13:21  time: 0.6616  data_time: 0.0080  memory: 2524  grad_norm: 0.6504  loss: 4.1920  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1920\n",
      "01/03 23:27:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1720/100228]  lr: 2.0000e-01  eta: 18 days, 8:14:40  time: 0.6626  data_time: 0.0080  memory: 2524  grad_norm: 0.7135  loss: 4.1365  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1365\n",
      "01/03 23:27:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1740/100228]  lr: 2.0000e-01  eta: 18 days, 8:16:28  time: 0.6637  data_time: 0.0085  memory: 2524  grad_norm: 0.6928  loss: 4.1469  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1469\n",
      "01/03 23:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1760/100228]  lr: 2.0000e-01  eta: 18 days, 8:17:35  time: 0.6623  data_time: 0.0078  memory: 2524  grad_norm: 0.7616  loss: 4.1822  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1822\n",
      "01/03 23:28:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1780/100228]  lr: 2.0000e-01  eta: 18 days, 8:19:04  time: 0.6632  data_time: 0.0093  memory: 2524  grad_norm: 0.7368  loss: 4.1817  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1817\n",
      "01/03 23:28:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1800/100228]  lr: 2.0000e-01  eta: 18 days, 8:19:32  time: 0.6610  data_time: 0.0080  memory: 2524  grad_norm: 0.7006  loss: 4.1480  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.1480\n",
      "01/03 23:28:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1820/100228]  lr: 2.0000e-01  eta: 18 days, 8:20:51  time: 0.6630  data_time: 0.0090  memory: 2524  grad_norm: 0.6661  loss: 4.2237  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2237\n",
      "01/03 23:28:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1840/100228]  lr: 2.0000e-01  eta: 18 days, 8:21:42  time: 0.6619  data_time: 0.0079  memory: 2524  grad_norm: 0.7403  loss: 4.0503  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0503\n",
      "01/03 23:29:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1860/100228]  lr: 2.0000e-01  eta: 18 days, 8:22:30  time: 0.6619  data_time: 0.0088  memory: 2524  grad_norm: 0.6806  loss: 4.1201  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.1201\n",
      "01/03 23:29:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1880/100228]  lr: 2.0000e-01  eta: 18 days, 8:23:05  time: 0.6615  data_time: 0.0077  memory: 2524  grad_norm: 0.6883  loss: 4.1074  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1074\n",
      "01/03 23:29:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1900/100228]  lr: 2.0000e-01  eta: 18 days, 8:23:44  time: 0.6617  data_time: 0.0077  memory: 2524  grad_norm: 0.7522  loss: 4.1544  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1544\n",
      "01/03 23:29:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1920/100228]  lr: 2.0000e-01  eta: 18 days, 8:24:24  time: 0.6617  data_time: 0.0083  memory: 2524  grad_norm: 0.6773  loss: 4.1056  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.1056\n",
      "01/03 23:30:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1940/100228]  lr: 2.0000e-01  eta: 18 days, 8:25:02  time: 0.6617  data_time: 0.0077  memory: 2524  grad_norm: 0.6551  loss: 4.1748  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1748\n",
      "01/03 23:30:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1960/100228]  lr: 2.0000e-01  eta: 18 days, 8:25:46  time: 0.6620  data_time: 0.0078  memory: 2524  grad_norm: 0.6232  loss: 4.1058  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1058\n",
      "01/03 23:30:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  1980/100228]  lr: 2.0000e-01  eta: 18 days, 8:26:16  time: 0.6615  data_time: 0.0077  memory: 2524  grad_norm: 0.7115  loss: 4.1856  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1856\n",
      "01/03 23:30:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowonly_r50_8xb16-u48-240e_ntu60-xsub-keypoint_20240103_230834\n",
      "01/03 23:30:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2000/100228]  lr: 2.0000e-01  eta: 18 days, 8:26:57  time: 0.6620  data_time: 0.0081  memory: 2524  grad_norm: 0.7036  loss: 4.0259  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0259\n",
      "01/03 23:30:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2020/100228]  lr: 2.0000e-01  eta: 18 days, 8:27:22  time: 0.6613  data_time: 0.0078  memory: 2524  grad_norm: 0.7074  loss: 4.1646  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1646\n",
      "01/03 23:31:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2040/100228]  lr: 2.0000e-01  eta: 18 days, 8:27:33  time: 0.6607  data_time: 0.0078  memory: 2524  grad_norm: 0.6581  loss: 4.1723  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 4.1723\n",
      "01/03 23:31:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2060/100228]  lr: 2.0000e-01  eta: 18 days, 8:28:19  time: 0.6623  data_time: 0.0088  memory: 2524  grad_norm: 0.6739  loss: 4.1215  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.1215\n",
      "01/03 23:31:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2080/100228]  lr: 2.0000e-01  eta: 18 days, 8:28:56  time: 0.6619  data_time: 0.0084  memory: 2524  grad_norm: 0.6168  loss: 4.1701  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1701\n",
      "01/03 23:31:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2100/100228]  lr: 2.0000e-01  eta: 18 days, 8:29:28  time: 0.6618  data_time: 0.0080  memory: 2524  grad_norm: 0.6813  loss: 4.0665  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0665\n",
      "01/03 23:32:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2120/100228]  lr: 2.0000e-01  eta: 18 days, 8:30:04  time: 0.6620  data_time: 0.0081  memory: 2524  grad_norm: 0.6803  loss: 3.9911  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9911\n",
      "01/03 23:32:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2140/100228]  lr: 2.0000e-01  eta: 18 days, 8:30:45  time: 0.6622  data_time: 0.0081  memory: 2524  grad_norm: 0.7391  loss: 4.1220  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.1220\n",
      "01/03 23:32:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2160/100228]  lr: 2.0000e-01  eta: 18 days, 8:31:17  time: 0.6619  data_time: 0.0081  memory: 2524  grad_norm: 0.6577  loss: 4.0727  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0727\n",
      "01/03 23:32:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2180/100228]  lr: 2.0000e-01  eta: 18 days, 8:31:47  time: 0.6618  data_time: 0.0077  memory: 2524  grad_norm: 0.8449  loss: 4.1102  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1102\n",
      "01/03 23:32:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2200/100228]  lr: 2.0000e-01  eta: 18 days, 8:32:13  time: 0.6617  data_time: 0.0078  memory: 2524  grad_norm: 0.7423  loss: 4.1025  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 4.1025\n",
      "01/03 23:33:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2220/100228]  lr: 2.0000e-01  eta: 18 days, 8:32:38  time: 0.6617  data_time: 0.0079  memory: 2524  grad_norm: 0.7884  loss: 4.1858  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.1858\n",
      "01/03 23:33:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2240/100228]  lr: 2.0000e-01  eta: 18 days, 8:33:12  time: 0.6621  data_time: 0.0081  memory: 2524  grad_norm: 0.7720  loss: 4.0323  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0323\n",
      "01/03 23:33:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2260/100228]  lr: 2.0000e-01  eta: 18 days, 8:33:39  time: 0.6618  data_time: 0.0079  memory: 2524  grad_norm: 0.8834  loss: 4.1653  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1653\n",
      "01/03 23:33:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2280/100228]  lr: 2.0000e-01  eta: 18 days, 8:34:25  time: 0.6628  data_time: 0.0083  memory: 2524  grad_norm: 0.7839  loss: 4.1285  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.1285\n",
      "01/03 23:34:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2300/100228]  lr: 2.0000e-01  eta: 18 days, 8:35:06  time: 0.6626  data_time: 0.0086  memory: 2524  grad_norm: 0.6714  loss: 4.1083  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1083\n",
      "01/03 23:34:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2320/100228]  lr: 2.0000e-01  eta: 18 days, 8:35:45  time: 0.6625  data_time: 0.0078  memory: 2524  grad_norm: 0.6596  loss: 4.1022  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1022\n",
      "01/03 23:34:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2340/100228]  lr: 2.0000e-01  eta: 18 days, 8:36:22  time: 0.6625  data_time: 0.0079  memory: 2524  grad_norm: 0.7233  loss: 4.0736  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0736\n",
      "01/03 23:34:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2360/100228]  lr: 2.0000e-01  eta: 18 days, 8:36:47  time: 0.6619  data_time: 0.0079  memory: 2524  grad_norm: 0.8100  loss: 4.0812  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0812\n",
      "01/03 23:34:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2380/100228]  lr: 2.0000e-01  eta: 18 days, 8:37:07  time: 0.6617  data_time: 0.0079  memory: 2524  grad_norm: 0.8754  loss: 4.0476  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0476\n",
      "01/03 23:35:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2400/100228]  lr: 2.0000e-01  eta: 18 days, 8:37:33  time: 0.6621  data_time: 0.0079  memory: 2524  grad_norm: 0.6915  loss: 4.1774  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.1774\n",
      "01/03 23:35:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2420/100228]  lr: 2.0000e-01  eta: 18 days, 8:38:01  time: 0.6622  data_time: 0.0080  memory: 2524  grad_norm: 0.6973  loss: 4.0296  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0296\n",
      "01/03 23:35:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2440/100228]  lr: 2.0000e-01  eta: 18 days, 8:39:21  time: 0.6649  data_time: 0.0085  memory: 2524  grad_norm: 0.7615  loss: 4.2106  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.2106\n",
      "01/03 23:35:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2460/100228]  lr: 2.0000e-01  eta: 18 days, 8:40:09  time: 0.6633  data_time: 0.0080  memory: 2524  grad_norm: 0.6589  loss: 4.0442  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0442\n",
      "01/03 23:35:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2480/100228]  lr: 2.0000e-01  eta: 18 days, 8:40:29  time: 0.6619  data_time: 0.0079  memory: 2524  grad_norm: 0.7082  loss: 4.0287  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0287\n",
      "01/03 23:36:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2500/100228]  lr: 2.0000e-01  eta: 18 days, 8:40:42  time: 0.6616  data_time: 0.0082  memory: 2524  grad_norm: 0.7900  loss: 4.1859  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 4.1859\n",
      "01/03 23:36:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2520/100228]  lr: 2.0000e-01  eta: 18 days, 8:43:21  time: 0.6693  data_time: 0.0097  memory: 2524  grad_norm: 0.6741  loss: 4.1228  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1228\n",
      "01/03 23:36:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2540/100228]  lr: 2.0000e-01  eta: 18 days, 8:45:25  time: 0.6675  data_time: 0.0086  memory: 2524  grad_norm: 0.7603  loss: 4.1888  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.1888\n",
      "01/03 23:36:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2560/100228]  lr: 2.0000e-01  eta: 18 days, 8:46:07  time: 0.6633  data_time: 0.0079  memory: 2524  grad_norm: 0.7156  loss: 3.9694  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 3.9694\n",
      "01/03 23:37:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2580/100228]  lr: 2.0000e-01  eta: 18 days, 8:46:56  time: 0.6637  data_time: 0.0082  memory: 2524  grad_norm: 0.8529  loss: 4.0674  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0674\n",
      "01/03 23:37:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2600/100228]  lr: 2.0000e-01  eta: 18 days, 8:49:27  time: 0.6693  data_time: 0.0088  memory: 2524  grad_norm: 0.7592  loss: 4.0693  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0693\n",
      "01/03 23:37:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2620/100228]  lr: 2.0000e-01  eta: 18 days, 8:50:14  time: 0.6638  data_time: 0.0078  memory: 2524  grad_norm: 0.9877  loss: 3.9772  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9772\n",
      "01/03 23:37:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2640/100228]  lr: 2.0000e-01  eta: 18 days, 8:51:44  time: 0.6661  data_time: 0.0083  memory: 2524  grad_norm: 1.4574  loss: 4.0915  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0915\n",
      "01/03 23:37:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2660/100228]  lr: 2.0000e-01  eta: 18 days, 8:51:57  time: 0.6620  data_time: 0.0086  memory: 2524  grad_norm: 0.9258  loss: 4.0791  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0791\n",
      "01/03 23:38:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2680/100228]  lr: 2.0000e-01  eta: 18 days, 8:51:52  time: 0.6610  data_time: 0.0078  memory: 2524  grad_norm: 0.9432  loss: 4.0270  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0270\n",
      "01/03 23:38:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2700/100228]  lr: 2.0000e-01  eta: 18 days, 8:51:58  time: 0.6616  data_time: 0.0079  memory: 2524  grad_norm: 0.8034  loss: 4.1593  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1593\n",
      "01/03 23:38:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2720/100228]  lr: 2.0000e-01  eta: 18 days, 8:55:05  time: 0.6718  data_time: 0.0090  memory: 2524  grad_norm: 0.8103  loss: 4.0086  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0086\n",
      "01/03 23:38:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2740/100228]  lr: 2.0000e-01  eta: 18 days, 8:55:59  time: 0.6645  data_time: 0.0084  memory: 2524  grad_norm: 0.8470  loss: 3.9964  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9964\n",
      "01/03 23:39:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2760/100228]  lr: 2.0000e-01  eta: 18 days, 8:58:24  time: 0.6698  data_time: 0.0093  memory: 2524  grad_norm: 1.0079  loss: 4.0546  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0546\n",
      "01/03 23:39:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2780/100228]  lr: 2.0000e-01  eta: 18 days, 9:01:18  time: 0.6715  data_time: 0.0089  memory: 2524  grad_norm: 0.7862  loss: 4.1450  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1450\n",
      "01/03 23:39:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2800/100228]  lr: 2.0000e-01  eta: 18 days, 9:02:24  time: 0.6654  data_time: 0.0085  memory: 2524  grad_norm: 0.7214  loss: 4.0394  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0394\n",
      "01/03 23:39:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2820/100228]  lr: 2.0000e-01  eta: 18 days, 9:03:23  time: 0.6651  data_time: 0.0087  memory: 2524  grad_norm: 0.8494  loss: 4.0199  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0199\n",
      "01/03 23:39:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2840/100228]  lr: 2.0000e-01  eta: 18 days, 9:04:38  time: 0.6661  data_time: 0.0099  memory: 2524  grad_norm: 0.9100  loss: 4.0457  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0457\n",
      "01/03 23:40:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2860/100228]  lr: 2.0000e-01  eta: 18 days, 9:05:38  time: 0.6652  data_time: 0.0085  memory: 2524  grad_norm: 0.8895  loss: 4.0555  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0555\n",
      "01/03 23:40:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2880/100228]  lr: 2.0000e-01  eta: 18 days, 9:06:48  time: 0.6659  data_time: 0.0082  memory: 2524  grad_norm: 0.8452  loss: 3.9017  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9017\n",
      "01/03 23:40:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2900/100228]  lr: 2.0000e-01  eta: 18 days, 9:08:27  time: 0.6677  data_time: 0.0087  memory: 2524  grad_norm: 0.7314  loss: 4.2005  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2005\n",
      "01/03 23:40:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2920/100228]  lr: 2.0000e-01  eta: 18 days, 9:08:57  time: 0.6637  data_time: 0.0082  memory: 2524  grad_norm: 0.8481  loss: 3.9461  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9461\n",
      "01/03 23:41:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2940/100228]  lr: 2.0000e-01  eta: 18 days, 9:10:21  time: 0.6669  data_time: 0.0092  memory: 2524  grad_norm: 0.8937  loss: 4.1104  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1104\n",
      "01/03 23:41:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2960/100228]  lr: 2.0000e-01  eta: 18 days, 9:11:10  time: 0.6649  data_time: 0.0083  memory: 2524  grad_norm: 1.0215  loss: 3.9764  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9764\n",
      "01/03 23:41:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  2980/100228]  lr: 2.0000e-01  eta: 18 days, 9:12:44  time: 0.6677  data_time: 0.0085  memory: 2524  grad_norm: 0.8268  loss: 4.0098  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0098\n",
      "01/03 23:41:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowonly_r50_8xb16-u48-240e_ntu60-xsub-keypoint_20240103_230834\n",
      "01/03 23:41:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3000/100228]  lr: 2.0000e-01  eta: 18 days, 9:13:04  time: 0.6632  data_time: 0.0082  memory: 2524  grad_norm: 0.7454  loss: 3.8784  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8784\n",
      "01/03 23:41:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3020/100228]  lr: 2.0000e-01  eta: 18 days, 9:14:40  time: 0.6680  data_time: 0.0088  memory: 2524  grad_norm: 1.6737  loss: 4.2752  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.2752\n",
      "01/03 23:42:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3040/100228]  lr: 2.0000e-01  eta: 18 days, 9:15:20  time: 0.6645  data_time: 0.0084  memory: 2524  grad_norm: 0.8000  loss: 4.1759  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1759\n",
      "01/03 23:42:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3060/100228]  lr: 2.0000e-01  eta: 18 days, 9:16:18  time: 0.6658  data_time: 0.0083  memory: 2524  grad_norm: 0.7122  loss: 3.9618  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9618\n",
      "01/03 23:42:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3080/100228]  lr: 2.0000e-01  eta: 18 days, 9:16:05  time: 0.6612  data_time: 0.0080  memory: 2524  grad_norm: 0.7665  loss: 3.9897  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9897\n",
      "01/03 23:42:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3100/100228]  lr: 2.0000e-01  eta: 18 days, 9:16:37  time: 0.6642  data_time: 0.0090  memory: 2524  grad_norm: 0.8072  loss: 4.0984  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0984\n",
      "01/03 23:43:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3120/100228]  lr: 2.0000e-01  eta: 18 days, 9:16:46  time: 0.6627  data_time: 0.0080  memory: 2524  grad_norm: 1.0187  loss: 3.9439  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.9439\n",
      "01/03 23:43:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3140/100228]  lr: 2.0000e-01  eta: 18 days, 9:16:52  time: 0.6625  data_time: 0.0080  memory: 2524  grad_norm: 0.7220  loss: 4.1400  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 4.1400\n",
      "01/03 23:43:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3160/100228]  lr: 2.0000e-01  eta: 18 days, 9:18:11  time: 0.6673  data_time: 0.0088  memory: 2524  grad_norm: 0.7185  loss: 4.0978  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0978\n",
      "01/03 23:43:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3180/100228]  lr: 2.0000e-01  eta: 18 days, 9:18:22  time: 0.6630  data_time: 0.0086  memory: 2524  grad_norm: 0.7359  loss: 4.0334  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0334\n",
      "01/03 23:43:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3200/100228]  lr: 2.0000e-01  eta: 18 days, 9:17:55  time: 0.6604  data_time: 0.0080  memory: 2524  grad_norm: 0.7735  loss: 4.1786  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1786\n",
      "01/03 23:44:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3220/100228]  lr: 2.0000e-01  eta: 18 days, 9:17:54  time: 0.6622  data_time: 0.0083  memory: 2524  grad_norm: 0.7293  loss: 3.9053  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9053\n",
      "01/03 23:44:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3240/100228]  lr: 2.0000e-01  eta: 18 days, 9:18:17  time: 0.6638  data_time: 0.0086  memory: 2524  grad_norm: 0.7552  loss: 4.0301  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0301\n",
      "01/03 23:44:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3260/100228]  lr: 2.0000e-01  eta: 18 days, 9:18:22  time: 0.6626  data_time: 0.0081  memory: 2524  grad_norm: 0.7075  loss: 3.9526  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.9526\n",
      "01/03 23:44:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3280/100228]  lr: 2.0000e-01  eta: 18 days, 9:19:06  time: 0.6652  data_time: 0.0088  memory: 2524  grad_norm: 1.3675  loss: 4.1502  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1502\n",
      "01/03 23:45:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3300/100228]  lr: 2.0000e-01  eta: 18 days, 9:21:01  time: 0.6702  data_time: 0.0090  memory: 2524  grad_norm: 0.8114  loss: 4.0481  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0481\n",
      "01/03 23:45:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3320/100228]  lr: 2.0000e-01  eta: 18 days, 9:22:28  time: 0.6683  data_time: 0.0085  memory: 2524  grad_norm: 0.9202  loss: 4.1313  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.1313\n",
      "01/03 23:45:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3340/100228]  lr: 2.0000e-01  eta: 18 days, 9:22:29  time: 0.6625  data_time: 0.0079  memory: 2524  grad_norm: 0.9348  loss: 4.0457  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0457\n",
      "01/03 23:45:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3360/100228]  lr: 2.0000e-01  eta: 18 days, 9:22:17  time: 0.6615  data_time: 0.0080  memory: 2524  grad_norm: 0.7635  loss: 4.0243  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0243\n",
      "01/03 23:45:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3380/100228]  lr: 2.0000e-01  eta: 18 days, 9:21:54  time: 0.6608  data_time: 0.0079  memory: 2524  grad_norm: 0.8052  loss: 4.1845  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1845\n",
      "01/03 23:46:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3400/100228]  lr: 2.0000e-01  eta: 18 days, 9:21:41  time: 0.6615  data_time: 0.0082  memory: 2524  grad_norm: 0.7077  loss: 3.9577  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 3.9577\n",
      "01/03 23:46:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3420/100228]  lr: 2.0000e-01  eta: 18 days, 9:21:21  time: 0.6610  data_time: 0.0079  memory: 2524  grad_norm: 0.7902  loss: 3.9802  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9802\n",
      "01/03 23:46:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3440/100228]  lr: 2.0000e-01  eta: 18 days, 9:21:19  time: 0.6623  data_time: 0.0080  memory: 2524  grad_norm: 0.8357  loss: 4.2027  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2027\n",
      "01/03 23:46:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3460/100228]  lr: 2.0000e-01  eta: 18 days, 9:21:30  time: 0.6632  data_time: 0.0081  memory: 2524  grad_norm: 0.6617  loss: 4.0028  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0028\n",
      "01/03 23:47:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3480/100228]  lr: 2.0000e-01  eta: 18 days, 9:20:58  time: 0.6601  data_time: 0.0082  memory: 2524  grad_norm: 0.7553  loss: 4.0536  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0536\n",
      "01/03 23:47:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3500/100228]  lr: 2.0000e-01  eta: 18 days, 9:20:27  time: 0.6602  data_time: 0.0081  memory: 2524  grad_norm: 0.7249  loss: 4.0474  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0474\n",
      "01/03 23:47:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3520/100228]  lr: 2.0000e-01  eta: 18 days, 9:19:47  time: 0.6595  data_time: 0.0084  memory: 2524  grad_norm: 0.7462  loss: 3.9673  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.9673\n",
      "01/03 23:47:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3540/100228]  lr: 2.0000e-01  eta: 18 days, 9:19:10  time: 0.6597  data_time: 0.0079  memory: 2524  grad_norm: 0.8836  loss: 3.9787  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.9787\n",
      "01/03 23:47:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3560/100228]  lr: 2.0000e-01  eta: 18 days, 9:18:52  time: 0.6611  data_time: 0.0087  memory: 2524  grad_norm: 0.7237  loss: 4.0156  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0156\n",
      "01/03 23:48:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3580/100228]  lr: 2.0000e-01  eta: 18 days, 9:18:23  time: 0.6603  data_time: 0.0081  memory: 2524  grad_norm: 0.7475  loss: 4.0423  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 4.0423\n",
      "01/03 23:48:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3600/100228]  lr: 2.0000e-01  eta: 18 days, 9:18:01  time: 0.6607  data_time: 0.0084  memory: 2524  grad_norm: 0.7603  loss: 3.9552  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9552\n",
      "01/03 23:48:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3620/100228]  lr: 2.0000e-01  eta: 18 days, 9:17:47  time: 0.6614  data_time: 0.0086  memory: 2524  grad_norm: 0.8489  loss: 4.0308  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0308\n",
      "01/03 23:48:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3640/100228]  lr: 2.0000e-01  eta: 18 days, 9:17:19  time: 0.6603  data_time: 0.0080  memory: 2524  grad_norm: 0.6968  loss: 4.0733  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0733\n",
      "01/03 23:49:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3660/100228]  lr: 2.0000e-01  eta: 18 days, 9:17:00  time: 0.6610  data_time: 0.0091  memory: 2524  grad_norm: 0.6608  loss: 3.9892  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9892\n",
      "01/03 23:49:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3680/100228]  lr: 2.0000e-01  eta: 18 days, 9:16:37  time: 0.6607  data_time: 0.0083  memory: 2524  grad_norm: 0.7618  loss: 3.9668  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9668\n",
      "01/03 23:49:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3700/100228]  lr: 2.0000e-01  eta: 18 days, 9:16:05  time: 0.6599  data_time: 0.0079  memory: 2524  grad_norm: 0.7943  loss: 4.0456  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 4.0456\n",
      "01/03 23:49:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3720/100228]  lr: 2.0000e-01  eta: 18 days, 9:15:43  time: 0.6607  data_time: 0.0089  memory: 2524  grad_norm: 0.8284  loss: 3.8895  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 3.8895\n",
      "01/03 23:49:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3740/100228]  lr: 2.0000e-01  eta: 18 days, 9:15:25  time: 0.6611  data_time: 0.0087  memory: 2524  grad_norm: 0.8139  loss: 3.9815  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9815\n",
      "01/03 23:50:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3760/100228]  lr: 2.0000e-01  eta: 18 days, 9:15:01  time: 0.6606  data_time: 0.0081  memory: 2524  grad_norm: 0.8109  loss: 3.8568  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8568\n",
      "01/03 23:50:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3780/100228]  lr: 2.0000e-01  eta: 18 days, 9:15:01  time: 0.6625  data_time: 0.0085  memory: 2524  grad_norm: 0.9626  loss: 4.0976  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0976\n",
      "01/03 23:50:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3800/100228]  lr: 2.0000e-01  eta: 18 days, 9:17:25  time: 0.6739  data_time: 0.0094  memory: 2524  grad_norm: 1.8856  loss: 4.1703  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1703\n",
      "01/03 23:50:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3820/100228]  lr: 2.0000e-01  eta: 18 days, 9:17:10  time: 0.6613  data_time: 0.0082  memory: 2524  grad_norm: 0.8699  loss: 3.9593  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.9593\n",
      "01/03 23:51:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3840/100228]  lr: 2.0000e-01  eta: 18 days, 9:17:08  time: 0.6624  data_time: 0.0086  memory: 2524  grad_norm: 0.8422  loss: 4.1012  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1012\n",
      "01/03 23:51:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3860/100228]  lr: 2.0000e-01  eta: 18 days, 9:16:46  time: 0.6607  data_time: 0.0080  memory: 2524  grad_norm: 0.8275  loss: 4.1016  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1016\n",
      "01/03 23:51:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3880/100228]  lr: 2.0000e-01  eta: 18 days, 9:16:22  time: 0.6606  data_time: 0.0084  memory: 2524  grad_norm: 0.7813  loss: 3.8086  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8086\n",
      "01/03 23:51:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3900/100228]  lr: 2.0000e-01  eta: 18 days, 9:15:52  time: 0.6601  data_time: 0.0083  memory: 2524  grad_norm: 0.7299  loss: 3.9774  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9774\n",
      "01/03 23:51:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3920/100228]  lr: 2.0000e-01  eta: 18 days, 9:15:35  time: 0.6611  data_time: 0.0080  memory: 2524  grad_norm: 0.8241  loss: 4.1106  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.1106\n",
      "01/03 23:52:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3940/100228]  lr: 2.0000e-01  eta: 18 days, 9:15:21  time: 0.6614  data_time: 0.0088  memory: 2524  grad_norm: 0.7656  loss: 4.0364  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0364\n",
      "01/03 23:52:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3960/100228]  lr: 2.0000e-01  eta: 18 days, 9:15:13  time: 0.6620  data_time: 0.0093  memory: 2524  grad_norm: 0.7181  loss: 3.9846  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9846\n",
      "01/03 23:52:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  3980/100228]  lr: 2.0000e-01  eta: 18 days, 9:15:12  time: 0.6625  data_time: 0.0101  memory: 2524  grad_norm: 0.7469  loss: 4.0496  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0496\n",
      "01/03 23:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowonly_r50_8xb16-u48-240e_ntu60-xsub-keypoint_20240103_230834\n",
      "01/03 23:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4000/100228]  lr: 2.0000e-01  eta: 18 days, 9:14:59  time: 0.6614  data_time: 0.0087  memory: 2524  grad_norm: 0.7396  loss: 3.9577  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.9577\n",
      "01/03 23:53:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4020/100228]  lr: 2.0000e-01  eta: 18 days, 9:14:55  time: 0.6623  data_time: 0.0103  memory: 2524  grad_norm: 1.0248  loss: 3.9126  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9126\n",
      "01/03 23:53:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4040/100228]  lr: 2.0000e-01  eta: 18 days, 9:14:30  time: 0.6604  data_time: 0.0079  memory: 2524  grad_norm: 0.8705  loss: 4.0203  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0203\n",
      "01/03 23:53:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4060/100228]  lr: 2.0000e-01  eta: 18 days, 9:14:06  time: 0.6606  data_time: 0.0078  memory: 2524  grad_norm: 0.8290  loss: 4.0013  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0013\n",
      "01/03 23:53:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4080/100228]  lr: 2.0000e-01  eta: 18 days, 9:13:38  time: 0.6602  data_time: 0.0080  memory: 2524  grad_norm: 0.7272  loss: 4.1303  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1303\n",
      "01/03 23:53:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4100/100228]  lr: 2.0000e-01  eta: 18 days, 9:13:03  time: 0.6595  data_time: 0.0078  memory: 2524  grad_norm: 0.7602  loss: 4.0220  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0220\n",
      "01/03 23:54:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4120/100228]  lr: 2.0000e-01  eta: 18 days, 9:12:27  time: 0.6596  data_time: 0.0080  memory: 2524  grad_norm: 0.7474  loss: 3.8692  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8692\n",
      "01/03 23:54:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4140/100228]  lr: 2.0000e-01  eta: 18 days, 9:12:03  time: 0.6605  data_time: 0.0079  memory: 2524  grad_norm: 0.8563  loss: 4.0274  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0274\n",
      "01/03 23:54:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4160/100228]  lr: 2.0000e-01  eta: 18 days, 9:11:35  time: 0.6602  data_time: 0.0083  memory: 2524  grad_norm: 0.7796  loss: 3.9433  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9433\n",
      "01/03 23:54:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4180/100228]  lr: 2.0000e-01  eta: 18 days, 9:12:46  time: 0.6688  data_time: 0.0096  memory: 2524  grad_norm: 0.7345  loss: 4.0049  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0049\n",
      "01/03 23:55:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4200/100228]  lr: 2.0000e-01  eta: 18 days, 9:12:49  time: 0.6629  data_time: 0.0092  memory: 2524  grad_norm: 0.7131  loss: 3.9885  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9885\n",
      "01/03 23:55:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4220/100228]  lr: 2.0000e-01  eta: 18 days, 9:13:17  time: 0.6650  data_time: 0.0088  memory: 2524  grad_norm: 0.7482  loss: 3.8915  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8915\n",
      "01/03 23:55:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4240/100228]  lr: 2.0000e-01  eta: 18 days, 9:12:57  time: 0.6609  data_time: 0.0082  memory: 2524  grad_norm: 0.7606  loss: 4.0705  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0705\n",
      "01/03 23:55:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4260/100228]  lr: 2.0000e-01  eta: 18 days, 9:12:37  time: 0.6609  data_time: 0.0080  memory: 2524  grad_norm: 0.7365  loss: 3.9491  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9491\n",
      "01/03 23:55:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4280/100228]  lr: 2.0000e-01  eta: 18 days, 9:12:18  time: 0.6610  data_time: 0.0086  memory: 2524  grad_norm: 0.7809  loss: 3.7824  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.7824\n",
      "01/03 23:56:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4300/100228]  lr: 2.0000e-01  eta: 18 days, 9:11:53  time: 0.6604  data_time: 0.0084  memory: 2524  grad_norm: 0.7573  loss: 4.0132  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0132\n",
      "01/03 23:56:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4320/100228]  lr: 2.0000e-01  eta: 18 days, 9:11:55  time: 0.6629  data_time: 0.0084  memory: 2524  grad_norm: 0.6370  loss: 4.0286  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0286\n",
      "01/03 23:56:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4340/100228]  lr: 2.0000e-01  eta: 18 days, 9:12:11  time: 0.6641  data_time: 0.0091  memory: 2524  grad_norm: 0.7514  loss: 3.8423  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8423\n",
      "01/03 23:56:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4360/100228]  lr: 2.0000e-01  eta: 18 days, 9:11:44  time: 0.6602  data_time: 0.0080  memory: 2524  grad_norm: 0.7387  loss: 3.9959  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.9959\n",
      "01/03 23:56:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4380/100228]  lr: 2.0000e-01  eta: 18 days, 9:11:17  time: 0.6603  data_time: 0.0084  memory: 2524  grad_norm: 0.7318  loss: 3.8566  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.8566\n",
      "01/03 23:57:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4400/100228]  lr: 2.0000e-01  eta: 18 days, 9:10:47  time: 0.6599  data_time: 0.0081  memory: 2524  grad_norm: 0.7738  loss: 4.0827  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0827\n",
      "01/03 23:57:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4420/100228]  lr: 2.0000e-01  eta: 18 days, 9:10:18  time: 0.6600  data_time: 0.0083  memory: 2524  grad_norm: 0.6730  loss: 3.9221  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.9221\n",
      "01/03 23:57:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4440/100228]  lr: 2.0000e-01  eta: 18 days, 9:10:05  time: 0.6616  data_time: 0.0085  memory: 2524  grad_norm: 0.7537  loss: 3.8233  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 3.8233\n",
      "01/03 23:57:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4460/100228]  lr: 2.0000e-01  eta: 18 days, 9:09:44  time: 0.6608  data_time: 0.0089  memory: 2524  grad_norm: 0.8628  loss: 3.8500  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 3.8500\n",
      "01/03 23:58:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4480/100228]  lr: 2.0000e-01  eta: 18 days, 9:09:30  time: 0.6614  data_time: 0.0089  memory: 2524  grad_norm: 0.7671  loss: 3.9438  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9438\n",
      "01/03 23:58:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4500/100228]  lr: 2.0000e-01  eta: 18 days, 9:08:53  time: 0.6592  data_time: 0.0082  memory: 2524  grad_norm: 0.6844  loss: 3.9463  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9463\n",
      "01/03 23:58:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4520/100228]  lr: 2.0000e-01  eta: 18 days, 9:08:17  time: 0.6593  data_time: 0.0082  memory: 2524  grad_norm: 0.6909  loss: 4.0440  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 4.0440\n",
      "01/03 23:58:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4540/100228]  lr: 2.0000e-01  eta: 18 days, 9:08:24  time: 0.6634  data_time: 0.0089  memory: 2524  grad_norm: 0.7490  loss: 4.0670  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0670\n",
      "01/03 23:58:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4560/100228]  lr: 2.0000e-01  eta: 18 days, 9:08:39  time: 0.6641  data_time: 0.0087  memory: 2524  grad_norm: 0.7148  loss: 4.0297  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 4.0297\n",
      "01/03 23:59:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4580/100228]  lr: 2.0000e-01  eta: 18 days, 9:08:32  time: 0.6621  data_time: 0.0080  memory: 2524  grad_norm: 0.7792  loss: 3.8627  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8627\n",
      "01/03 23:59:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4600/100228]  lr: 2.0000e-01  eta: 18 days, 9:08:34  time: 0.6629  data_time: 0.0085  memory: 2524  grad_norm: 0.6663  loss: 3.9339  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9339\n",
      "01/03 23:59:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4620/100228]  lr: 2.0000e-01  eta: 18 days, 9:09:27  time: 0.6679  data_time: 0.0091  memory: 2524  grad_norm: 0.7230  loss: 3.8973  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8973\n",
      "01/03 23:59:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4640/100228]  lr: 2.0000e-01  eta: 18 days, 9:10:10  time: 0.6669  data_time: 0.0093  memory: 2524  grad_norm: 0.7499  loss: 3.8677  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8677\n",
      "01/04 00:00:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4660/100228]  lr: 2.0000e-01  eta: 18 days, 9:10:12  time: 0.6629  data_time: 0.0080  memory: 2524  grad_norm: 0.8157  loss: 4.0104  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 4.0104\n",
      "01/04 00:00:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4680/100228]  lr: 2.0000e-01  eta: 18 days, 9:10:48  time: 0.6663  data_time: 0.0087  memory: 2524  grad_norm: 0.7944  loss: 3.9135  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.9135\n",
      "01/04 00:00:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4700/100228]  lr: 2.0000e-01  eta: 18 days, 9:10:48  time: 0.6629  data_time: 0.0082  memory: 2524  grad_norm: 0.8691  loss: 3.8646  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8646\n",
      "01/04 00:00:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4720/100228]  lr: 2.0000e-01  eta: 18 days, 9:10:28  time: 0.6609  data_time: 0.0083  memory: 2524  grad_norm: 0.8561  loss: 3.7828  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.7828\n",
      "01/04 00:00:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4740/100228]  lr: 2.0000e-01  eta: 18 days, 9:10:12  time: 0.6613  data_time: 0.0087  memory: 2524  grad_norm: 0.8564  loss: 4.0078  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0078\n",
      "01/04 00:01:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4760/100228]  lr: 2.0000e-01  eta: 18 days, 9:10:43  time: 0.6660  data_time: 0.0090  memory: 2524  grad_norm: 0.7797  loss: 3.8672  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.8672\n",
      "01/04 00:01:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4780/100228]  lr: 2.0000e-01  eta: 18 days, 9:10:33  time: 0.6618  data_time: 0.0085  memory: 2524  grad_norm: 0.7499  loss: 3.9958  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.9958\n",
      "01/04 00:01:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4800/100228]  lr: 2.0000e-01  eta: 18 days, 9:11:13  time: 0.6669  data_time: 0.0091  memory: 2524  grad_norm: 0.7448  loss: 4.0308  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0308\n",
      "01/04 00:01:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4820/100228]  lr: 2.0000e-01  eta: 18 days, 9:11:58  time: 0.6675  data_time: 0.0087  memory: 2524  grad_norm: 0.7891  loss: 3.8922  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8922\n",
      "01/04 00:02:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4840/100228]  lr: 2.0000e-01  eta: 18 days, 9:11:33  time: 0.6604  data_time: 0.0086  memory: 2524  grad_norm: 0.7825  loss: 3.8369  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8369\n",
      "01/04 00:02:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4860/100228]  lr: 2.0000e-01  eta: 18 days, 9:11:49  time: 0.6646  data_time: 0.0092  memory: 2524  grad_norm: 0.8505  loss: 3.6202  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.6202\n",
      "01/04 00:02:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4880/100228]  lr: 2.0000e-01  eta: 18 days, 9:11:52  time: 0.6633  data_time: 0.0089  memory: 2524  grad_norm: 0.8739  loss: 4.0728  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0728\n",
      "01/04 00:02:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4900/100228]  lr: 2.0000e-01  eta: 18 days, 9:13:14  time: 0.6713  data_time: 0.0104  memory: 2524  grad_norm: 0.7453  loss: 3.9479  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9479\n",
      "01/04 00:02:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4920/100228]  lr: 2.0000e-01  eta: 18 days, 9:13:59  time: 0.6676  data_time: 0.0089  memory: 2524  grad_norm: 0.9898  loss: 3.8966  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8966\n",
      "01/04 00:03:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4940/100228]  lr: 2.0000e-01  eta: 18 days, 9:15:04  time: 0.6698  data_time: 0.0114  memory: 2524  grad_norm: 0.8251  loss: 3.9755  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9755\n",
      "01/04 00:03:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4960/100228]  lr: 2.0000e-01  eta: 18 days, 9:15:30  time: 0.6657  data_time: 0.0093  memory: 2524  grad_norm: 0.7167  loss: 3.9403  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9403\n",
      "01/04 00:03:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  4980/100228]  lr: 2.0000e-01  eta: 18 days, 9:15:42  time: 0.6644  data_time: 0.0092  memory: 2524  grad_norm: 0.8999  loss: 3.9469  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.9469\n",
      "01/04 00:03:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowonly_r50_8xb16-u48-240e_ntu60-xsub-keypoint_20240103_230834\n",
      "01/04 00:03:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5000/100228]  lr: 2.0000e-01  eta: 18 days, 9:15:11  time: 0.6599  data_time: 0.0084  memory: 2524  grad_norm: 0.8050  loss: 3.9350  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9350\n",
      "01/04 00:04:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5020/100228]  lr: 2.0000e-01  eta: 18 days, 9:14:43  time: 0.6602  data_time: 0.0084  memory: 2524  grad_norm: 1.8915  loss: 4.0286  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0286\n",
      "01/04 00:04:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5040/100228]  lr: 2.0000e-01  eta: 18 days, 9:14:09  time: 0.6596  data_time: 0.0084  memory: 2524  grad_norm: 1.1627  loss: 4.0555  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0555\n",
      "01/04 00:04:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5060/100228]  lr: 2.0000e-01  eta: 18 days, 9:13:32  time: 0.6592  data_time: 0.0085  memory: 2524  grad_norm: 0.9152  loss: 4.0822  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0822\n",
      "01/04 00:04:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5080/100228]  lr: 2.0000e-01  eta: 18 days, 9:13:18  time: 0.6617  data_time: 0.0106  memory: 2524  grad_norm: 0.6966  loss: 4.0369  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0369\n",
      "01/04 00:04:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5100/100228]  lr: 2.0000e-01  eta: 18 days, 9:12:42  time: 0.6593  data_time: 0.0084  memory: 2524  grad_norm: 0.8081  loss: 3.9325  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.9325\n",
      "01/04 00:05:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5120/100228]  lr: 2.0000e-01  eta: 18 days, 9:12:07  time: 0.6593  data_time: 0.0084  memory: 2524  grad_norm: 1.0497  loss: 4.0108  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0108\n",
      "01/04 00:05:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5140/100228]  lr: 2.0000e-01  eta: 18 days, 9:11:33  time: 0.6595  data_time: 0.0086  memory: 2524  grad_norm: 0.7546  loss: 4.0748  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0748\n",
      "01/04 00:05:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5160/100228]  lr: 2.0000e-01  eta: 18 days, 9:11:03  time: 0.6599  data_time: 0.0087  memory: 2524  grad_norm: 0.7891  loss: 3.8230  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.8230\n",
      "01/04 00:05:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5180/100228]  lr: 2.0000e-01  eta: 18 days, 9:10:34  time: 0.6599  data_time: 0.0085  memory: 2524  grad_norm: 0.7699  loss: 4.0471  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0471\n",
      "01/04 00:06:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5200/100228]  lr: 2.0000e-01  eta: 18 days, 9:10:10  time: 0.6605  data_time: 0.0089  memory: 2524  grad_norm: 0.7798  loss: 3.9576  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9576\n",
      "01/04 00:06:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5220/100228]  lr: 2.0000e-01  eta: 18 days, 9:09:37  time: 0.6596  data_time: 0.0084  memory: 2524  grad_norm: 0.7326  loss: 3.9590  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9590\n",
      "01/04 00:06:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5240/100228]  lr: 2.0000e-01  eta: 18 days, 9:09:06  time: 0.6597  data_time: 0.0084  memory: 2524  grad_norm: 0.7419  loss: 3.9168  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9168\n",
      "01/04 00:06:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5260/100228]  lr: 2.0000e-01  eta: 18 days, 9:08:39  time: 0.6601  data_time: 0.0085  memory: 2524  grad_norm: 0.7636  loss: 3.7849  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.7849\n",
      "01/04 00:06:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5280/100228]  lr: 2.0000e-01  eta: 18 days, 9:08:05  time: 0.6594  data_time: 0.0082  memory: 2524  grad_norm: 0.9774  loss: 3.8905  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8905\n",
      "01/04 00:07:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5300/100228]  lr: 2.0000e-01  eta: 18 days, 9:07:31  time: 0.6593  data_time: 0.0080  memory: 2524  grad_norm: 0.7425  loss: 4.0662  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0662\n",
      "01/04 00:07:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5320/100228]  lr: 2.0000e-01  eta: 18 days, 9:06:50  time: 0.6586  data_time: 0.0082  memory: 2524  grad_norm: 0.6992  loss: 3.8341  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 3.8341\n",
      "01/04 00:07:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5340/100228]  lr: 2.0000e-01  eta: 18 days, 9:06:08  time: 0.6585  data_time: 0.0079  memory: 2524  grad_norm: 0.7083  loss: 3.9355  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9355\n",
      "01/04 00:07:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5360/100228]  lr: 2.0000e-01  eta: 18 days, 9:05:36  time: 0.6594  data_time: 0.0086  memory: 2524  grad_norm: 1.0410  loss: 3.9322  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9322\n",
      "01/04 00:08:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5380/100228]  lr: 2.0000e-01  eta: 18 days, 9:05:06  time: 0.6598  data_time: 0.0087  memory: 2524  grad_norm: 0.7947  loss: 4.0109  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0109\n",
      "01/04 00:08:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5400/100228]  lr: 2.0000e-01  eta: 18 days, 9:04:25  time: 0.6585  data_time: 0.0081  memory: 2524  grad_norm: 0.6544  loss: 4.0713  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0713\n",
      "01/04 00:08:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5420/100228]  lr: 2.0000e-01  eta: 18 days, 9:03:53  time: 0.6595  data_time: 0.0084  memory: 2524  grad_norm: 0.7075  loss: 3.9952  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.9952\n",
      "01/04 00:08:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5440/100228]  lr: 2.0000e-01  eta: 18 days, 9:03:17  time: 0.6589  data_time: 0.0080  memory: 2524  grad_norm: 0.8927  loss: 3.9883  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9883\n",
      "01/04 00:08:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5460/100228]  lr: 2.0000e-01  eta: 18 days, 9:02:37  time: 0.6586  data_time: 0.0082  memory: 2524  grad_norm: 0.6289  loss: 3.9336  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9336\n",
      "01/04 00:09:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5480/100228]  lr: 2.0000e-01  eta: 18 days, 9:01:57  time: 0.6585  data_time: 0.0081  memory: 2524  grad_norm: 0.7264  loss: 3.8354  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8354\n",
      "01/04 00:09:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5500/100228]  lr: 2.0000e-01  eta: 18 days, 9:01:24  time: 0.6593  data_time: 0.0087  memory: 2524  grad_norm: 0.6845  loss: 3.8698  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.8698\n",
      "01/04 00:09:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5520/100228]  lr: 2.0000e-01  eta: 18 days, 9:00:52  time: 0.6594  data_time: 0.0084  memory: 2524  grad_norm: 0.7296  loss: 3.8542  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8542\n",
      "01/04 00:09:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5540/100228]  lr: 2.0000e-01  eta: 18 days, 9:00:17  time: 0.6590  data_time: 0.0084  memory: 2524  grad_norm: 0.7441  loss: 4.0378  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0378\n",
      "01/04 00:10:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5560/100228]  lr: 2.0000e-01  eta: 18 days, 8:59:39  time: 0.6587  data_time: 0.0085  memory: 2524  grad_norm: 0.6717  loss: 3.8528  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 3.8528\n",
      "01/04 00:10:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5580/100228]  lr: 2.0000e-01  eta: 18 days, 8:59:01  time: 0.6586  data_time: 0.0080  memory: 2524  grad_norm: 0.7159  loss: 3.8804  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8804\n",
      "01/04 00:10:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5600/100228]  lr: 2.0000e-01  eta: 18 days, 8:58:21  time: 0.6585  data_time: 0.0082  memory: 2524  grad_norm: 0.7516  loss: 4.0161  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0161\n",
      "01/04 00:10:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5620/100228]  lr: 2.0000e-01  eta: 18 days, 8:57:46  time: 0.6589  data_time: 0.0079  memory: 2524  grad_norm: 0.6705  loss: 3.8962  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8962\n",
      "01/04 00:10:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5640/100228]  lr: 2.0000e-01  eta: 18 days, 8:57:06  time: 0.6583  data_time: 0.0084  memory: 2524  grad_norm: 0.7137  loss: 3.7108  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.7108\n",
      "01/04 00:11:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5660/100228]  lr: 2.0000e-01  eta: 18 days, 8:56:27  time: 0.6585  data_time: 0.0081  memory: 2524  grad_norm: 0.6880  loss: 3.9830  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9830\n",
      "01/04 00:11:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5680/100228]  lr: 2.0000e-01  eta: 18 days, 8:55:50  time: 0.6586  data_time: 0.0083  memory: 2524  grad_norm: 0.7059  loss: 3.8903  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8903\n",
      "01/04 00:11:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5700/100228]  lr: 2.0000e-01  eta: 18 days, 8:55:18  time: 0.6593  data_time: 0.0089  memory: 2524  grad_norm: 0.6334  loss: 3.9795  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.9795\n",
      "01/04 00:11:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5720/100228]  lr: 2.0000e-01  eta: 18 days, 9:20:13  time: 0.8411  data_time: 0.0137  memory: 2524  grad_norm: 0.6687  loss: 3.9255  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9255\n",
      "01/04 00:12:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5740/100228]  lr: 2.0000e-01  eta: 18 days, 9:45:29  time: 0.8450  data_time: 0.0079  memory: 2524  grad_norm: 0.7244  loss: 3.9364  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9364\n",
      "01/04 00:12:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5760/100228]  lr: 2.0000e-01  eta: 18 days, 10:09:19  time: 0.8359  data_time: 0.0081  memory: 2524  grad_norm: 0.6944  loss: 3.9381  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.9381\n",
      "01/04 00:12:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5780/100228]  lr: 2.0000e-01  eta: 18 days, 10:32:19  time: 0.8311  data_time: 0.0080  memory: 2524  grad_norm: 0.8366  loss: 3.8501  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8501\n",
      "01/04 00:12:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5800/100228]  lr: 2.0000e-01  eta: 18 days, 10:31:43  time: 0.6612  data_time: 0.0089  memory: 2524  grad_norm: 0.6436  loss: 3.9080  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.9080\n",
      "01/04 00:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5820/100228]  lr: 2.0000e-01  eta: 18 days, 10:29:54  time: 0.6522  data_time: 0.0080  memory: 2524  grad_norm: 0.6479  loss: 3.8418  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8418\n",
      "01/04 00:13:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5840/100228]  lr: 2.0000e-01  eta: 18 days, 10:28:12  time: 0.6531  data_time: 0.0083  memory: 2524  grad_norm: 0.6704  loss: 3.9440  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.9440\n",
      "01/04 00:13:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5860/100228]  lr: 2.0000e-01  eta: 18 days, 10:26:31  time: 0.6530  data_time: 0.0079  memory: 2524  grad_norm: 0.8005  loss: 3.9039  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9039\n",
      "01/04 00:13:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5880/100228]  lr: 2.0000e-01  eta: 18 days, 10:24:57  time: 0.6539  data_time: 0.0087  memory: 2524  grad_norm: 0.7530  loss: 3.8588  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8588\n",
      "01/04 00:13:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5900/100228]  lr: 2.0000e-01  eta: 18 days, 10:23:29  time: 0.6545  data_time: 0.0084  memory: 2524  grad_norm: 0.8029  loss: 3.9860  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9860\n",
      "01/04 00:14:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5920/100228]  lr: 2.0000e-01  eta: 18 days, 10:22:00  time: 0.6544  data_time: 0.0085  memory: 2524  grad_norm: 0.7098  loss: 4.0854  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0854\n",
      "01/04 00:14:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5940/100228]  lr: 2.0000e-01  eta: 18 days, 10:20:25  time: 0.6535  data_time: 0.0080  memory: 2524  grad_norm: 0.6533  loss: 3.9148  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9148\n",
      "01/04 00:14:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5960/100228]  lr: 2.0000e-01  eta: 18 days, 10:18:58  time: 0.6544  data_time: 0.0082  memory: 2524  grad_norm: 0.6331  loss: 4.0512  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0512\n",
      "01/04 00:14:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  5980/100228]  lr: 2.0000e-01  eta: 18 days, 10:17:23  time: 0.6535  data_time: 0.0081  memory: 2524  grad_norm: 0.6762  loss: 4.0124  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0124\n",
      "01/04 00:15:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowonly_r50_8xb16-u48-240e_ntu60-xsub-keypoint_20240103_230834\n",
      "01/04 00:15:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6000/100228]  lr: 2.0000e-01  eta: 18 days, 10:15:58  time: 0.6546  data_time: 0.0084  memory: 2524  grad_norm: 0.7308  loss: 3.8289  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.8289\n",
      "01/04 00:15:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6020/100228]  lr: 2.0000e-01  eta: 18 days, 10:14:31  time: 0.6542  data_time: 0.0083  memory: 2524  grad_norm: 0.6891  loss: 3.8924  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8924\n",
      "01/04 00:15:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6040/100228]  lr: 2.0000e-01  eta: 18 days, 10:13:19  time: 0.6561  data_time: 0.0101  memory: 2524  grad_norm: 0.8758  loss: 3.9163  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9163\n",
      "01/04 00:15:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6060/100228]  lr: 2.0000e-01  eta: 18 days, 10:11:53  time: 0.6543  data_time: 0.0080  memory: 2524  grad_norm: 0.7452  loss: 3.9113  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9113\n",
      "01/04 00:15:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6080/100228]  lr: 2.0000e-01  eta: 18 days, 10:10:26  time: 0.6542  data_time: 0.0080  memory: 2524  grad_norm: 1.0569  loss: 4.0589  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0589\n",
      "01/04 00:16:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6100/100228]  lr: 2.0000e-01  eta: 18 days, 10:08:56  time: 0.6537  data_time: 0.0081  memory: 2524  grad_norm: 0.6233  loss: 3.8794  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8794\n",
      "01/04 00:16:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6120/100228]  lr: 2.0000e-01  eta: 18 days, 10:07:20  time: 0.6529  data_time: 0.0079  memory: 2524  grad_norm: 0.8151  loss: 3.8997  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8997\n",
      "01/04 00:16:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6140/100228]  lr: 2.0000e-01  eta: 18 days, 10:05:49  time: 0.6533  data_time: 0.0084  memory: 2524  grad_norm: 0.7589  loss: 3.9798  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9798\n",
      "01/04 00:16:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6160/100228]  lr: 2.0000e-01  eta: 18 days, 10:04:23  time: 0.6541  data_time: 0.0087  memory: 2524  grad_norm: 0.6913  loss: 4.0095  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0095\n",
      "01/04 00:17:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6180/100228]  lr: 2.0000e-01  eta: 18 days, 10:02:56  time: 0.6538  data_time: 0.0081  memory: 2524  grad_norm: 0.6476  loss: 3.9759  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.9759\n",
      "01/04 00:17:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6200/100228]  lr: 2.0000e-01  eta: 18 days, 10:01:32  time: 0.6541  data_time: 0.0083  memory: 2524  grad_norm: 0.6618  loss: 3.9879  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9879\n",
      "01/04 00:17:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6220/100228]  lr: 2.0000e-01  eta: 18 days, 10:00:04  time: 0.6535  data_time: 0.0079  memory: 2524  grad_norm: 0.6876  loss: 3.8782  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8782\n",
      "01/04 00:17:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6240/100228]  lr: 2.0000e-01  eta: 18 days, 9:58:30  time: 0.6527  data_time: 0.0078  memory: 2524  grad_norm: 0.6390  loss: 3.9730  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9730\n",
      "01/04 00:17:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6260/100228]  lr: 2.0000e-01  eta: 18 days, 9:57:02  time: 0.6535  data_time: 0.0080  memory: 2524  grad_norm: 0.6485  loss: 3.9592  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9592\n",
      "01/04 00:18:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6280/100228]  lr: 2.0000e-01  eta: 18 days, 9:55:31  time: 0.6530  data_time: 0.0078  memory: 2524  grad_norm: 0.6314  loss: 3.9622  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.9622\n",
      "01/04 00:18:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6300/100228]  lr: 2.0000e-01  eta: 18 days, 9:54:00  time: 0.6530  data_time: 0.0078  memory: 2524  grad_norm: 0.7049  loss: 3.9130  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9130\n",
      "01/04 00:18:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6320/100228]  lr: 2.0000e-01  eta: 18 days, 9:52:30  time: 0.6529  data_time: 0.0082  memory: 2524  grad_norm: 0.7508  loss: 4.0781  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 4.0781\n",
      "01/04 00:18:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6340/100228]  lr: 2.0000e-01  eta: 18 days, 9:50:57  time: 0.6526  data_time: 0.0078  memory: 2524  grad_norm: 0.6731  loss: 3.7851  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.7851\n",
      "01/04 00:18:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6360/100228]  lr: 2.0000e-01  eta: 18 days, 9:49:38  time: 0.6543  data_time: 0.0081  memory: 2524  grad_norm: 0.8132  loss: 3.9677  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9677\n",
      "01/04 00:19:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6380/100228]  lr: 2.0000e-01  eta: 18 days, 9:48:25  time: 0.6550  data_time: 0.0087  memory: 2524  grad_norm: 0.7543  loss: 3.9446  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9446\n",
      "01/04 00:19:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6400/100228]  lr: 2.0000e-01  eta: 18 days, 9:47:00  time: 0.6534  data_time: 0.0083  memory: 2524  grad_norm: 0.7494  loss: 3.9538  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9538\n",
      "01/04 00:19:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6420/100228]  lr: 2.0000e-01  eta: 18 days, 9:45:38  time: 0.6538  data_time: 0.0081  memory: 2524  grad_norm: 0.7028  loss: 3.7773  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 3.7773\n",
      "01/04 00:19:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6440/100228]  lr: 2.0000e-01  eta: 18 days, 9:44:20  time: 0.6541  data_time: 0.0083  memory: 2524  grad_norm: 0.7554  loss: 4.0303  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0303\n",
      "01/04 00:20:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6460/100228]  lr: 2.0000e-01  eta: 18 days, 9:43:09  time: 0.6551  data_time: 0.0089  memory: 2524  grad_norm: 0.8295  loss: 3.9548  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9548\n",
      "01/04 00:20:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6480/100228]  lr: 2.0000e-01  eta: 18 days, 9:41:56  time: 0.6549  data_time: 0.0086  memory: 2524  grad_norm: 0.7027  loss: 4.1230  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1230\n",
      "01/04 00:20:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6500/100228]  lr: 2.0000e-01  eta: 18 days, 9:40:47  time: 0.6553  data_time: 0.0085  memory: 2524  grad_norm: 0.6745  loss: 3.9343  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9343\n",
      "01/04 00:20:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6520/100228]  lr: 2.0000e-01  eta: 18 days, 9:39:28  time: 0.6538  data_time: 0.0078  memory: 2524  grad_norm: 0.6994  loss: 4.0082  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0082\n",
      "01/04 00:20:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6540/100228]  lr: 2.0000e-01  eta: 18 days, 9:38:09  time: 0.6539  data_time: 0.0078  memory: 2524  grad_norm: 0.7383  loss: 3.8610  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8610\n",
      "01/04 00:21:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6560/100228]  lr: 2.0000e-01  eta: 18 days, 9:37:18  time: 0.6576  data_time: 0.0084  memory: 2524  grad_norm: 0.7126  loss: 3.8819  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8819\n",
      "01/04 00:21:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6580/100228]  lr: 2.0000e-01  eta: 18 days, 9:37:23  time: 0.6652  data_time: 0.0091  memory: 2524  grad_norm: 0.7797  loss: 3.9652  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9652\n",
      "01/04 00:21:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6600/100228]  lr: 2.0000e-01  eta: 18 days, 9:36:15  time: 0.6552  data_time: 0.0081  memory: 2524  grad_norm: 0.6914  loss: 3.8681  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8681\n",
      "01/04 00:21:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6620/100228]  lr: 2.0000e-01  eta: 18 days, 9:35:03  time: 0.6545  data_time: 0.0079  memory: 2524  grad_norm: 0.6782  loss: 3.9354  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9354\n",
      "01/04 00:22:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6640/100228]  lr: 2.0000e-01  eta: 18 days, 9:34:22  time: 0.6589  data_time: 0.0082  memory: 2524  grad_norm: 0.7358  loss: 3.9185  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9185\n",
      "01/04 00:22:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6660/100228]  lr: 2.0000e-01  eta: 18 days, 9:33:27  time: 0.6569  data_time: 0.0086  memory: 2524  grad_norm: 0.7370  loss: 3.7836  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.7836\n",
      "01/04 00:22:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6680/100228]  lr: 2.0000e-01  eta: 18 days, 9:32:12  time: 0.6541  data_time: 0.0079  memory: 2524  grad_norm: 0.7472  loss: 3.9185  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9185\n",
      "01/04 00:22:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6700/100228]  lr: 2.0000e-01  eta: 18 days, 9:31:04  time: 0.6551  data_time: 0.0080  memory: 2524  grad_norm: 0.9954  loss: 3.7705  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.7705\n",
      "01/04 00:22:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6720/100228]  lr: 2.0000e-01  eta: 18 days, 9:29:54  time: 0.6546  data_time: 0.0082  memory: 2524  grad_norm: 0.9443  loss: 3.9313  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9313\n",
      "01/04 00:23:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6740/100228]  lr: 2.0000e-01  eta: 18 days, 9:29:21  time: 0.6598  data_time: 0.0093  memory: 2524  grad_norm: 0.6940  loss: 4.0087  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0087\n",
      "01/04 00:23:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6760/100228]  lr: 2.0000e-01  eta: 18 days, 9:28:05  time: 0.6538  data_time: 0.0079  memory: 2524  grad_norm: 0.6617  loss: 4.0354  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0354\n",
      "01/04 00:23:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6780/100228]  lr: 2.0000e-01  eta: 18 days, 9:26:49  time: 0.6537  data_time: 0.0080  memory: 2524  grad_norm: 0.6988  loss: 3.6629  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.6629\n",
      "01/04 00:23:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6800/100228]  lr: 2.0000e-01  eta: 18 days, 9:26:26  time: 0.6611  data_time: 0.0086  memory: 2524  grad_norm: 0.7918  loss: 4.0609  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0609\n",
      "01/04 00:24:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6820/100228]  lr: 2.0000e-01  eta: 18 days, 9:25:15  time: 0.6544  data_time: 0.0082  memory: 2524  grad_norm: 0.7162  loss: 3.9648  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 3.9648\n",
      "01/04 00:24:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6840/100228]  lr: 2.0000e-01  eta: 18 days, 9:24:34  time: 0.6585  data_time: 0.0087  memory: 2524  grad_norm: 0.8712  loss: 3.9699  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9699\n",
      "01/04 00:24:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6860/100228]  lr: 2.0000e-01  eta: 18 days, 9:23:46  time: 0.6576  data_time: 0.0082  memory: 2524  grad_norm: 0.6878  loss: 3.9937  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.9937\n",
      "01/04 00:24:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6880/100228]  lr: 2.0000e-01  eta: 18 days, 9:22:32  time: 0.6538  data_time: 0.0081  memory: 2524  grad_norm: 0.7638  loss: 4.0089  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0089\n",
      "01/04 00:24:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6900/100228]  lr: 2.0000e-01  eta: 18 days, 9:21:22  time: 0.6543  data_time: 0.0082  memory: 2524  grad_norm: 0.6327  loss: 3.9606  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.9606\n",
      "01/04 00:25:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6920/100228]  lr: 2.0000e-01  eta: 18 days, 9:21:01  time: 0.6613  data_time: 0.0087  memory: 2524  grad_norm: 0.7291  loss: 3.9248  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 3.9248\n",
      "01/04 00:25:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6940/100228]  lr: 2.0000e-01  eta: 18 days, 9:20:04  time: 0.6561  data_time: 0.0087  memory: 2524  grad_norm: 0.7510  loss: 3.8958  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 3.8958\n",
      "01/04 00:25:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6960/100228]  lr: 2.0000e-01  eta: 18 days, 9:19:01  time: 0.6553  data_time: 0.0086  memory: 2524  grad_norm: 0.7576  loss: 3.9450  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9450\n",
      "01/04 00:25:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  6980/100228]  lr: 2.0000e-01  eta: 18 days, 9:18:03  time: 0.6558  data_time: 0.0089  memory: 2524  grad_norm: 0.7327  loss: 3.9714  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9714\n",
      "01/04 00:25:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowonly_r50_8xb16-u48-240e_ntu60-xsub-keypoint_20240103_230834\n",
      "01/04 00:25:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7000/100228]  lr: 2.0000e-01  eta: 18 days, 9:17:20  time: 0.6581  data_time: 0.0088  memory: 2524  grad_norm: 0.6695  loss: 3.9403  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.9403\n",
      "01/04 00:26:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7020/100228]  lr: 2.0000e-01  eta: 18 days, 9:16:41  time: 0.6585  data_time: 0.0089  memory: 2524  grad_norm: 0.6508  loss: 3.8168  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8168\n",
      "01/04 00:26:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7040/100228]  lr: 2.0000e-01  eta: 18 days, 9:15:24  time: 0.6531  data_time: 0.0087  memory: 2524  grad_norm: 0.7866  loss: 3.8682  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8682\n",
      "01/04 00:26:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7060/100228]  lr: 2.0000e-01  eta: 18 days, 9:14:05  time: 0.6526  data_time: 0.0080  memory: 2524  grad_norm: 0.6363  loss: 3.9193  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 3.9193\n",
      "01/04 00:26:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7080/100228]  lr: 2.0000e-01  eta: 18 days, 9:13:01  time: 0.6548  data_time: 0.0090  memory: 2524  grad_norm: 0.8616  loss: 3.9593  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9593\n",
      "01/04 00:27:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7100/100228]  lr: 2.0000e-01  eta: 18 days, 9:11:45  time: 0.6529  data_time: 0.0083  memory: 2524  grad_norm: 0.6718  loss: 3.9631  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.9631\n",
      "01/04 00:27:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7120/100228]  lr: 2.0000e-01  eta: 18 days, 9:10:43  time: 0.6550  data_time: 0.0086  memory: 2524  grad_norm: 0.7224  loss: 4.0304  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0304\n",
      "01/04 00:27:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7140/100228]  lr: 2.0000e-01  eta: 18 days, 9:09:41  time: 0.6550  data_time: 0.0082  memory: 2524  grad_norm: 0.7605  loss: 3.8788  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8788\n",
      "01/04 00:27:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7160/100228]  lr: 2.0000e-01  eta: 18 days, 9:08:26  time: 0.6531  data_time: 0.0084  memory: 2524  grad_norm: 0.8163  loss: 3.8348  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.8348\n",
      "01/04 00:27:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7180/100228]  lr: 2.0000e-01  eta: 18 days, 9:07:15  time: 0.6535  data_time: 0.0082  memory: 2524  grad_norm: 0.7213  loss: 3.8590  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8590\n",
      "01/04 00:28:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7200/100228]  lr: 2.0000e-01  eta: 18 days, 9:06:00  time: 0.6529  data_time: 0.0078  memory: 2524  grad_norm: 0.9255  loss: 3.8462  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.8462\n",
      "01/04 00:28:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7220/100228]  lr: 2.0000e-01  eta: 18 days, 9:04:46  time: 0.6529  data_time: 0.0086  memory: 2524  grad_norm: 0.8399  loss: 3.7978  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.7978\n",
      "01/04 00:28:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7240/100228]  lr: 2.0000e-01  eta: 18 days, 9:03:27  time: 0.6523  data_time: 0.0077  memory: 2524  grad_norm: 0.7627  loss: 3.9607  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9607\n",
      "01/04 00:28:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7260/100228]  lr: 2.0000e-01  eta: 18 days, 9:02:13  time: 0.6529  data_time: 0.0077  memory: 2524  grad_norm: 0.7611  loss: 3.8967  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8967\n",
      "01/04 00:29:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7280/100228]  lr: 2.0000e-01  eta: 18 days, 9:00:57  time: 0.6525  data_time: 0.0079  memory: 2524  grad_norm: 0.7004  loss: 3.7815  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.7815\n",
      "01/04 00:29:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7300/100228]  lr: 2.0000e-01  eta: 18 days, 8:59:45  time: 0.6530  data_time: 0.0084  memory: 2524  grad_norm: 0.7115  loss: 3.7838  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.7838\n",
      "01/04 00:29:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7320/100228]  lr: 2.0000e-01  eta: 18 days, 8:58:33  time: 0.6531  data_time: 0.0079  memory: 2524  grad_norm: 0.7979  loss: 3.8958  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8958\n",
      "01/04 00:29:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7340/100228]  lr: 2.0000e-01  eta: 18 days, 8:57:52  time: 0.6577  data_time: 0.0079  memory: 2524  grad_norm: 0.6966  loss: 4.0664  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0664\n",
      "01/04 00:29:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7360/100228]  lr: 2.0000e-01  eta: 18 days, 8:56:54  time: 0.6552  data_time: 0.0080  memory: 2524  grad_norm: 0.7548  loss: 3.8596  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8596\n",
      "01/04 00:30:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7380/100228]  lr: 2.0000e-01  eta: 18 days, 8:56:19  time: 0.6586  data_time: 0.0086  memory: 2524  grad_norm: 0.8098  loss: 3.9558  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9558\n",
      "01/04 00:30:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7400/100228]  lr: 2.0000e-01  eta: 18 days, 8:55:05  time: 0.6525  data_time: 0.0083  memory: 2524  grad_norm: 0.7503  loss: 3.8395  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8395\n",
      "01/04 00:30:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7420/100228]  lr: 2.0000e-01  eta: 18 days, 8:53:54  time: 0.6529  data_time: 0.0082  memory: 2524  grad_norm: 0.7773  loss: 3.9413  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9413\n",
      "01/04 00:30:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7440/100228]  lr: 2.0000e-01  eta: 18 days, 8:52:45  time: 0.6533  data_time: 0.0085  memory: 2524  grad_norm: 0.7284  loss: 3.9208  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.9208\n",
      "01/04 00:31:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7460/100228]  lr: 2.0000e-01  eta: 18 days, 8:51:30  time: 0.6523  data_time: 0.0080  memory: 2524  grad_norm: 0.9098  loss: 3.7457  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.7457\n",
      "01/04 00:31:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7480/100228]  lr: 2.0000e-01  eta: 18 days, 8:50:23  time: 0.6534  data_time: 0.0085  memory: 2524  grad_norm: 0.8418  loss: 3.8780  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 3.8780\n",
      "01/04 00:31:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7500/100228]  lr: 2.0000e-01  eta: 18 days, 8:49:17  time: 0.6536  data_time: 0.0085  memory: 2524  grad_norm: 0.8612  loss: 3.8342  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8342\n",
      "01/04 00:31:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7520/100228]  lr: 2.0000e-01  eta: 18 days, 8:48:03  time: 0.6522  data_time: 0.0079  memory: 2524  grad_norm: 0.9061  loss: 3.8123  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8123\n",
      "01/04 00:31:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7540/100228]  lr: 2.0000e-01  eta: 18 days, 8:46:52  time: 0.6527  data_time: 0.0084  memory: 2524  grad_norm: 0.9810  loss: 3.9749  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9749\n",
      "01/04 00:32:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7560/100228]  lr: 2.0000e-01  eta: 18 days, 8:45:39  time: 0.6523  data_time: 0.0081  memory: 2524  grad_norm: 0.7022  loss: 4.0239  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0239\n",
      "01/04 00:32:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7580/100228]  lr: 2.0000e-01  eta: 18 days, 8:44:26  time: 0.6523  data_time: 0.0081  memory: 2524  grad_norm: 0.6709  loss: 4.0558  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0558\n",
      "01/04 00:32:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7600/100228]  lr: 2.0000e-01  eta: 18 days, 8:43:13  time: 0.6522  data_time: 0.0081  memory: 2524  grad_norm: 0.6996  loss: 3.8973  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8973\n",
      "01/04 00:32:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7620/100228]  lr: 2.0000e-01  eta: 18 days, 8:41:58  time: 0.6519  data_time: 0.0078  memory: 2524  grad_norm: 0.7620  loss: 3.7346  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 3.7346\n",
      "01/04 00:32:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7640/100228]  lr: 2.0000e-01  eta: 18 days, 8:40:42  time: 0.6517  data_time: 0.0079  memory: 2524  grad_norm: 0.6905  loss: 3.8214  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8214\n",
      "01/04 00:33:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7660/100228]  lr: 1.9999e-01  eta: 18 days, 8:39:34  time: 0.6528  data_time: 0.0081  memory: 2524  grad_norm: 0.8074  loss: 3.9919  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9919\n",
      "01/04 00:33:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7680/100228]  lr: 1.9999e-01  eta: 18 days, 8:38:23  time: 0.6523  data_time: 0.0078  memory: 2524  grad_norm: 0.7770  loss: 3.9106  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9106\n",
      "01/04 00:33:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7700/100228]  lr: 1.9999e-01  eta: 18 days, 8:37:08  time: 0.6516  data_time: 0.0080  memory: 2524  grad_norm: 0.7305  loss: 3.8993  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8993\n",
      "01/04 00:33:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7720/100228]  lr: 1.9999e-01  eta: 18 days, 8:35:55  time: 0.6519  data_time: 0.0078  memory: 2524  grad_norm: 0.8010  loss: 3.8723  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8723\n",
      "01/04 00:34:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7740/100228]  lr: 1.9999e-01  eta: 18 days, 8:34:45  time: 0.6525  data_time: 0.0079  memory: 2524  grad_norm: 0.6456  loss: 4.0777  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0777\n",
      "01/04 00:34:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7760/100228]  lr: 1.9999e-01  eta: 18 days, 8:33:40  time: 0.6530  data_time: 0.0089  memory: 2524  grad_norm: 0.7510  loss: 3.9126  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.9126\n",
      "01/04 00:34:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7780/100228]  lr: 1.9999e-01  eta: 18 days, 8:32:31  time: 0.6524  data_time: 0.0080  memory: 2524  grad_norm: 0.7280  loss: 3.9316  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9316\n",
      "01/04 00:34:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7800/100228]  lr: 1.9999e-01  eta: 18 days, 8:31:21  time: 0.6523  data_time: 0.0082  memory: 2524  grad_norm: 0.7794  loss: 3.9754  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9754\n",
      "01/04 00:34:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7820/100228]  lr: 1.9999e-01  eta: 18 days, 8:30:12  time: 0.6523  data_time: 0.0086  memory: 2524  grad_norm: 0.6648  loss: 3.9572  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.9572\n",
      "01/04 00:35:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7840/100228]  lr: 1.9999e-01  eta: 18 days, 8:28:59  time: 0.6516  data_time: 0.0079  memory: 2524  grad_norm: 0.8006  loss: 3.9359  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9359\n",
      "01/04 00:35:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7860/100228]  lr: 1.9999e-01  eta: 18 days, 8:27:48  time: 0.6519  data_time: 0.0080  memory: 2524  grad_norm: 0.7855  loss: 3.8333  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8333\n",
      "01/04 00:35:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7880/100228]  lr: 1.9999e-01  eta: 18 days, 8:26:32  time: 0.6511  data_time: 0.0079  memory: 2524  grad_norm: 0.6756  loss: 3.9457  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9457\n",
      "01/04 00:35:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7900/100228]  lr: 1.9999e-01  eta: 18 days, 8:25:20  time: 0.6516  data_time: 0.0083  memory: 2524  grad_norm: 0.7463  loss: 3.9064  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.9064\n",
      "01/04 00:36:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7920/100228]  lr: 1.9999e-01  eta: 18 days, 8:24:10  time: 0.6518  data_time: 0.0079  memory: 2524  grad_norm: 0.7164  loss: 3.9800  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9800\n",
      "01/04 00:36:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7940/100228]  lr: 1.9999e-01  eta: 18 days, 8:23:00  time: 0.6519  data_time: 0.0080  memory: 2524  grad_norm: 0.7689  loss: 3.7769  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.7769\n",
      "01/04 00:36:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7960/100228]  lr: 1.9999e-01  eta: 18 days, 8:21:49  time: 0.6517  data_time: 0.0081  memory: 2524  grad_norm: 0.7750  loss: 3.8720  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8720\n",
      "01/04 00:36:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  7980/100228]  lr: 1.9999e-01  eta: 18 days, 8:20:40  time: 0.6519  data_time: 0.0079  memory: 2524  grad_norm: 0.7811  loss: 3.8793  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8793\n",
      "01/04 00:36:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowonly_r50_8xb16-u48-240e_ntu60-xsub-keypoint_20240103_230834\n",
      "01/04 00:36:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8000/100228]  lr: 1.9999e-01  eta: 18 days, 8:19:34  time: 0.6525  data_time: 0.0081  memory: 2524  grad_norm: 0.8760  loss: 3.8772  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8772\n",
      "01/04 00:37:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8020/100228]  lr: 1.9999e-01  eta: 18 days, 8:18:30  time: 0.6525  data_time: 0.0078  memory: 2524  grad_norm: 1.5237  loss: 4.0492  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 4.0492\n",
      "01/04 00:37:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8040/100228]  lr: 1.9999e-01  eta: 18 days, 8:17:24  time: 0.6524  data_time: 0.0084  memory: 2524  grad_norm: 0.7337  loss: 3.9419  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9419\n",
      "01/04 00:37:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8060/100228]  lr: 1.9999e-01  eta: 18 days, 8:16:18  time: 0.6524  data_time: 0.0081  memory: 2524  grad_norm: 0.8105  loss: 4.0439  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0439\n",
      "01/04 00:37:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8080/100228]  lr: 1.9999e-01  eta: 18 days, 8:15:10  time: 0.6519  data_time: 0.0079  memory: 2524  grad_norm: 0.7751  loss: 3.8215  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8215\n",
      "01/04 00:37:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8100/100228]  lr: 1.9999e-01  eta: 18 days, 8:14:01  time: 0.6517  data_time: 0.0079  memory: 2524  grad_norm: 0.7874  loss: 3.8275  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.8275\n",
      "01/04 00:38:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8120/100228]  lr: 1.9999e-01  eta: 18 days, 8:12:52  time: 0.6515  data_time: 0.0081  memory: 2524  grad_norm: 0.8937  loss: 3.9003  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9003\n",
      "01/04 00:38:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8140/100228]  lr: 1.9999e-01  eta: 18 days, 8:11:52  time: 0.6532  data_time: 0.0084  memory: 2524  grad_norm: 0.6483  loss: 3.9960  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9960\n",
      "01/04 00:38:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8160/100228]  lr: 1.9999e-01  eta: 18 days, 8:11:35  time: 0.6604  data_time: 0.0089  memory: 2524  grad_norm: 0.7359  loss: 3.9342  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.9342\n",
      "01/04 00:38:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8180/100228]  lr: 1.9999e-01  eta: 18 days, 8:11:27  time: 0.6618  data_time: 0.0095  memory: 2524  grad_norm: 0.7144  loss: 3.9764  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9764\n",
      "01/04 00:39:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8200/100228]  lr: 1.9999e-01  eta: 18 days, 8:11:25  time: 0.6631  data_time: 0.0095  memory: 2524  grad_norm: 0.7558  loss: 3.8961  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8961\n",
      "01/04 00:39:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8220/100228]  lr: 1.9999e-01  eta: 18 days, 8:11:20  time: 0.6624  data_time: 0.0096  memory: 2524  grad_norm: 0.8016  loss: 3.8269  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8269\n",
      "01/04 00:39:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8240/100228]  lr: 1.9999e-01  eta: 18 days, 8:10:21  time: 0.6531  data_time: 0.0079  memory: 2524  grad_norm: 0.7389  loss: 3.7972  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 3.7972\n",
      "01/04 00:39:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8260/100228]  lr: 1.9999e-01  eta: 18 days, 8:09:27  time: 0.6540  data_time: 0.0087  memory: 2524  grad_norm: 0.6907  loss: 3.8337  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 3.8337\n",
      "01/04 00:39:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8280/100228]  lr: 1.9999e-01  eta: 18 days, 8:08:20  time: 0.6517  data_time: 0.0080  memory: 2524  grad_norm: 0.7327  loss: 4.0149  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0149\n",
      "01/04 00:40:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8300/100228]  lr: 1.9999e-01  eta: 18 days, 8:07:27  time: 0.6540  data_time: 0.0104  memory: 2524  grad_norm: 0.6730  loss: 3.8304  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8304\n",
      "01/04 00:40:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8320/100228]  lr: 1.9999e-01  eta: 18 days, 8:06:20  time: 0.6517  data_time: 0.0082  memory: 2524  grad_norm: 0.7437  loss: 3.9804  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9804\n",
      "01/04 00:40:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8340/100228]  lr: 1.9999e-01  eta: 18 days, 8:05:13  time: 0.6516  data_time: 0.0080  memory: 2524  grad_norm: 0.6798  loss: 3.8858  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.8858\n",
      "01/04 00:40:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8360/100228]  lr: 1.9999e-01  eta: 18 days, 8:04:06  time: 0.6515  data_time: 0.0080  memory: 2524  grad_norm: 0.7428  loss: 3.9395  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9395\n",
      "01/04 00:41:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8380/100228]  lr: 1.9999e-01  eta: 18 days, 8:03:03  time: 0.6522  data_time: 0.0082  memory: 2524  grad_norm: 0.7301  loss: 3.7830  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.7830\n",
      "01/04 00:41:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8400/100228]  lr: 1.9999e-01  eta: 18 days, 8:02:07  time: 0.6535  data_time: 0.0088  memory: 2524  grad_norm: 0.7691  loss: 3.8709  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8709\n",
      "01/04 00:41:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8420/100228]  lr: 1.9999e-01  eta: 18 days, 8:01:11  time: 0.6533  data_time: 0.0085  memory: 2524  grad_norm: 0.7690  loss: 3.8422  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8422\n",
      "01/04 00:41:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8440/100228]  lr: 1.9999e-01  eta: 18 days, 8:00:15  time: 0.6534  data_time: 0.0086  memory: 2524  grad_norm: 0.7244  loss: 3.8386  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8386\n",
      "01/04 00:41:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8460/100228]  lr: 1.9999e-01  eta: 18 days, 7:59:20  time: 0.6534  data_time: 0.0084  memory: 2524  grad_norm: 0.7260  loss: 3.8619  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8619\n",
      "01/04 00:42:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8480/100228]  lr: 1.9999e-01  eta: 18 days, 7:58:19  time: 0.6523  data_time: 0.0083  memory: 2524  grad_norm: 0.7447  loss: 3.9881  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9881\n",
      "01/04 00:42:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8500/100228]  lr: 1.9999e-01  eta: 18 days, 7:57:18  time: 0.6523  data_time: 0.0086  memory: 2524  grad_norm: 0.7991  loss: 3.8957  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8957\n",
      "01/04 00:42:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8520/100228]  lr: 1.9999e-01  eta: 18 days, 7:56:17  time: 0.6523  data_time: 0.0082  memory: 2524  grad_norm: 0.7377  loss: 3.9863  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9863\n",
      "01/04 00:42:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8540/100228]  lr: 1.9999e-01  eta: 18 days, 7:55:15  time: 0.6520  data_time: 0.0079  memory: 2524  grad_norm: 0.7187  loss: 3.8521  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8521\n",
      "01/04 00:42:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8560/100228]  lr: 1.9999e-01  eta: 18 days, 7:54:15  time: 0.6524  data_time: 0.0081  memory: 2524  grad_norm: 0.7851  loss: 3.9076  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9076\n",
      "01/04 00:43:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8580/100228]  lr: 1.9999e-01  eta: 18 days, 7:53:14  time: 0.6522  data_time: 0.0083  memory: 2524  grad_norm: 0.7397  loss: 3.7718  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.7718\n",
      "01/04 00:43:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8600/100228]  lr: 1.9999e-01  eta: 18 days, 7:52:13  time: 0.6521  data_time: 0.0080  memory: 2524  grad_norm: 0.8323  loss: 3.9424  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9424\n",
      "01/04 00:43:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8620/100228]  lr: 1.9999e-01  eta: 18 days, 7:51:12  time: 0.6520  data_time: 0.0080  memory: 2524  grad_norm: 0.7794  loss: 3.8757  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.8757\n",
      "01/04 00:43:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8640/100228]  lr: 1.9999e-01  eta: 18 days, 7:50:11  time: 0.6521  data_time: 0.0088  memory: 2524  grad_norm: 0.6861  loss: 3.8709  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8709\n",
      "01/04 00:44:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8660/100228]  lr: 1.9999e-01  eta: 18 days, 7:49:09  time: 0.6517  data_time: 0.0087  memory: 2524  grad_norm: 0.6673  loss: 3.9258  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.9258\n",
      "01/04 00:44:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8680/100228]  lr: 1.9999e-01  eta: 18 days, 7:48:03  time: 0.6511  data_time: 0.0081  memory: 2524  grad_norm: 0.7743  loss: 3.8781  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.8781\n",
      "01/04 00:44:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8700/100228]  lr: 1.9999e-01  eta: 18 days, 7:46:57  time: 0.6511  data_time: 0.0082  memory: 2524  grad_norm: 0.7256  loss: 3.8448  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8448\n",
      "01/04 00:44:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8720/100228]  lr: 1.9999e-01  eta: 18 days, 7:45:50  time: 0.6506  data_time: 0.0082  memory: 2524  grad_norm: 0.7367  loss: 3.8963  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8963\n",
      "01/04 00:44:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8740/100228]  lr: 1.9999e-01  eta: 18 days, 7:44:46  time: 0.6513  data_time: 0.0084  memory: 2524  grad_norm: 0.7116  loss: 3.9690  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.9690\n",
      "01/04 00:45:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8760/100228]  lr: 1.9999e-01  eta: 18 days, 7:43:53  time: 0.6534  data_time: 0.0088  memory: 2524  grad_norm: 0.7748  loss: 3.9543  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9543\n",
      "01/04 00:45:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8780/100228]  lr: 1.9999e-01  eta: 18 days, 7:42:45  time: 0.6504  data_time: 0.0079  memory: 2524  grad_norm: 0.7239  loss: 3.6476  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.6476\n",
      "01/04 00:45:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8800/100228]  lr: 1.9999e-01  eta: 18 days, 7:41:38  time: 0.6506  data_time: 0.0080  memory: 2524  grad_norm: 0.8035  loss: 3.9992  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.9992\n",
      "01/04 00:45:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8820/100228]  lr: 1.9999e-01  eta: 18 days, 7:40:34  time: 0.6511  data_time: 0.0082  memory: 2524  grad_norm: 0.8095  loss: 3.7808  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.7808\n",
      "01/04 00:46:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8840/100228]  lr: 1.9999e-01  eta: 18 days, 7:39:26  time: 0.6504  data_time: 0.0079  memory: 2524  grad_norm: 0.8431  loss: 3.7492  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 3.7492\n",
      "01/04 00:46:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8860/100228]  lr: 1.9999e-01  eta: 18 days, 7:38:22  time: 0.6510  data_time: 0.0082  memory: 2524  grad_norm: 0.9111  loss: 4.0394  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0394\n",
      "01/04 00:46:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8880/100228]  lr: 1.9999e-01  eta: 18 days, 7:37:20  time: 0.6513  data_time: 0.0080  memory: 2524  grad_norm: 0.7903  loss: 3.8912  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8912\n",
      "01/04 00:46:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8900/100228]  lr: 1.9999e-01  eta: 18 days, 7:36:18  time: 0.6513  data_time: 0.0082  memory: 2524  grad_norm: 0.7536  loss: 3.9991  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9991\n",
      "01/04 00:46:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8920/100228]  lr: 1.9999e-01  eta: 18 days, 7:35:17  time: 0.6515  data_time: 0.0084  memory: 2524  grad_norm: 1.0669  loss: 4.0678  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0678\n",
      "01/04 00:47:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8940/100228]  lr: 1.9999e-01  eta: 18 days, 7:34:13  time: 0.6508  data_time: 0.0081  memory: 2524  grad_norm: 0.8430  loss: 3.8451  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8451\n",
      "01/04 00:47:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8960/100228]  lr: 1.9999e-01  eta: 18 days, 7:33:09  time: 0.6509  data_time: 0.0078  memory: 2524  grad_norm: 0.7607  loss: 3.8117  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 3.8117\n",
      "01/04 00:47:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  8980/100228]  lr: 1.9999e-01  eta: 18 days, 7:32:06  time: 0.6509  data_time: 0.0081  memory: 2524  grad_norm: 0.6909  loss: 3.9489  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9489\n",
      "01/04 00:47:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowonly_r50_8xb16-u48-240e_ntu60-xsub-keypoint_20240103_230834\n",
      "01/04 00:47:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9000/100228]  lr: 1.9999e-01  eta: 18 days, 7:31:05  time: 0.6514  data_time: 0.0084  memory: 2524  grad_norm: 0.7608  loss: 3.8557  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8557\n",
      "01/04 00:47:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9020/100228]  lr: 1.9999e-01  eta: 18 days, 7:30:01  time: 0.6507  data_time: 0.0083  memory: 2524  grad_norm: 0.7040  loss: 3.9778  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9778\n",
      "01/04 00:48:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9040/100228]  lr: 1.9999e-01  eta: 18 days, 7:29:07  time: 0.6525  data_time: 0.0096  memory: 2524  grad_norm: 0.6296  loss: 3.9998  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9998\n",
      "01/04 00:48:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9060/100228]  lr: 1.9999e-01  eta: 18 days, 7:28:09  time: 0.6517  data_time: 0.0089  memory: 2524  grad_norm: 0.6847  loss: 4.0419  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0419\n",
      "01/04 00:48:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9080/100228]  lr: 1.9999e-01  eta: 18 days, 7:27:06  time: 0.6509  data_time: 0.0081  memory: 2524  grad_norm: 0.6751  loss: 3.8282  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8282\n",
      "01/04 00:48:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9100/100228]  lr: 1.9999e-01  eta: 18 days, 7:26:15  time: 0.6529  data_time: 0.0094  memory: 2524  grad_norm: 0.8078  loss: 3.9061  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9061\n",
      "01/04 00:49:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9120/100228]  lr: 1.9999e-01  eta: 18 days, 7:25:18  time: 0.6517  data_time: 0.0086  memory: 2524  grad_norm: 0.7857  loss: 4.1436  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1436\n",
      "01/04 00:49:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9140/100228]  lr: 1.9999e-01  eta: 18 days, 7:24:17  time: 0.6512  data_time: 0.0080  memory: 2524  grad_norm: 0.6947  loss: 4.0555  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0555\n",
      "01/04 00:49:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9160/100228]  lr: 1.9999e-01  eta: 18 days, 7:23:21  time: 0.6518  data_time: 0.0086  memory: 2524  grad_norm: 0.6783  loss: 3.9251  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9251\n",
      "01/04 00:49:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9180/100228]  lr: 1.9999e-01  eta: 18 days, 7:22:31  time: 0.6531  data_time: 0.0097  memory: 2524  grad_norm: 0.8858  loss: 3.8852  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8852\n",
      "01/04 00:49:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9200/100228]  lr: 1.9999e-01  eta: 18 days, 7:21:30  time: 0.6509  data_time: 0.0079  memory: 2524  grad_norm: 0.7748  loss: 3.6796  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.6796\n",
      "01/04 00:50:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9220/100228]  lr: 1.9999e-01  eta: 18 days, 7:20:33  time: 0.6516  data_time: 0.0086  memory: 2524  grad_norm: 0.7929  loss: 3.9536  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9536\n",
      "01/04 00:50:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9240/100228]  lr: 1.9999e-01  eta: 18 days, 7:19:34  time: 0.6513  data_time: 0.0089  memory: 2524  grad_norm: 0.6191  loss: 3.9510  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9510\n",
      "01/04 00:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9260/100228]  lr: 1.9999e-01  eta: 18 days, 7:18:34  time: 0.6509  data_time: 0.0087  memory: 2524  grad_norm: 0.6895  loss: 3.8493  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8493\n",
      "01/04 00:50:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9280/100228]  lr: 1.9999e-01  eta: 18 days, 7:17:35  time: 0.6513  data_time: 0.0085  memory: 2524  grad_norm: 0.6414  loss: 3.8696  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.8696\n",
      "01/04 00:51:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9300/100228]  lr: 1.9999e-01  eta: 18 days, 7:16:40  time: 0.6518  data_time: 0.0086  memory: 2524  grad_norm: 0.7412  loss: 3.8474  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8474\n",
      "01/04 00:51:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9320/100228]  lr: 1.9999e-01  eta: 18 days, 7:15:38  time: 0.6504  data_time: 0.0082  memory: 2524  grad_norm: 0.8652  loss: 3.9454  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9454\n",
      "01/04 00:51:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9340/100228]  lr: 1.9999e-01  eta: 18 days, 7:14:40  time: 0.6512  data_time: 0.0084  memory: 2524  grad_norm: 0.6802  loss: 3.8860  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.8860\n",
      "01/04 00:51:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9360/100228]  lr: 1.9999e-01  eta: 18 days, 7:13:36  time: 0.6500  data_time: 0.0079  memory: 2524  grad_norm: 0.8216  loss: 3.8529  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8529\n",
      "01/04 00:51:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9380/100228]  lr: 1.9999e-01  eta: 18 days, 7:12:33  time: 0.6503  data_time: 0.0079  memory: 2524  grad_norm: 0.6840  loss: 3.8932  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.8932\n",
      "01/04 00:52:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9400/100228]  lr: 1.9999e-01  eta: 18 days, 7:11:32  time: 0.6505  data_time: 0.0085  memory: 2524  grad_norm: 0.6495  loss: 3.8766  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8766\n",
      "01/04 00:52:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9420/100228]  lr: 1.9999e-01  eta: 18 days, 7:10:30  time: 0.6503  data_time: 0.0078  memory: 2524  grad_norm: 0.8024  loss: 4.0465  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 4.0465\n",
      "01/04 00:52:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9440/100228]  lr: 1.9999e-01  eta: 18 days, 7:09:26  time: 0.6498  data_time: 0.0078  memory: 2524  grad_norm: 0.7681  loss: 3.9482  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9482\n",
      "01/04 00:52:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9460/100228]  lr: 1.9999e-01  eta: 18 days, 7:08:23  time: 0.6499  data_time: 0.0077  memory: 2524  grad_norm: 0.8346  loss: 3.7960  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.7960\n",
      "01/04 00:52:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9480/100228]  lr: 1.9999e-01  eta: 18 days, 7:07:24  time: 0.6507  data_time: 0.0079  memory: 2524  grad_norm: 0.7272  loss: 3.7666  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 3.7666\n",
      "01/04 00:53:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9500/100228]  lr: 1.9999e-01  eta: 18 days, 7:06:28  time: 0.6514  data_time: 0.0083  memory: 2524  grad_norm: 0.8372  loss: 3.8796  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8796\n",
      "01/04 00:53:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9520/100228]  lr: 1.9999e-01  eta: 18 days, 7:05:26  time: 0.6501  data_time: 0.0081  memory: 2524  grad_norm: 0.8636  loss: 4.0611  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0611\n",
      "01/04 00:53:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9540/100228]  lr: 1.9999e-01  eta: 18 days, 7:04:28  time: 0.6507  data_time: 0.0081  memory: 2524  grad_norm: 0.9265  loss: 3.9260  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.9260\n",
      "01/04 00:53:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9560/100228]  lr: 1.9999e-01  eta: 18 days, 7:03:26  time: 0.6501  data_time: 0.0082  memory: 2524  grad_norm: 1.6246  loss: 3.9504  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.9504\n",
      "01/04 00:54:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9580/100228]  lr: 1.9999e-01  eta: 18 days, 7:02:22  time: 0.6494  data_time: 0.0077  memory: 2524  grad_norm: 0.9969  loss: 3.9974  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9974\n",
      "01/04 00:54:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9600/100228]  lr: 1.9999e-01  eta: 18 days, 7:01:14  time: 0.6488  data_time: 0.0079  memory: 2524  grad_norm: 0.6971  loss: 3.9465  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9465\n",
      "01/04 00:54:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9620/100228]  lr: 1.9999e-01  eta: 18 days, 7:00:07  time: 0.6489  data_time: 0.0078  memory: 2524  grad_norm: 0.8014  loss: 3.8654  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.8654\n",
      "01/04 00:54:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9640/100228]  lr: 1.9999e-01  eta: 18 days, 6:59:00  time: 0.6487  data_time: 0.0078  memory: 2524  grad_norm: 0.7264  loss: 3.8738  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.8738\n",
      "01/04 00:54:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9660/100228]  lr: 1.9999e-01  eta: 18 days, 6:57:50  time: 0.6483  data_time: 0.0077  memory: 2524  grad_norm: 0.7098  loss: 3.8948  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.8948\n",
      "01/04 00:55:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9680/100228]  lr: 1.9999e-01  eta: 18 days, 6:56:44  time: 0.6487  data_time: 0.0078  memory: 2524  grad_norm: 0.8182  loss: 4.0396  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0396\n",
      "01/04 00:55:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9700/100228]  lr: 1.9999e-01  eta: 18 days, 6:55:37  time: 0.6488  data_time: 0.0079  memory: 2524  grad_norm: 0.7899  loss: 3.8091  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8091\n",
      "01/04 00:55:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9720/100228]  lr: 1.9999e-01  eta: 18 days, 6:54:31  time: 0.6488  data_time: 0.0079  memory: 2524  grad_norm: 0.7215  loss: 3.9372  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 3.9372\n",
      "01/04 00:55:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9740/100228]  lr: 1.9999e-01  eta: 18 days, 6:53:26  time: 0.6489  data_time: 0.0080  memory: 2524  grad_norm: 0.7733  loss: 3.8658  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8658\n",
      "01/04 00:55:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9760/100228]  lr: 1.9999e-01  eta: 18 days, 6:52:17  time: 0.6481  data_time: 0.0078  memory: 2524  grad_norm: 0.7881  loss: 3.9392  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9392\n",
      "01/04 00:56:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9780/100228]  lr: 1.9999e-01  eta: 18 days, 6:51:11  time: 0.6487  data_time: 0.0083  memory: 2524  grad_norm: 0.7695  loss: 3.9205  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9205\n",
      "01/04 00:56:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9800/100228]  lr: 1.9999e-01  eta: 18 days, 6:50:05  time: 0.6487  data_time: 0.0081  memory: 2524  grad_norm: 0.7909  loss: 3.8915  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.8915\n",
      "01/04 00:56:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9820/100228]  lr: 1.9999e-01  eta: 18 days, 6:49:00  time: 0.6489  data_time: 0.0079  memory: 2524  grad_norm: 0.7681  loss: 3.8800  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8800\n",
      "01/04 00:56:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9840/100228]  lr: 1.9999e-01  eta: 18 days, 6:48:06  time: 0.6509  data_time: 0.0100  memory: 2524  grad_norm: 0.7288  loss: 3.9880  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9880\n",
      "01/04 00:57:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9860/100228]  lr: 1.9999e-01  eta: 18 days, 6:47:00  time: 0.6487  data_time: 0.0081  memory: 2524  grad_norm: 0.7458  loss: 3.8734  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 3.8734\n",
      "01/04 00:57:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9880/100228]  lr: 1.9999e-01  eta: 18 days, 6:45:53  time: 0.6482  data_time: 0.0078  memory: 2524  grad_norm: 0.7172  loss: 3.7989  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 3.7989\n",
      "01/04 00:57:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9900/100228]  lr: 1.9999e-01  eta: 18 days, 6:44:46  time: 0.6482  data_time: 0.0079  memory: 2524  grad_norm: 0.7938  loss: 3.8501  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8501\n",
      "01/04 00:57:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9920/100228]  lr: 1.9999e-01  eta: 18 days, 6:43:39  time: 0.6482  data_time: 0.0078  memory: 2524  grad_norm: 0.8043  loss: 3.8542  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8542\n",
      "01/04 00:57:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9940/100228]  lr: 1.9999e-01  eta: 18 days, 6:42:31  time: 0.6480  data_time: 0.0080  memory: 2524  grad_norm: 0.7238  loss: 3.9070  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9070\n",
      "01/04 00:58:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9960/100228]  lr: 1.9999e-01  eta: 18 days, 6:41:21  time: 0.6474  data_time: 0.0079  memory: 2524  grad_norm: 0.7885  loss: 3.7436  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.7436\n",
      "01/04 00:58:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  9980/100228]  lr: 1.9999e-01  eta: 18 days, 6:40:16  time: 0.6485  data_time: 0.0082  memory: 2524  grad_norm: 0.7741  loss: 4.0478  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0478\n",
      "01/04 00:58:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowonly_r50_8xb16-u48-240e_ntu60-xsub-keypoint_20240103_230834\n",
      "01/04 00:58:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10000/100228]  lr: 1.9999e-01  eta: 18 days, 6:39:05  time: 0.6473  data_time: 0.0079  memory: 2524  grad_norm: 0.7295  loss: 4.0635  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0635\n",
      "01/04 00:58:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10020/100228]  lr: 1.9999e-01  eta: 18 days, 6:37:56  time: 0.6474  data_time: 0.0079  memory: 2524  grad_norm: 0.7023  loss: 3.8756  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.8756\n",
      "01/04 00:59:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10040/100228]  lr: 1.9999e-01  eta: 18 days, 6:36:49  time: 0.6479  data_time: 0.0083  memory: 2524  grad_norm: 0.6840  loss: 3.9603  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9603\n",
      "01/04 00:59:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10060/100228]  lr: 1.9999e-01  eta: 18 days, 6:35:44  time: 0.6482  data_time: 0.0082  memory: 2524  grad_norm: 0.8294  loss: 3.7942  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 3.7942\n",
      "01/04 00:59:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10080/100228]  lr: 1.9999e-01  eta: 18 days, 6:34:37  time: 0.6478  data_time: 0.0080  memory: 2524  grad_norm: 0.8430  loss: 3.9113  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9113\n",
      "01/04 00:59:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10100/100228]  lr: 1.9999e-01  eta: 18 days, 6:33:32  time: 0.6483  data_time: 0.0082  memory: 2524  grad_norm: 1.0385  loss: 3.9122  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9122\n",
      "01/04 00:59:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10120/100228]  lr: 1.9999e-01  eta: 18 days, 6:32:24  time: 0.6476  data_time: 0.0078  memory: 2524  grad_norm: 0.8661  loss: 3.8528  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8528\n",
      "01/04 01:00:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10140/100228]  lr: 1.9999e-01  eta: 18 days, 6:31:16  time: 0.6476  data_time: 0.0081  memory: 2524  grad_norm: 0.7328  loss: 3.9552  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9552\n",
      "01/04 01:00:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10160/100228]  lr: 1.9999e-01  eta: 18 days, 6:30:08  time: 0.6474  data_time: 0.0078  memory: 2524  grad_norm: 0.7717  loss: 4.0605  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0605\n",
      "01/04 01:00:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10180/100228]  lr: 1.9999e-01  eta: 18 days, 6:28:57  time: 0.6466  data_time: 0.0077  memory: 2524  grad_norm: 0.6940  loss: 3.9021  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.9021\n",
      "01/04 01:00:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10200/100228]  lr: 1.9999e-01  eta: 18 days, 6:27:50  time: 0.6475  data_time: 0.0078  memory: 2524  grad_norm: 0.7192  loss: 3.9144  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9144\n",
      "01/04 01:00:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10220/100228]  lr: 1.9999e-01  eta: 18 days, 6:26:43  time: 0.6476  data_time: 0.0078  memory: 2524  grad_norm: 0.7074  loss: 3.9568  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 3.9568\n",
      "01/04 01:01:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10240/100228]  lr: 1.9999e-01  eta: 18 days, 6:25:36  time: 0.6475  data_time: 0.0080  memory: 2524  grad_norm: 0.6826  loss: 3.9466  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.9466\n",
      "01/04 01:01:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10260/100228]  lr: 1.9999e-01  eta: 18 days, 6:24:27  time: 0.6469  data_time: 0.0078  memory: 2524  grad_norm: 0.7300  loss: 3.9236  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9236\n",
      "01/04 01:01:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10280/100228]  lr: 1.9999e-01  eta: 18 days, 6:23:25  time: 0.6484  data_time: 0.0078  memory: 2524  grad_norm: 0.7342  loss: 3.9761  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9761\n",
      "01/04 01:01:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10300/100228]  lr: 1.9999e-01  eta: 18 days, 6:22:20  time: 0.6479  data_time: 0.0079  memory: 2524  grad_norm: 0.7606  loss: 3.7011  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.7011\n",
      "01/04 01:02:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10320/100228]  lr: 1.9999e-01  eta: 18 days, 6:21:15  time: 0.6477  data_time: 0.0083  memory: 2524  grad_norm: 0.7176  loss: 3.7339  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 3.7339\n",
      "01/04 01:02:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10340/100228]  lr: 1.9999e-01  eta: 18 days, 6:20:08  time: 0.6471  data_time: 0.0080  memory: 2524  grad_norm: 0.7615  loss: 3.9384  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9384\n",
      "01/04 01:02:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10360/100228]  lr: 1.9999e-01  eta: 18 days, 6:19:03  time: 0.6478  data_time: 0.0085  memory: 2524  grad_norm: 0.7421  loss: 3.9446  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9446\n",
      "01/04 01:02:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10380/100228]  lr: 1.9999e-01  eta: 18 days, 6:17:56  time: 0.6471  data_time: 0.0079  memory: 2524  grad_norm: 0.7621  loss: 3.6461  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.6461\n",
      "01/04 01:02:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10400/100228]  lr: 1.9999e-01  eta: 18 days, 6:16:45  time: 0.6463  data_time: 0.0080  memory: 2524  grad_norm: 0.8162  loss: 3.8574  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8574\n",
      "01/04 01:03:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10420/100228]  lr: 1.9999e-01  eta: 18 days, 6:15:35  time: 0.6463  data_time: 0.0077  memory: 2524  grad_norm: 0.7322  loss: 3.9715  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9715\n",
      "01/04 01:03:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10440/100228]  lr: 1.9999e-01  eta: 18 days, 6:14:25  time: 0.6464  data_time: 0.0078  memory: 2524  grad_norm: 0.7700  loss: 3.7698  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.7698\n",
      "01/04 01:03:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10460/100228]  lr: 1.9999e-01  eta: 18 days, 6:13:13  time: 0.6459  data_time: 0.0079  memory: 2524  grad_norm: 0.7364  loss: 3.9052  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9052\n",
      "01/04 01:03:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10480/100228]  lr: 1.9999e-01  eta: 18 days, 6:12:06  time: 0.6470  data_time: 0.0084  memory: 2524  grad_norm: 0.7029  loss: 3.9197  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9197\n",
      "01/04 01:03:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10500/100228]  lr: 1.9999e-01  eta: 18 days, 6:10:56  time: 0.6461  data_time: 0.0080  memory: 2524  grad_norm: 0.7575  loss: 3.9784  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.9784\n",
      "01/04 01:04:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10520/100228]  lr: 1.9999e-01  eta: 18 days, 6:09:49  time: 0.6469  data_time: 0.0080  memory: 2524  grad_norm: 0.6932  loss: 3.9244  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9244\n",
      "01/04 01:04:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10540/100228]  lr: 1.9999e-01  eta: 18 days, 6:08:40  time: 0.6463  data_time: 0.0080  memory: 2524  grad_norm: 0.7097  loss: 3.8906  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8906\n",
      "01/04 01:04:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10560/100228]  lr: 1.9999e-01  eta: 18 days, 6:07:32  time: 0.6466  data_time: 0.0079  memory: 2524  grad_norm: 0.7642  loss: 4.0903  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0903\n",
      "01/04 01:04:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10580/100228]  lr: 1.9999e-01  eta: 18 days, 6:06:26  time: 0.6467  data_time: 0.0078  memory: 2524  grad_norm: 0.7184  loss: 3.6939  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.6939\n",
      "01/04 01:05:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10600/100228]  lr: 1.9999e-01  eta: 18 days, 6:05:17  time: 0.6463  data_time: 0.0077  memory: 2524  grad_norm: 0.8672  loss: 3.9218  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9218\n",
      "01/04 01:05:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10620/100228]  lr: 1.9999e-01  eta: 18 days, 6:04:16  time: 0.6479  data_time: 0.0099  memory: 2524  grad_norm: 0.7527  loss: 4.0440  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0440\n",
      "01/04 01:05:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10640/100228]  lr: 1.9999e-01  eta: 18 days, 6:03:05  time: 0.6458  data_time: 0.0081  memory: 2524  grad_norm: 0.7599  loss: 3.9412  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9412\n",
      "01/04 01:05:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10660/100228]  lr: 1.9999e-01  eta: 18 days, 6:01:58  time: 0.6466  data_time: 0.0084  memory: 2524  grad_norm: 0.6161  loss: 3.7627  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.7627\n",
      "01/04 01:05:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10680/100228]  lr: 1.9999e-01  eta: 18 days, 6:00:52  time: 0.6467  data_time: 0.0085  memory: 2524  grad_norm: 0.6437  loss: 3.9925  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9925\n",
      "01/04 01:06:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10700/100228]  lr: 1.9999e-01  eta: 18 days, 5:59:45  time: 0.6465  data_time: 0.0081  memory: 2524  grad_norm: 0.6415  loss: 3.8397  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8397\n",
      "01/04 01:06:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10720/100228]  lr: 1.9999e-01  eta: 18 days, 5:58:36  time: 0.6459  data_time: 0.0079  memory: 2524  grad_norm: 0.8444  loss: 4.0001  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0001\n",
      "01/04 01:06:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10740/100228]  lr: 1.9999e-01  eta: 18 days, 5:57:29  time: 0.6463  data_time: 0.0080  memory: 2524  grad_norm: 0.6177  loss: 4.0403  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0403\n",
      "01/04 01:06:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10760/100228]  lr: 1.9999e-01  eta: 18 days, 5:56:24  time: 0.6466  data_time: 0.0080  memory: 2524  grad_norm: 0.7300  loss: 3.8572  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 3.8572\n",
      "01/04 01:06:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10780/100228]  lr: 1.9999e-01  eta: 18 days, 5:55:23  time: 0.6477  data_time: 0.0101  memory: 2524  grad_norm: 0.7598  loss: 4.0693  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0693\n",
      "01/04 01:07:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10800/100228]  lr: 1.9999e-01  eta: 18 days, 5:54:16  time: 0.6461  data_time: 0.0079  memory: 2524  grad_norm: 0.7173  loss: 3.8054  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 3.8054\n",
      "01/04 01:07:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10820/100228]  lr: 1.9999e-01  eta: 18 days, 5:53:07  time: 0.6457  data_time: 0.0079  memory: 2524  grad_norm: 0.7537  loss: 3.8555  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8555\n",
      "01/04 01:07:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10840/100228]  lr: 1.9999e-01  eta: 18 days, 5:51:57  time: 0.6454  data_time: 0.0078  memory: 2524  grad_norm: 0.6672  loss: 4.0981  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0981\n",
      "01/04 01:07:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10860/100228]  lr: 1.9999e-01  eta: 18 days, 5:50:48  time: 0.6458  data_time: 0.0081  memory: 2524  grad_norm: 0.6467  loss: 3.8744  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8744\n",
      "01/04 01:08:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10880/100228]  lr: 1.9999e-01  eta: 18 days, 5:49:38  time: 0.6452  data_time: 0.0079  memory: 2524  grad_norm: 0.6950  loss: 3.8976  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8976\n",
      "01/04 01:08:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10900/100228]  lr: 1.9999e-01  eta: 18 days, 5:48:30  time: 0.6458  data_time: 0.0077  memory: 2524  grad_norm: 0.7922  loss: 3.7410  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.7410\n",
      "01/04 01:08:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10920/100228]  lr: 1.9999e-01  eta: 18 days, 5:47:23  time: 0.6460  data_time: 0.0079  memory: 2524  grad_norm: 0.7742  loss: 3.8970  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 3.8970\n",
      "01/04 01:08:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10940/100228]  lr: 1.9999e-01  eta: 18 days, 5:46:16  time: 0.6459  data_time: 0.0078  memory: 2524  grad_norm: 0.7429  loss: 3.8994  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.8994\n",
      "01/04 01:08:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10960/100228]  lr: 1.9999e-01  eta: 18 days, 5:45:13  time: 0.6466  data_time: 0.0082  memory: 2524  grad_norm: 0.8169  loss: 3.8028  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8028\n",
      "01/04 01:09:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 10980/100228]  lr: 1.9999e-01  eta: 18 days, 5:44:09  time: 0.6465  data_time: 0.0080  memory: 2524  grad_norm: 1.2115  loss: 3.9331  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9331\n",
      "01/04 01:09:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowonly_r50_8xb16-u48-240e_ntu60-xsub-keypoint_20240103_230834\n",
      "01/04 01:09:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11000/100228]  lr: 1.9999e-01  eta: 18 days, 5:43:04  time: 0.6462  data_time: 0.0082  memory: 2524  grad_norm: 0.8603  loss: 3.9967  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.9967\n",
      "01/04 01:09:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11020/100228]  lr: 1.9999e-01  eta: 18 days, 5:42:01  time: 0.6467  data_time: 0.0083  memory: 2524  grad_norm: 0.7415  loss: 4.0087  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0087\n",
      "01/04 01:09:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11040/100228]  lr: 1.9999e-01  eta: 18 days, 5:40:56  time: 0.6461  data_time: 0.0080  memory: 2524  grad_norm: 0.7192  loss: 3.9216  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9216\n",
      "01/04 01:10:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11060/100228]  lr: 1.9999e-01  eta: 18 days, 5:39:51  time: 0.6461  data_time: 0.0079  memory: 2524  grad_norm: 0.7106  loss: 4.0051  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0051\n",
      "01/04 01:10:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11080/100228]  lr: 1.9999e-01  eta: 18 days, 5:38:50  time: 0.6468  data_time: 0.0079  memory: 2524  grad_norm: 0.8439  loss: 3.9165  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9165\n",
      "01/04 01:10:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11100/100228]  lr: 1.9999e-01  eta: 18 days, 5:37:51  time: 0.6474  data_time: 0.0080  memory: 2524  grad_norm: 0.7808  loss: 3.8079  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8079\n",
      "01/04 01:10:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11120/100228]  lr: 1.9999e-01  eta: 18 days, 5:36:52  time: 0.6474  data_time: 0.0083  memory: 2524  grad_norm: 0.8322  loss: 3.9340  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9340\n",
      "01/04 01:10:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11140/100228]  lr: 1.9999e-01  eta: 18 days, 5:35:49  time: 0.6464  data_time: 0.0079  memory: 2524  grad_norm: 0.6917  loss: 3.7873  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.7873\n",
      "01/04 01:11:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11160/100228]  lr: 1.9999e-01  eta: 18 days, 5:34:47  time: 0.6465  data_time: 0.0081  memory: 2524  grad_norm: 0.7698  loss: 3.9867  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9867\n",
      "01/04 01:11:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11180/100228]  lr: 1.9999e-01  eta: 18 days, 5:33:39  time: 0.6452  data_time: 0.0077  memory: 2524  grad_norm: 0.7532  loss: 3.7804  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.7804\n",
      "01/04 01:11:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11200/100228]  lr: 1.9999e-01  eta: 18 days, 5:32:34  time: 0.6457  data_time: 0.0076  memory: 2524  grad_norm: 0.7517  loss: 3.7288  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.7288\n",
      "01/04 01:11:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11220/100228]  lr: 1.9999e-01  eta: 18 days, 5:31:27  time: 0.6453  data_time: 0.0078  memory: 2524  grad_norm: 0.7799  loss: 3.9799  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9799\n",
      "01/04 01:11:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11240/100228]  lr: 1.9999e-01  eta: 18 days, 5:30:23  time: 0.6458  data_time: 0.0080  memory: 2524  grad_norm: 0.7182  loss: 3.8701  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8701\n",
      "01/04 01:12:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11260/100228]  lr: 1.9999e-01  eta: 18 days, 5:29:19  time: 0.6460  data_time: 0.0081  memory: 2524  grad_norm: 0.7324  loss: 3.7493  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 3.7493\n",
      "01/04 01:12:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11280/100228]  lr: 1.9999e-01  eta: 18 days, 5:28:13  time: 0.6454  data_time: 0.0078  memory: 2524  grad_norm: 0.7347  loss: 3.8075  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8075\n",
      "01/04 01:12:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11300/100228]  lr: 1.9999e-01  eta: 18 days, 5:27:11  time: 0.6462  data_time: 0.0080  memory: 2524  grad_norm: 0.7756  loss: 3.9045  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9045\n",
      "01/04 01:12:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11320/100228]  lr: 1.9999e-01  eta: 18 days, 5:26:08  time: 0.6461  data_time: 0.0082  memory: 2524  grad_norm: 0.7479  loss: 3.8872  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8872\n",
      "01/04 01:13:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11340/100228]  lr: 1.9999e-01  eta: 18 days, 5:25:05  time: 0.6459  data_time: 0.0079  memory: 2524  grad_norm: 0.7910  loss: 3.8497  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.8497\n",
      "01/04 01:13:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11360/100228]  lr: 1.9999e-01  eta: 18 days, 5:23:59  time: 0.6452  data_time: 0.0080  memory: 2524  grad_norm: 0.7115  loss: 4.0221  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0221\n",
      "01/04 01:13:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11380/100228]  lr: 1.9999e-01  eta: 18 days, 5:22:54  time: 0.6454  data_time: 0.0082  memory: 2524  grad_norm: 0.6854  loss: 3.9111  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9111\n",
      "01/04 01:13:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11400/100228]  lr: 1.9999e-01  eta: 18 days, 5:21:53  time: 0.6461  data_time: 0.0081  memory: 2524  grad_norm: 0.6859  loss: 3.9015  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9015\n",
      "01/04 01:13:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11420/100228]  lr: 1.9999e-01  eta: 18 days, 5:20:53  time: 0.6467  data_time: 0.0085  memory: 2524  grad_norm: 0.8357  loss: 3.8680  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.8680\n",
      "01/04 01:14:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11440/100228]  lr: 1.9999e-01  eta: 18 days, 5:19:49  time: 0.6453  data_time: 0.0078  memory: 2524  grad_norm: 0.8090  loss: 3.9751  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9751\n",
      "01/04 01:14:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11460/100228]  lr: 1.9999e-01  eta: 18 days, 5:18:46  time: 0.6458  data_time: 0.0080  memory: 2524  grad_norm: 1.1671  loss: 3.9156  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9156\n",
      "01/04 01:14:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11480/100228]  lr: 1.9999e-01  eta: 18 days, 5:17:43  time: 0.6456  data_time: 0.0079  memory: 2524  grad_norm: 0.7338  loss: 3.9501  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9501\n",
      "01/04 01:14:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11500/100228]  lr: 1.9999e-01  eta: 18 days, 5:16:40  time: 0.6458  data_time: 0.0084  memory: 2524  grad_norm: 0.7812  loss: 4.0245  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0245\n",
      "01/04 01:14:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11520/100228]  lr: 1.9999e-01  eta: 18 days, 5:15:37  time: 0.6455  data_time: 0.0079  memory: 2524  grad_norm: 0.6545  loss: 3.8442  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 3.8442\n",
      "01/04 01:15:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11540/100228]  lr: 1.9999e-01  eta: 18 days, 5:14:37  time: 0.6462  data_time: 0.0083  memory: 2524  grad_norm: 0.8942  loss: 3.9745  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9745\n",
      "01/04 01:15:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11560/100228]  lr: 1.9999e-01  eta: 18 days, 5:13:35  time: 0.6457  data_time: 0.0081  memory: 2524  grad_norm: 0.7089  loss: 3.9655  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9655\n",
      "01/04 01:15:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11580/100228]  lr: 1.9999e-01  eta: 18 days, 5:12:35  time: 0.6463  data_time: 0.0079  memory: 2524  grad_norm: 0.8338  loss: 3.9179  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9179\n",
      "01/04 01:15:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11600/100228]  lr: 1.9999e-01  eta: 18 days, 5:11:37  time: 0.6466  data_time: 0.0083  memory: 2524  grad_norm: 0.8996  loss: 4.1155  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1155\n",
      "01/04 01:16:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11620/100228]  lr: 1.9999e-01  eta: 18 days, 5:10:41  time: 0.6471  data_time: 0.0085  memory: 2524  grad_norm: 0.7439  loss: 3.8626  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8626\n",
      "01/04 01:16:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11640/100228]  lr: 1.9999e-01  eta: 18 days, 5:09:41  time: 0.6461  data_time: 0.0077  memory: 2524  grad_norm: 0.7470  loss: 3.9694  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9694\n",
      "01/04 01:16:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11660/100228]  lr: 1.9999e-01  eta: 18 days, 5:08:40  time: 0.6456  data_time: 0.0077  memory: 2524  grad_norm: 0.7126  loss: 3.7970  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.7970\n",
      "01/04 01:16:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11680/100228]  lr: 1.9999e-01  eta: 18 days, 5:07:37  time: 0.6454  data_time: 0.0078  memory: 2524  grad_norm: 0.6487  loss: 3.8357  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8357\n",
      "01/04 01:16:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11700/100228]  lr: 1.9999e-01  eta: 18 days, 5:06:37  time: 0.6459  data_time: 0.0077  memory: 2524  grad_norm: 0.7612  loss: 3.9140  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9140\n",
      "01/04 01:17:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11720/100228]  lr: 1.9999e-01  eta: 18 days, 5:05:38  time: 0.6462  data_time: 0.0079  memory: 2524  grad_norm: 0.7226  loss: 3.9493  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9493\n",
      "01/04 01:17:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11740/100228]  lr: 1.9999e-01  eta: 18 days, 5:04:42  time: 0.6468  data_time: 0.0081  memory: 2524  grad_norm: 0.7186  loss: 3.8703  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8703\n",
      "01/04 01:17:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11760/100228]  lr: 1.9999e-01  eta: 18 days, 5:03:41  time: 0.6454  data_time: 0.0078  memory: 2524  grad_norm: 0.6866  loss: 3.9533  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9533\n",
      "01/04 01:17:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11780/100228]  lr: 1.9999e-01  eta: 18 days, 5:02:40  time: 0.6455  data_time: 0.0078  memory: 2524  grad_norm: 0.7682  loss: 3.8461  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8461\n",
      "01/04 01:17:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11800/100228]  lr: 1.9999e-01  eta: 18 days, 5:01:39  time: 0.6457  data_time: 0.0078  memory: 2524  grad_norm: 0.9023  loss: 3.9285  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9285\n",
      "01/04 01:18:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11820/100228]  lr: 1.9999e-01  eta: 18 days, 5:00:48  time: 0.6479  data_time: 0.0101  memory: 2524  grad_norm: 0.8500  loss: 3.8982  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8982\n",
      "01/04 01:18:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11840/100228]  lr: 1.9999e-01  eta: 18 days, 4:59:49  time: 0.6460  data_time: 0.0082  memory: 2524  grad_norm: 1.4478  loss: 4.1209  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1209\n",
      "01/04 01:18:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11860/100228]  lr: 1.9999e-01  eta: 18 days, 4:58:53  time: 0.6464  data_time: 0.0080  memory: 2524  grad_norm: 0.9633  loss: 4.2337  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2337\n",
      "01/04 01:18:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11880/100228]  lr: 1.9999e-01  eta: 18 days, 4:57:54  time: 0.6460  data_time: 0.0078  memory: 2524  grad_norm: 0.7881  loss: 4.1317  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1317\n",
      "01/04 01:19:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11900/100228]  lr: 1.9999e-01  eta: 18 days, 4:56:56  time: 0.6460  data_time: 0.0082  memory: 2524  grad_norm: 0.6766  loss: 4.2539  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2539\n",
      "01/04 01:19:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11920/100228]  lr: 1.9999e-01  eta: 18 days, 4:55:59  time: 0.6462  data_time: 0.0081  memory: 2524  grad_norm: 0.8288  loss: 4.1517  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1517\n",
      "01/04 01:19:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11940/100228]  lr: 1.9999e-01  eta: 18 days, 4:55:01  time: 0.6460  data_time: 0.0080  memory: 2524  grad_norm: 0.6373  loss: 4.0925  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0925\n",
      "01/04 01:19:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11960/100228]  lr: 1.9999e-01  eta: 18 days, 4:54:02  time: 0.6458  data_time: 0.0079  memory: 2524  grad_norm: 0.6801  loss: 3.9776  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9776\n",
      "01/04 01:19:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 11980/100228]  lr: 1.9999e-01  eta: 18 days, 4:53:08  time: 0.6469  data_time: 0.0084  memory: 2524  grad_norm: 0.7838  loss: 3.9994  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9994\n",
      "01/04 01:20:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowonly_r50_8xb16-u48-240e_ntu60-xsub-keypoint_20240103_230834\n",
      "01/04 01:20:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12000/100228]  lr: 1.9999e-01  eta: 18 days, 4:52:13  time: 0.6465  data_time: 0.0079  memory: 2524  grad_norm: 0.7866  loss: 4.0615  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0615\n",
      "01/04 01:20:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12020/100228]  lr: 1.9999e-01  eta: 18 days, 4:51:19  time: 0.6470  data_time: 0.0083  memory: 2524  grad_norm: 0.6881  loss: 3.9438  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.9438\n",
      "01/04 01:20:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12040/100228]  lr: 1.9999e-01  eta: 18 days, 4:50:22  time: 0.6459  data_time: 0.0079  memory: 2524  grad_norm: 0.7244  loss: 4.0948  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0948\n",
      "01/04 01:20:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12060/100228]  lr: 1.9999e-01  eta: 18 days, 4:49:24  time: 0.6458  data_time: 0.0080  memory: 2524  grad_norm: 0.6810  loss: 3.8956  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8956\n",
      "01/04 01:20:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12080/100228]  lr: 1.9999e-01  eta: 18 days, 4:48:29  time: 0.6465  data_time: 0.0084  memory: 2524  grad_norm: 0.6205  loss: 4.0980  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0980\n",
      "01/04 01:21:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12100/100228]  lr: 1.9999e-01  eta: 18 days, 4:47:31  time: 0.6456  data_time: 0.0079  memory: 2524  grad_norm: 0.6564  loss: 4.0254  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0254\n",
      "01/04 01:21:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12120/100228]  lr: 1.9999e-01  eta: 18 days, 4:46:33  time: 0.6457  data_time: 0.0078  memory: 2524  grad_norm: 0.7546  loss: 4.0416  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0416\n",
      "01/04 01:21:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12140/100228]  lr: 1.9999e-01  eta: 18 days, 4:45:39  time: 0.6466  data_time: 0.0080  memory: 2524  grad_norm: 0.7502  loss: 3.9540  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.9540\n",
      "01/04 01:21:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12160/100228]  lr: 1.9999e-01  eta: 18 days, 4:44:45  time: 0.6468  data_time: 0.0080  memory: 2524  grad_norm: 10.2587  loss: 4.1734  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.1734\n",
      "01/04 01:22:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12180/100228]  lr: 1.9999e-01  eta: 18 days, 4:43:55  time: 0.6476  data_time: 0.0084  memory: 2524  grad_norm: 4.1398  loss: 4.0262  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0262\n",
      "01/04 01:22:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12200/100228]  lr: 1.9999e-01  eta: 18 days, 4:43:04  time: 0.6472  data_time: 0.0078  memory: 2524  grad_norm: 0.6848  loss: 4.0800  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0800\n",
      "01/04 01:22:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12220/100228]  lr: 1.9999e-01  eta: 18 days, 4:42:11  time: 0.6468  data_time: 0.0078  memory: 2524  grad_norm: 0.7244  loss: 3.9969  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 3.9969\n",
      "01/04 01:22:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12240/100228]  lr: 1.9999e-01  eta: 18 days, 4:41:20  time: 0.6473  data_time: 0.0079  memory: 2524  grad_norm: 0.7637  loss: 3.9654  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9654\n",
      "01/04 01:22:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12260/100228]  lr: 1.9999e-01  eta: 18 days, 4:40:32  time: 0.6478  data_time: 0.0078  memory: 2524  grad_norm: 0.7467  loss: 3.9765  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.9765\n",
      "01/04 01:23:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12280/100228]  lr: 1.9999e-01  eta: 18 days, 4:39:43  time: 0.6478  data_time: 0.0083  memory: 2524  grad_norm: 0.7840  loss: 4.0361  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0361\n",
      "01/04 01:23:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12300/100228]  lr: 1.9999e-01  eta: 18 days, 4:38:53  time: 0.6474  data_time: 0.0081  memory: 2524  grad_norm: 0.6521  loss: 4.0082  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 4.0082\n",
      "01/04 01:23:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12320/100228]  lr: 1.9999e-01  eta: 18 days, 4:38:04  time: 0.6476  data_time: 0.0079  memory: 2524  grad_norm: 0.9456  loss: 3.8602  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8602\n",
      "01/04 01:23:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12340/100228]  lr: 1.9999e-01  eta: 18 days, 4:37:15  time: 0.6476  data_time: 0.0081  memory: 2524  grad_norm: 0.7607  loss: 3.9730  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9730\n",
      "01/04 01:24:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12360/100228]  lr: 1.9999e-01  eta: 18 days, 4:36:24  time: 0.6469  data_time: 0.0077  memory: 2524  grad_norm: 0.6659  loss: 3.9189  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9189\n",
      "01/04 01:24:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12380/100228]  lr: 1.9999e-01  eta: 18 days, 4:35:36  time: 0.6477  data_time: 0.0079  memory: 2524  grad_norm: 0.6798  loss: 4.0415  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0415\n",
      "01/04 01:24:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12400/100228]  lr: 1.9999e-01  eta: 18 days, 4:34:53  time: 0.6491  data_time: 0.0084  memory: 2524  grad_norm: 0.6794  loss: 4.0089  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0089\n",
      "01/04 01:24:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12420/100228]  lr: 1.9999e-01  eta: 18 days, 4:34:20  time: 0.6515  data_time: 0.0100  memory: 2524  grad_norm: 0.6872  loss: 3.8716  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8716\n",
      "01/04 01:24:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12440/100228]  lr: 1.9999e-01  eta: 18 days, 4:33:41  time: 0.6501  data_time: 0.0101  memory: 2524  grad_norm: 0.7018  loss: 4.0155  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0155\n",
      "01/04 01:25:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12460/100228]  lr: 1.9999e-01  eta: 18 days, 4:33:14  time: 0.6533  data_time: 0.0086  memory: 2524  grad_norm: 0.6908  loss: 3.9418  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.9418\n",
      "01/04 01:25:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12480/100228]  lr: 1.9999e-01  eta: 18 days, 4:32:32  time: 0.6493  data_time: 0.0085  memory: 2524  grad_norm: 0.7227  loss: 3.9530  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9530\n",
      "01/04 01:25:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12500/100228]  lr: 1.9999e-01  eta: 18 days, 4:31:48  time: 0.6486  data_time: 0.0086  memory: 2524  grad_norm: 0.6450  loss: 4.0308  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0308\n",
      "01/04 01:25:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12520/100228]  lr: 1.9999e-01  eta: 18 days, 4:31:03  time: 0.6484  data_time: 0.0085  memory: 2524  grad_norm: 0.6776  loss: 3.9290  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9290\n",
      "01/04 01:25:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12540/100228]  lr: 1.9999e-01  eta: 18 days, 4:30:48  time: 0.6561  data_time: 0.0089  memory: 2524  grad_norm: 0.6772  loss: 3.9198  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.9198\n",
      "01/04 01:26:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12560/100228]  lr: 1.9999e-01  eta: 18 days, 4:30:38  time: 0.6576  data_time: 0.0096  memory: 2524  grad_norm: 0.7010  loss: 3.8759  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.8759\n",
      "01/04 01:26:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12580/100228]  lr: 1.9999e-01  eta: 18 days, 4:30:07  time: 0.6518  data_time: 0.0099  memory: 2524  grad_norm: 0.7595  loss: 4.0577  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0577\n",
      "01/04 01:26:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12600/100228]  lr: 1.9999e-01  eta: 18 days, 4:29:23  time: 0.6486  data_time: 0.0080  memory: 2524  grad_norm: 0.6987  loss: 3.9959  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9959\n",
      "01/04 01:26:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12620/100228]  lr: 1.9999e-01  eta: 18 days, 4:28:40  time: 0.6489  data_time: 0.0084  memory: 2524  grad_norm: 0.7245  loss: 3.8094  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8094\n",
      "01/04 01:27:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12640/100228]  lr: 1.9999e-01  eta: 18 days, 4:28:01  time: 0.6499  data_time: 0.0085  memory: 2524  grad_norm: 0.6715  loss: 4.0017  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 4.0017\n",
      "01/04 01:27:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12660/100228]  lr: 1.9999e-01  eta: 18 days, 4:27:21  time: 0.6494  data_time: 0.0088  memory: 2524  grad_norm: 0.7317  loss: 3.8193  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8193\n",
      "01/04 01:27:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12680/100228]  lr: 1.9999e-01  eta: 18 days, 4:26:41  time: 0.6496  data_time: 0.0086  memory: 2524  grad_norm: 0.6665  loss: 4.0676  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0676\n",
      "01/04 01:27:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12700/100228]  lr: 1.9999e-01  eta: 18 days, 4:26:02  time: 0.6498  data_time: 0.0083  memory: 2524  grad_norm: 0.8014  loss: 3.7934  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.7934\n",
      "01/04 01:27:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12720/100228]  lr: 1.9999e-01  eta: 18 days, 4:25:26  time: 0.6504  data_time: 0.0084  memory: 2524  grad_norm: 0.8063  loss: 3.8078  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.8078\n",
      "01/04 01:28:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12740/100228]  lr: 1.9999e-01  eta: 18 days, 4:24:43  time: 0.6487  data_time: 0.0084  memory: 2524  grad_norm: 0.7337  loss: 3.9213  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9213\n",
      "01/04 01:28:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12760/100228]  lr: 1.9999e-01  eta: 18 days, 4:24:04  time: 0.6498  data_time: 0.0082  memory: 2524  grad_norm: 0.7575  loss: 3.9683  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9683\n",
      "01/04 01:28:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12780/100228]  lr: 1.9999e-01  eta: 18 days, 4:23:27  time: 0.6500  data_time: 0.0079  memory: 2524  grad_norm: 0.6853  loss: 3.8638  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8638\n",
      "01/04 01:28:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12800/100228]  lr: 1.9999e-01  eta: 18 days, 4:22:43  time: 0.6485  data_time: 0.0080  memory: 2524  grad_norm: 0.7658  loss: 3.9222  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.9222\n",
      "01/04 01:29:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12820/100228]  lr: 1.9999e-01  eta: 18 days, 4:22:01  time: 0.6488  data_time: 0.0083  memory: 2524  grad_norm: 0.7390  loss: 3.8245  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8245\n",
      "01/04 01:29:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12840/100228]  lr: 1.9999e-01  eta: 18 days, 4:21:21  time: 0.6493  data_time: 0.0083  memory: 2524  grad_norm: 0.6285  loss: 4.0202  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0202\n",
      "01/04 01:29:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12860/100228]  lr: 1.9999e-01  eta: 18 days, 4:20:46  time: 0.6507  data_time: 0.0082  memory: 2524  grad_norm: 0.6703  loss: 3.8290  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8290\n",
      "01/04 01:29:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12880/100228]  lr: 1.9999e-01  eta: 18 days, 4:20:06  time: 0.6493  data_time: 0.0082  memory: 2524  grad_norm: 0.7586  loss: 3.7622  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.7622\n",
      "01/04 01:29:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12900/100228]  lr: 1.9999e-01  eta: 18 days, 4:19:30  time: 0.6503  data_time: 0.0089  memory: 2524  grad_norm: 0.7048  loss: 3.9045  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.9045\n",
      "01/04 01:30:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12920/100228]  lr: 1.9999e-01  eta: 18 days, 4:18:51  time: 0.6496  data_time: 0.0085  memory: 2524  grad_norm: 0.7074  loss: 3.9534  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9534\n",
      "01/04 01:30:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12940/100228]  lr: 1.9999e-01  eta: 18 days, 4:18:13  time: 0.6498  data_time: 0.0083  memory: 2524  grad_norm: 0.8075  loss: 3.8021  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.8021\n",
      "01/04 01:30:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12960/100228]  lr: 1.9999e-01  eta: 18 days, 4:17:31  time: 0.6487  data_time: 0.0082  memory: 2524  grad_norm: 0.6950  loss: 3.8721  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8721\n",
      "01/04 01:30:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 12980/100228]  lr: 1.9999e-01  eta: 18 days, 4:16:48  time: 0.6484  data_time: 0.0082  memory: 2524  grad_norm: 0.7247  loss: 3.7628  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.7628\n",
      "01/04 01:30:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowonly_r50_8xb16-u48-240e_ntu60-xsub-keypoint_20240103_230834\n",
      "01/04 01:30:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13000/100228]  lr: 1.9999e-01  eta: 18 days, 4:16:10  time: 0.6495  data_time: 0.0087  memory: 2524  grad_norm: 0.8460  loss: 3.9426  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9426\n",
      "01/04 01:31:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13020/100228]  lr: 1.9999e-01  eta: 18 days, 4:15:32  time: 0.6498  data_time: 0.0080  memory: 2524  grad_norm: 1.1886  loss: 3.9923  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.9923\n",
      "01/04 01:31:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13040/100228]  lr: 1.9999e-01  eta: 18 days, 4:14:50  time: 0.6487  data_time: 0.0083  memory: 2524  grad_norm: 0.7191  loss: 3.8862  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8862\n",
      "01/04 01:31:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13060/100228]  lr: 1.9999e-01  eta: 18 days, 4:14:12  time: 0.6497  data_time: 0.0097  memory: 2524  grad_norm: 0.7006  loss: 3.9984  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.9984\n",
      "01/04 01:31:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13080/100228]  lr: 1.9999e-01  eta: 18 days, 4:13:33  time: 0.6491  data_time: 0.0087  memory: 2524  grad_norm: 0.7016  loss: 3.8828  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8828\n",
      "01/04 01:32:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13100/100228]  lr: 1.9999e-01  eta: 18 days, 4:12:49  time: 0.6480  data_time: 0.0080  memory: 2524  grad_norm: 0.8126  loss: 3.7948  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.7948\n",
      "01/04 01:32:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13120/100228]  lr: 1.9999e-01  eta: 18 days, 4:12:10  time: 0.6493  data_time: 0.0082  memory: 2524  grad_norm: 0.7255  loss: 3.9814  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9814\n",
      "01/04 01:32:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13140/100228]  lr: 1.9999e-01  eta: 18 days, 4:11:28  time: 0.6485  data_time: 0.0084  memory: 2524  grad_norm: 0.7444  loss: 3.6949  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.6949\n",
      "01/04 01:32:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13160/100228]  lr: 1.9999e-01  eta: 18 days, 4:10:51  time: 0.6499  data_time: 0.0084  memory: 2524  grad_norm: 0.7173  loss: 3.9047  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9047\n",
      "01/04 01:32:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13180/100228]  lr: 1.9999e-01  eta: 18 days, 4:10:11  time: 0.6490  data_time: 0.0085  memory: 2524  grad_norm: 0.7366  loss: 3.8124  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.8124\n",
      "01/04 01:33:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13200/100228]  lr: 1.9999e-01  eta: 18 days, 4:09:34  time: 0.6497  data_time: 0.0090  memory: 2524  grad_norm: 0.8230  loss: 3.8282  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.8282\n",
      "01/04 01:33:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13220/100228]  lr: 1.9999e-01  eta: 18 days, 4:08:53  time: 0.6489  data_time: 0.0086  memory: 2524  grad_norm: 0.8052  loss: 3.9381  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9381\n",
      "01/04 01:33:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13240/100228]  lr: 1.9999e-01  eta: 18 days, 4:08:09  time: 0.6477  data_time: 0.0080  memory: 2524  grad_norm: 0.7019  loss: 3.9148  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.9148\n",
      "01/04 01:33:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13260/100228]  lr: 1.9999e-01  eta: 18 days, 4:07:24  time: 0.6476  data_time: 0.0081  memory: 2524  grad_norm: 0.6638  loss: 4.0073  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0073\n",
      "01/04 01:33:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13280/100228]  lr: 1.9998e-01  eta: 18 days, 4:06:43  time: 0.6485  data_time: 0.0089  memory: 2524  grad_norm: 0.7144  loss: 3.9235  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9235\n",
      "01/04 01:34:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13300/100228]  lr: 1.9998e-01  eta: 18 days, 4:05:59  time: 0.6477  data_time: 0.0081  memory: 2524  grad_norm: 0.7071  loss: 3.9331  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9331\n",
      "01/04 01:34:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13320/100228]  lr: 1.9998e-01  eta: 18 days, 4:05:13  time: 0.6470  data_time: 0.0080  memory: 2524  grad_norm: 0.7649  loss: 3.7106  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.7106\n",
      "01/04 01:34:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13340/100228]  lr: 1.9998e-01  eta: 18 days, 4:04:31  time: 0.6484  data_time: 0.0082  memory: 2524  grad_norm: 0.7482  loss: 3.9103  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.9103\n",
      "01/04 01:34:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13360/100228]  lr: 1.9998e-01  eta: 18 days, 4:03:49  time: 0.6481  data_time: 0.0081  memory: 2524  grad_norm: 0.6523  loss: 3.9535  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9535\n",
      "01/04 01:35:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13380/100228]  lr: 1.9998e-01  eta: 18 days, 4:03:11  time: 0.6492  data_time: 0.0088  memory: 2524  grad_norm: 0.6976  loss: 3.9534  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9534\n",
      "01/04 01:35:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13400/100228]  lr: 1.9998e-01  eta: 18 days, 4:02:28  time: 0.6481  data_time: 0.0085  memory: 2524  grad_norm: 0.7777  loss: 3.9134  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 3.9134\n",
      "01/04 01:35:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13420/100228]  lr: 1.9998e-01  eta: 18 days, 4:01:46  time: 0.6480  data_time: 0.0080  memory: 2524  grad_norm: 0.7977  loss: 3.8896  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.8896\n",
      "01/04 01:35:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13440/100228]  lr: 1.9998e-01  eta: 18 days, 4:01:05  time: 0.6484  data_time: 0.0084  memory: 2524  grad_norm: 0.6810  loss: 3.9447  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9447\n",
      "01/04 01:35:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13460/100228]  lr: 1.9998e-01  eta: 18 days, 4:00:32  time: 0.6505  data_time: 0.0086  memory: 2524  grad_norm: 0.7000  loss: 3.7485  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.7485\n",
      "01/04 01:36:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13480/100228]  lr: 1.9998e-01  eta: 18 days, 3:59:51  time: 0.6484  data_time: 0.0089  memory: 2524  grad_norm: 0.8323  loss: 3.8839  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8839\n",
      "01/04 01:36:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13500/100228]  lr: 1.9998e-01  eta: 18 days, 3:59:12  time: 0.6490  data_time: 0.0091  memory: 2524  grad_norm: 0.7623  loss: 3.8926  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8926\n",
      "01/04 01:36:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13520/100228]  lr: 1.9998e-01  eta: 18 days, 3:58:33  time: 0.6489  data_time: 0.0093  memory: 2524  grad_norm: 0.7790  loss: 3.8363  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8363\n",
      "01/04 01:36:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13540/100228]  lr: 1.9998e-01  eta: 18 days, 3:57:56  time: 0.6493  data_time: 0.0088  memory: 2524  grad_norm: 0.7642  loss: 3.9418  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.9418\n",
      "01/04 01:37:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13560/100228]  lr: 1.9998e-01  eta: 18 days, 3:57:15  time: 0.6483  data_time: 0.0079  memory: 2524  grad_norm: 0.7365  loss: 3.9157  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9157\n",
      "01/04 01:37:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13580/100228]  lr: 1.9998e-01  eta: 18 days, 3:56:37  time: 0.6490  data_time: 0.0089  memory: 2524  grad_norm: 0.8142  loss: 3.9071  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9071\n",
      "01/04 01:37:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13600/100228]  lr: 1.9998e-01  eta: 18 days, 3:55:58  time: 0.6488  data_time: 0.0089  memory: 2524  grad_norm: 0.6821  loss: 3.9261  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9261\n",
      "01/04 01:37:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13620/100228]  lr: 1.9998e-01  eta: 18 days, 3:55:15  time: 0.6476  data_time: 0.0081  memory: 2524  grad_norm: 0.6846  loss: 3.9636  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9636\n",
      "01/04 01:37:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13640/100228]  lr: 1.9998e-01  eta: 18 days, 3:54:33  time: 0.6480  data_time: 0.0085  memory: 2524  grad_norm: 0.7716  loss: 3.8463  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8463\n",
      "01/04 01:38:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13660/100228]  lr: 1.9998e-01  eta: 18 days, 3:53:55  time: 0.6489  data_time: 0.0092  memory: 2524  grad_norm: 0.7232  loss: 3.7957  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.7957\n",
      "01/04 01:38:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13680/100228]  lr: 1.9998e-01  eta: 18 days, 3:53:17  time: 0.6489  data_time: 0.0093  memory: 2524  grad_norm: 0.7608  loss: 3.9605  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9605\n",
      "01/04 01:38:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13700/100228]  lr: 1.9998e-01  eta: 18 days, 3:52:39  time: 0.6489  data_time: 0.0089  memory: 2524  grad_norm: 0.7646  loss: 3.7775  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.7775\n",
      "01/04 01:38:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13720/100228]  lr: 1.9998e-01  eta: 18 days, 3:52:00  time: 0.6488  data_time: 0.0085  memory: 2524  grad_norm: 0.7981  loss: 3.8917  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8917\n",
      "01/04 01:38:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13740/100228]  lr: 1.9998e-01  eta: 18 days, 3:51:18  time: 0.6476  data_time: 0.0086  memory: 2524  grad_norm: 0.7693  loss: 3.9894  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.9894\n",
      "01/04 01:39:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13760/100228]  lr: 1.9998e-01  eta: 18 days, 3:50:38  time: 0.6483  data_time: 0.0088  memory: 2524  grad_norm: 0.7097  loss: 3.9160  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9160\n",
      "01/04 01:39:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13780/100228]  lr: 1.9998e-01  eta: 18 days, 3:50:10  time: 0.6520  data_time: 0.0116  memory: 2524  grad_norm: 0.7008  loss: 3.9472  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9472\n",
      "01/04 01:39:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13800/100228]  lr: 1.9998e-01  eta: 18 days, 3:49:32  time: 0.6489  data_time: 0.0091  memory: 2524  grad_norm: 0.7841  loss: 3.8447  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.8447\n",
      "01/04 01:39:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13820/100228]  lr: 1.9998e-01  eta: 18 days, 3:48:51  time: 0.6477  data_time: 0.0082  memory: 2524  grad_norm: 0.7046  loss: 3.9156  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9156\n",
      "01/04 01:40:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13840/100228]  lr: 1.9998e-01  eta: 18 days, 3:48:21  time: 0.6513  data_time: 0.0089  memory: 2524  grad_norm: 0.7606  loss: 3.8770  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8770\n",
      "01/04 01:40:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13860/100228]  lr: 1.9998e-01  eta: 18 days, 3:47:45  time: 0.6494  data_time: 0.0085  memory: 2524  grad_norm: 1.0691  loss: 3.9852  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9852\n",
      "01/04 01:40:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13880/100228]  lr: 1.9998e-01  eta: 18 days, 3:47:05  time: 0.6480  data_time: 0.0086  memory: 2524  grad_norm: 0.7469  loss: 3.8213  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 3.8213\n",
      "01/04 01:40:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13900/100228]  lr: 1.9998e-01  eta: 18 days, 3:46:24  time: 0.6481  data_time: 0.0086  memory: 2524  grad_norm: 0.8051  loss: 3.9841  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9841\n",
      "01/04 01:40:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13920/100228]  lr: 1.9998e-01  eta: 18 days, 3:45:43  time: 0.6477  data_time: 0.0079  memory: 2524  grad_norm: 0.7311  loss: 4.0052  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 4.0052\n",
      "01/04 01:41:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13940/100228]  lr: 1.9998e-01  eta: 18 days, 3:45:04  time: 0.6485  data_time: 0.0084  memory: 2524  grad_norm: 0.7072  loss: 3.9812  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 3.9812\n",
      "01/04 01:41:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13960/100228]  lr: 1.9998e-01  eta: 18 days, 3:44:25  time: 0.6483  data_time: 0.0084  memory: 2524  grad_norm: 0.6896  loss: 3.9569  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9569\n",
      "01/04 01:41:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 13980/100228]  lr: 1.9998e-01  eta: 18 days, 3:43:43  time: 0.6475  data_time: 0.0080  memory: 2524  grad_norm: 0.7458  loss: 3.9572  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9572\n",
      "01/04 01:41:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowonly_r50_8xb16-u48-240e_ntu60-xsub-keypoint_20240103_230834\n",
      "01/04 01:41:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14000/100228]  lr: 1.9998e-01  eta: 18 days, 3:43:03  time: 0.6479  data_time: 0.0081  memory: 2524  grad_norm: 0.6512  loss: 3.8435  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8435\n",
      "01/04 01:41:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14020/100228]  lr: 1.9998e-01  eta: 18 days, 3:42:26  time: 0.6491  data_time: 0.0088  memory: 2524  grad_norm: 0.6370  loss: 4.0907  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 4.0907\n",
      "01/04 01:42:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14040/100228]  lr: 1.9998e-01  eta: 18 days, 3:41:54  time: 0.6503  data_time: 0.0088  memory: 2524  grad_norm: 0.7572  loss: 3.9180  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9180\n",
      "01/04 01:42:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14060/100228]  lr: 1.9998e-01  eta: 18 days, 3:41:16  time: 0.6485  data_time: 0.0082  memory: 2524  grad_norm: 0.8103  loss: 3.7858  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.7858\n",
      "01/04 01:42:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14080/100228]  lr: 1.9998e-01  eta: 18 days, 3:40:50  time: 0.6523  data_time: 0.0103  memory: 2524  grad_norm: 0.7037  loss: 3.8825  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.8825\n",
      "01/04 01:42:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14100/100228]  lr: 1.9998e-01  eta: 18 days, 3:40:38  time: 0.6562  data_time: 0.0095  memory: 2524  grad_norm: 0.7197  loss: 3.8544  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8544\n",
      "01/04 01:43:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14120/100228]  lr: 1.9998e-01  eta: 18 days, 3:40:19  time: 0.6541  data_time: 0.0096  memory: 2524  grad_norm: 0.7401  loss: 3.9306  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9306\n",
      "01/04 01:43:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14140/100228]  lr: 1.9998e-01  eta: 18 days, 3:39:45  time: 0.6496  data_time: 0.0082  memory: 2524  grad_norm: 0.7043  loss: 3.9417  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.9417\n",
      "01/04 01:43:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14160/100228]  lr: 1.9998e-01  eta: 18 days, 3:39:08  time: 0.6489  data_time: 0.0087  memory: 2524  grad_norm: 0.7930  loss: 4.0439  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0439\n",
      "01/04 01:43:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14180/100228]  lr: 1.9998e-01  eta: 18 days, 3:38:32  time: 0.6490  data_time: 0.0088  memory: 2524  grad_norm: 0.7595  loss: 3.7825  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.7825\n",
      "01/04 01:43:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14200/100228]  lr: 1.9998e-01  eta: 18 days, 3:37:52  time: 0.6478  data_time: 0.0081  memory: 2524  grad_norm: 0.7544  loss: 4.1131  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1131\n",
      "01/04 01:44:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14220/100228]  lr: 1.9998e-01  eta: 18 days, 3:37:11  time: 0.6475  data_time: 0.0081  memory: 2524  grad_norm: 0.7365  loss: 3.8806  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8806\n",
      "01/04 01:44:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14240/100228]  lr: 1.9998e-01  eta: 18 days, 3:36:35  time: 0.6492  data_time: 0.0087  memory: 2524  grad_norm: 0.7531  loss: 4.0477  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0477\n",
      "01/04 01:44:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14260/100228]  lr: 1.9998e-01  eta: 18 days, 3:36:06  time: 0.6512  data_time: 0.0084  memory: 2524  grad_norm: 0.6849  loss: 3.7423  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.7423\n",
      "01/04 01:44:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14280/100228]  lr: 1.9998e-01  eta: 18 days, 3:35:25  time: 0.6472  data_time: 0.0080  memory: 2524  grad_norm: 0.7172  loss: 3.9055  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9055\n",
      "01/04 01:45:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14300/100228]  lr: 1.9998e-01  eta: 18 days, 3:34:44  time: 0.6477  data_time: 0.0084  memory: 2524  grad_norm: 0.7475  loss: 3.9597  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9597\n",
      "01/04 01:45:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14320/100228]  lr: 1.9998e-01  eta: 18 days, 3:34:17  time: 0.6514  data_time: 0.0092  memory: 2524  grad_norm: 0.7730  loss: 3.8640  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8640\n",
      "01/04 01:45:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14340/100228]  lr: 1.9998e-01  eta: 18 days, 3:33:41  time: 0.6490  data_time: 0.0093  memory: 2524  grad_norm: 1.0016  loss: 3.6777  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.6777\n",
      "01/04 01:45:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14360/100228]  lr: 1.9998e-01  eta: 18 days, 3:33:03  time: 0.6483  data_time: 0.0087  memory: 2524  grad_norm: 0.8849  loss: 3.9259  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9259\n",
      "01/04 01:45:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14380/100228]  lr: 1.9998e-01  eta: 18 days, 3:32:22  time: 0.6474  data_time: 0.0086  memory: 2524  grad_norm: 0.7167  loss: 3.8448  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8448\n",
      "01/04 01:46:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14400/100228]  lr: 1.9998e-01  eta: 18 days, 3:31:39  time: 0.6468  data_time: 0.0084  memory: 2524  grad_norm: 0.7165  loss: 3.8974  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8974\n",
      "01/04 01:46:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14420/100228]  lr: 1.9998e-01  eta: 18 days, 3:31:04  time: 0.6491  data_time: 0.0092  memory: 2524  grad_norm: 0.8933  loss: 3.8196  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8196\n",
      "01/04 01:46:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14440/100228]  lr: 1.9998e-01  eta: 18 days, 3:30:23  time: 0.6474  data_time: 0.0084  memory: 2524  grad_norm: 0.6962  loss: 3.8737  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.8737\n",
      "01/04 01:46:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14460/100228]  lr: 1.9998e-01  eta: 18 days, 3:29:48  time: 0.6491  data_time: 0.0093  memory: 2524  grad_norm: 0.6872  loss: 3.9866  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9866\n",
      "01/04 01:46:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14480/100228]  lr: 1.9998e-01  eta: 18 days, 3:29:10  time: 0.6481  data_time: 0.0088  memory: 2524  grad_norm: 0.8532  loss: 3.9054  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9054\n",
      "01/04 01:47:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14500/100228]  lr: 1.9998e-01  eta: 18 days, 3:28:34  time: 0.6487  data_time: 0.0087  memory: 2524  grad_norm: 0.8311  loss: 3.7420  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.7420\n",
      "01/04 01:47:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14520/100228]  lr: 1.9998e-01  eta: 18 days, 3:27:55  time: 0.6479  data_time: 0.0088  memory: 2524  grad_norm: 0.7753  loss: 3.7451  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.7451\n",
      "01/04 01:47:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14540/100228]  lr: 1.9998e-01  eta: 18 days, 3:27:23  time: 0.6499  data_time: 0.0087  memory: 2524  grad_norm: 0.8505  loss: 3.8751  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8751\n",
      "01/04 01:47:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14560/100228]  lr: 1.9998e-01  eta: 18 days, 3:26:53  time: 0.6505  data_time: 0.0087  memory: 2524  grad_norm: 0.7679  loss: 3.7206  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.7206\n",
      "01/04 01:48:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14580/100228]  lr: 1.9998e-01  eta: 18 days, 3:26:19  time: 0.6492  data_time: 0.0084  memory: 2524  grad_norm: 0.7261  loss: 3.7986  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.7986\n",
      "01/04 01:48:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14600/100228]  lr: 1.9998e-01  eta: 18 days, 3:25:42  time: 0.6484  data_time: 0.0081  memory: 2524  grad_norm: 0.6978  loss: 3.8486  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.8486\n",
      "01/04 01:48:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14620/100228]  lr: 1.9998e-01  eta: 18 days, 3:25:05  time: 0.6484  data_time: 0.0085  memory: 2524  grad_norm: 0.7616  loss: 3.9067  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9067\n",
      "01/04 01:48:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14640/100228]  lr: 1.9998e-01  eta: 18 days, 3:24:27  time: 0.6481  data_time: 0.0085  memory: 2524  grad_norm: 1.0733  loss: 3.7487  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 3.7487\n",
      "01/04 01:48:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14660/100228]  lr: 1.9998e-01  eta: 18 days, 3:24:09  time: 0.6540  data_time: 0.0089  memory: 2524  grad_norm: 0.7854  loss: 3.9389  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9389\n",
      "01/04 01:49:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14680/100228]  lr: 1.9998e-01  eta: 18 days, 3:24:05  time: 0.6585  data_time: 0.0108  memory: 2524  grad_norm: 0.7418  loss: 3.8674  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8674\n",
      "01/04 01:49:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14700/100228]  lr: 1.9998e-01  eta: 18 days, 3:23:56  time: 0.6567  data_time: 0.0100  memory: 2524  grad_norm: 0.8313  loss: 3.7374  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.7374\n",
      "01/04 01:49:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14720/100228]  lr: 1.9998e-01  eta: 18 days, 3:23:26  time: 0.6507  data_time: 0.0095  memory: 2524  grad_norm: 0.6939  loss: 4.0271  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0271\n",
      "01/04 01:49:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14740/100228]  lr: 1.9998e-01  eta: 18 days, 3:22:46  time: 0.6472  data_time: 0.0083  memory: 2524  grad_norm: 0.7850  loss: 3.9529  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9529\n",
      "01/04 01:49:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14760/100228]  lr: 1.9998e-01  eta: 18 days, 3:22:07  time: 0.6475  data_time: 0.0082  memory: 2524  grad_norm: 0.7720  loss: 3.8017  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.8017\n",
      "01/04 01:50:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14780/100228]  lr: 1.9998e-01  eta: 18 days, 3:21:33  time: 0.6493  data_time: 0.0088  memory: 2524  grad_norm: 1.3855  loss: 3.9120  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9120\n",
      "01/04 01:50:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14800/100228]  lr: 1.9998e-01  eta: 18 days, 3:20:59  time: 0.6492  data_time: 0.0093  memory: 2524  grad_norm: 0.9170  loss: 4.0346  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0346\n",
      "01/04 01:50:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14820/100228]  lr: 1.9998e-01  eta: 18 days, 3:20:27  time: 0.6496  data_time: 0.0088  memory: 2524  grad_norm: 1.0797  loss: 4.2018  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2018\n",
      "01/04 01:50:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14840/100228]  lr: 1.9998e-01  eta: 18 days, 3:19:55  time: 0.6496  data_time: 0.0089  memory: 2524  grad_norm: 0.8719  loss: 3.9756  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9756\n",
      "01/04 01:51:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14860/100228]  lr: 1.9998e-01  eta: 18 days, 3:19:31  time: 0.6524  data_time: 0.0096  memory: 2524  grad_norm: 0.7316  loss: 3.9936  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9936\n",
      "01/04 01:51:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14880/100228]  lr: 1.9998e-01  eta: 18 days, 3:19:18  time: 0.6555  data_time: 0.0106  memory: 2524  grad_norm: 0.9288  loss: 4.1491  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1491\n",
      "01/04 01:51:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14900/100228]  lr: 1.9998e-01  eta: 18 days, 3:18:58  time: 0.6532  data_time: 0.0095  memory: 2524  grad_norm: 0.7299  loss: 3.9958  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9958\n",
      "01/04 01:51:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14920/100228]  lr: 1.9998e-01  eta: 18 days, 3:18:30  time: 0.6511  data_time: 0.0092  memory: 2524  grad_norm: 0.7193  loss: 4.0618  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0618\n",
      "01/04 01:51:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14940/100228]  lr: 1.9998e-01  eta: 18 days, 3:17:58  time: 0.6496  data_time: 0.0092  memory: 2524  grad_norm: 0.6623  loss: 4.1051  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.1051\n",
      "01/04 01:52:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14960/100228]  lr: 1.9998e-01  eta: 18 days, 3:17:34  time: 0.6521  data_time: 0.0091  memory: 2524  grad_norm: 0.7530  loss: 3.9465  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9465\n",
      "01/04 01:52:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 14980/100228]  lr: 1.9998e-01  eta: 18 days, 3:17:04  time: 0.6502  data_time: 0.0094  memory: 2524  grad_norm: 0.6245  loss: 3.9166  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.9166\n",
      "01/04 01:52:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: slowonly_r50_8xb16-u48-240e_ntu60-xsub-keypoint_20240103_230834\n",
      "01/04 01:52:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 15000/100228]  lr: 1.9998e-01  eta: 18 days, 3:16:39  time: 0.6520  data_time: 0.0096  memory: 2524  grad_norm: 0.7737  loss: 3.9618  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.9618\n",
      "01/04 01:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 15020/100228]  lr: 1.9998e-01  eta: 18 days, 3:16:05  time: 0.6489  data_time: 0.0084  memory: 2524  grad_norm: 0.6948  loss: 3.9462  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.9462\n",
      "01/04 01:53:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 15040/100228]  lr: 1.9998e-01  eta: 18 days, 3:15:32  time: 0.6493  data_time: 0.0093  memory: 2524  grad_norm: 0.7287  loss: 3.8500  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 3.8500\n",
      "01/04 01:53:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 15060/100228]  lr: 1.9998e-01  eta: 18 days, 3:14:58  time: 0.6487  data_time: 0.0090  memory: 2524  grad_norm: 0.7748  loss: 3.9658  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9658\n",
      "01/04 01:53:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 15080/100228]  lr: 1.9998e-01  eta: 18 days, 3:14:27  time: 0.6499  data_time: 0.0102  memory: 2524  grad_norm: 0.6928  loss: 3.7497  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.7497\n",
      "01/04 01:53:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 15100/100228]  lr: 1.9998e-01  eta: 18 days, 3:13:54  time: 0.6492  data_time: 0.0085  memory: 2524  grad_norm: 0.7028  loss: 4.0748  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0748\n",
      "01/04 01:53:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 15120/100228]  lr: 1.9998e-01  eta: 18 days, 3:13:16  time: 0.6476  data_time: 0.0085  memory: 2524  grad_norm: 0.7617  loss: 3.9776  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9776\n",
      "01/04 01:54:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 15140/100228]  lr: 1.9998e-01  eta: 18 days, 3:12:41  time: 0.6487  data_time: 0.0085  memory: 2524  grad_norm: 0.7447  loss: 3.9137  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9137\n",
      "01/04 01:54:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 15160/100228]  lr: 1.9998e-01  eta: 18 days, 3:12:16  time: 0.6515  data_time: 0.0090  memory: 2524  grad_norm: 0.8508  loss: 3.9822  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9822\n",
      "01/04 01:54:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 15180/100228]  lr: 1.9998e-01  eta: 18 days, 3:11:40  time: 0.6482  data_time: 0.0083  memory: 2524  grad_norm: 0.6522  loss: 3.9072  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9072\n",
      "01/04 01:54:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 15200/100228]  lr: 1.9998e-01  eta: 18 days, 3:11:10  time: 0.6503  data_time: 0.0104  memory: 2524  grad_norm: 0.7537  loss: 3.8893  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8893\n",
      "01/04 01:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 15220/100228]  lr: 1.9998e-01  eta: 18 days, 3:10:35  time: 0.6485  data_time: 0.0085  memory: 2524  grad_norm: 1.0234  loss: 4.0142  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0142\n",
      "01/04 01:55:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 15240/100228]  lr: 1.9998e-01  eta: 18 days, 3:09:58  time: 0.6478  data_time: 0.0085  memory: 2524  grad_norm: 1.0098  loss: 4.0318  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0318\n",
      "01/04 01:55:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 15260/100228]  lr: 1.9998e-01  eta: 18 days, 3:09:25  time: 0.6489  data_time: 0.0090  memory: 2524  grad_norm: 0.8633  loss: 3.8988  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.8988\n",
      "01/04 01:55:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 15280/100228]  lr: 1.9998e-01  eta: 18 days, 3:08:51  time: 0.6487  data_time: 0.0085  memory: 2524  grad_norm: 1.2484  loss: 4.1176  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1176\n",
      "01/04 01:55:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 15300/100228]  lr: 1.9998e-01  eta: 18 days, 3:08:15  time: 0.6482  data_time: 0.0088  memory: 2524  grad_norm: 0.8732  loss: 4.0583  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0583\n",
      "01/04 01:56:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 15320/100228]  lr: 1.9998e-01  eta: 18 days, 3:07:39  time: 0.6480  data_time: 0.0082  memory: 2524  grad_norm: 0.8078  loss: 3.6927  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.6927\n",
      "01/04 01:56:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 15340/100228]  lr: 1.9998e-01  eta: 18 days, 3:07:07  time: 0.6492  data_time: 0.0095  memory: 2524  grad_norm: 0.7617  loss: 3.9561  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9561\n",
      "01/04 01:56:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 15360/100228]  lr: 1.9998e-01  eta: 18 days, 3:06:31  time: 0.6480  data_time: 0.0090  memory: 2524  grad_norm: 0.7180  loss: 3.9768  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9768\n",
      "01/04 01:56:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 15380/100228]  lr: 1.9998e-01  eta: 18 days, 3:05:55  time: 0.6481  data_time: 0.0081  memory: 2524  grad_norm: 0.6718  loss: 4.0121  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 4.0121\n",
      "01/04 01:56:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 15400/100228]  lr: 1.9998e-01  eta: 18 days, 3:05:18  time: 0.6475  data_time: 0.0083  memory: 2524  grad_norm: 0.7822  loss: 3.8645  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 3.8645\n",
      "01/04 01:57:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 15420/100228]  lr: 1.9998e-01  eta: 18 days, 3:04:42  time: 0.6480  data_time: 0.0082  memory: 2524  grad_norm: 0.7892  loss: 3.9601  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9601\n",
      "01/04 01:57:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 15440/100228]  lr: 1.9998e-01  eta: 18 days, 3:04:06  time: 0.6479  data_time: 0.0086  memory: 2524  grad_norm: 0.9124  loss: 4.1719  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1719\n",
      "01/04 01:57:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 15460/100228]  lr: 1.9998e-01  eta: 18 days, 3:03:32  time: 0.6486  data_time: 0.0085  memory: 2524  grad_norm: 1.1149  loss: 3.8619  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8619\n",
      "01/04 01:57:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 15480/100228]  lr: 1.9998e-01  eta: 18 days, 3:03:06  time: 0.6513  data_time: 0.0085  memory: 2524  grad_norm: 0.7315  loss: 3.8198  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.8198\n",
      "01/04 01:58:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 15500/100228]  lr: 1.9998e-01  eta: 18 days, 3:02:32  time: 0.6485  data_time: 0.0087  memory: 2524  grad_norm: 0.7918  loss: 3.9561  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 3.9561\n",
      "01/04 01:58:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 15520/100228]  lr: 1.9998e-01  eta: 18 days, 3:01:58  time: 0.6485  data_time: 0.0087  memory: 2524  grad_norm: 0.6904  loss: 3.9129  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9129\n",
      "01/04 01:58:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 15540/100228]  lr: 1.9998e-01  eta: 18 days, 3:01:28  time: 0.6497  data_time: 0.0089  memory: 2524  grad_norm: 0.6936  loss: 3.9096  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9096\n",
      "01/04 01:58:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 15560/100228]  lr: 1.9998e-01  eta: 18 days, 3:00:55  time: 0.6488  data_time: 0.0088  memory: 2524  grad_norm: 0.7118  loss: 3.9755  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9755\n",
      "01/04 01:58:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 15580/100228]  lr: 1.9998e-01  eta: 18 days, 3:00:18  time: 0.6475  data_time: 0.0084  memory: 2524  grad_norm: 0.6613  loss: 3.8723  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8723\n",
      "01/04 01:59:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 15600/100228]  lr: 1.9998e-01  eta: 18 days, 2:59:47  time: 0.6496  data_time: 0.0089  memory: 2524  grad_norm: 0.7445  loss: 3.9901  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9901\n",
      "01/04 01:59:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 15620/100228]  lr: 1.9998e-01  eta: 18 days, 2:59:33  time: 0.6549  data_time: 0.0090  memory: 2524  grad_norm: 0.6732  loss: 4.0062  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 4.0062\n",
      "01/04 01:59:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 15640/100228]  lr: 1.9998e-01  eta: 18 days, 2:58:57  time: 0.6476  data_time: 0.0081  memory: 2524  grad_norm: 0.8324  loss: 4.0025  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0025\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"mmaction2/tools/train.py\", line 143, in <module>\n",
      "    main()\n",
      "  File \"mmaction2/tools/train.py\", line 139, in main\n",
      "    runner.train()\n",
      "  File \"/home/aldy/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/runner/runner.py\", line 1777, in train\n",
      "    model = self.train_loop.run()  # type: ignore\n",
      "  File \"/home/aldy/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/runner/loops.py\", line 96, in run\n",
      "    self.run_epoch()\n",
      "  File \"/home/aldy/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/runner/loops.py\", line 112, in run_epoch\n",
      "    self.run_iter(idx, data_batch)\n",
      "  File \"/home/aldy/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/runner/loops.py\", line 128, in run_iter\n",
      "    outputs = self.runner.model.train_step(\n",
      "  File \"/home/aldy/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/model/base_model/base_model.py\", line 116, in train_step\n",
      "    optim_wrapper.update_params(parsed_losses)\n",
      "  File \"/home/aldy/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/optim/optimizer/optimizer_wrapper.py\", line 201, in update_params\n",
      "    self.step(**step_kwargs)\n",
      "  File \"/home/aldy/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/optim/scheduler/param_scheduler.py\", line 115, in wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"/home/aldy/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/optim/optimizer/optimizer_wrapper.py\", line 252, in step\n",
      "    self._clip_grad()\n",
      "  File \"/home/aldy/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/optim/optimizer/optimizer_wrapper.py\", line 298, in _clip_grad\n",
      "    float(grad))\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python mmaction2/tools/train.py mmaction2/configs/skeleton/posec3d/slowonly_r50_8xb16-u48-240e_ntu60-xsub-keypoint.py \\\n",
    "    --work-dir work_dirs/slowonly_r50_8xb16-u48-240e_ntu60-xsub-keypoint \\\n",
    "    --seed 0 \n",
    "    --resume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6244f32-9406-4f93-b9c6-6cdc7557dccf",
   "metadata": {},
   "source": [
    "## Training from python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
