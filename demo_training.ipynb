{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a83e8aa-9403-42e3-ab17-07b34e1e49fa",
   "metadata": {},
   "source": [
    "## Training from bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bdfe89-b1e2-4238-940d-7586d302535a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/13 11:59:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.8.18 (default, Sep 11 2023, 13:40:15) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 0\n",
      "    GPU 0: NVIDIA GeForce GTX 1650 Ti\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 12.3, V12.3.107\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
      "    PyTorch: 2.1.2+cu121\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 12.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.9.2\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.16.2\n",
      "    OpenCV: 4.9.0\n",
      "    MMEngine: 0.10.2\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 0\n",
      "    diff_rank_seed: False\n",
      "    deterministic: False\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "03/13 11:59:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "ann_file = 'data/skeleton/ciis.pkl'\n",
      "dataset_type = 'PoseDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, save_best='auto', type='CheckpointHook'),\n",
      "    logger=dict(ignore_last=False, interval=20, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    runtime_info=dict(type='RuntimeInfoHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    sync_buffers=dict(type='SyncBuffersHook'),\n",
      "    timer=dict(type='IterTimerHook'))\n",
      "default_scope = 'mmaction'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "launcher = 'none'\n",
      "left_kp = [\n",
      "    1,\n",
      "    3,\n",
      "    5,\n",
      "    7,\n",
      "    9,\n",
      "    11,\n",
      "    13,\n",
      "    15,\n",
      "]\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=20)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        base_channels=32,\n",
      "        conv1_stride_s=1,\n",
      "        depth=50,\n",
      "        dilations=(\n",
      "            1,\n",
      "            1,\n",
      "            1,\n",
      "        ),\n",
      "        in_channels=17,\n",
      "        inflate=(\n",
      "            0,\n",
      "            1,\n",
      "            1,\n",
      "        ),\n",
      "        num_stages=3,\n",
      "        out_indices=(2, ),\n",
      "        pool1_stride_s=1,\n",
      "        pretrained=\n",
      "        'https://download.openmmlab.com/mmaction/skeleton/posec3d/posec3d_ava.pth',\n",
      "        spatial_strides=(\n",
      "            2,\n",
      "            2,\n",
      "            2,\n",
      "        ),\n",
      "        stage_blocks=(\n",
      "            4,\n",
      "            6,\n",
      "            3,\n",
      "        ),\n",
      "        temporal_strides=(\n",
      "            1,\n",
      "            1,\n",
      "            2,\n",
      "        ),\n",
      "        type='ResNet3dSlowOnly'),\n",
      "    cls_head=dict(\n",
      "        average_clips='prob',\n",
      "        dropout_ratio=0.5,\n",
      "        in_channels=512,\n",
      "        multi_class=True,\n",
      "        num_classes=11,\n",
      "        spatial_type='avg',\n",
      "        type='I3DHead'),\n",
      "    type='Recognizer3D')\n",
      "optim_wrapper = dict(\n",
      "    clip_grad=dict(max_norm=40, norm_type=2),\n",
      "    optimizer=dict(lr=0.2, momentum=0.9, type='SGD', weight_decay=0.0003))\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        T_max=24,\n",
      "        by_epoch=True,\n",
      "        convert_to_iter_based=True,\n",
      "        eta_min=0,\n",
      "        type='CosineAnnealingLR'),\n",
      "]\n",
      "randomness = dict(deterministic=False, diff_rank_seed=False, seed=0)\n",
      "resume = False\n",
      "right_kp = [\n",
      "    2,\n",
      "    4,\n",
      "    6,\n",
      "    8,\n",
      "    10,\n",
      "    12,\n",
      "    14,\n",
      "    16,\n",
      "]\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='data/skeleton/ciis.pkl',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                clip_len=12,\n",
      "                num_clips=10,\n",
      "                test_mode=True,\n",
      "                type='UniformSampleFrames'),\n",
      "            dict(type='PoseDecode'),\n",
      "            dict(allow_imgpad=True, hw_ratio=1.0, type='PoseCompact'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                64,\n",
      "            ), type='Resize'),\n",
      "            dict(crop_size=64, type='CenterCrop'),\n",
      "            dict(\n",
      "                double=True,\n",
      "                left_kp=[\n",
      "                    1,\n",
      "                    3,\n",
      "                    5,\n",
      "                    7,\n",
      "                    9,\n",
      "                    11,\n",
      "                    13,\n",
      "                    15,\n",
      "                ],\n",
      "                right_kp=[\n",
      "                    2,\n",
      "                    4,\n",
      "                    6,\n",
      "                    8,\n",
      "                    10,\n",
      "                    12,\n",
      "                    14,\n",
      "                    16,\n",
      "                ],\n",
      "                sigma=0.6,\n",
      "                type='GeneratePoseTarget',\n",
      "                use_score=True,\n",
      "                with_kp=True,\n",
      "                with_limb=False),\n",
      "            dict(input_format='NCTHW_Heatmap', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        split='xsub_val',\n",
      "        test_mode=True,\n",
      "        type='PoseDataset'),\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = [\n",
      "    dict(type='AccMetric'),\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(\n",
      "        clip_len=12, num_clips=10, test_mode=True, type='UniformSampleFrames'),\n",
      "    dict(type='PoseDecode'),\n",
      "    dict(allow_imgpad=True, hw_ratio=1.0, type='PoseCompact'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        64,\n",
      "    ), type='Resize'),\n",
      "    dict(crop_size=64, type='CenterCrop'),\n",
      "    dict(\n",
      "        double=True,\n",
      "        left_kp=[\n",
      "            1,\n",
      "            3,\n",
      "            5,\n",
      "            7,\n",
      "            9,\n",
      "            11,\n",
      "            13,\n",
      "            15,\n",
      "        ],\n",
      "        right_kp=[\n",
      "            2,\n",
      "            4,\n",
      "            6,\n",
      "            8,\n",
      "            10,\n",
      "            12,\n",
      "            14,\n",
      "            16,\n",
      "        ],\n",
      "        sigma=0.6,\n",
      "        type='GeneratePoseTarget',\n",
      "        use_score=True,\n",
      "        with_kp=True,\n",
      "        with_limb=False),\n",
      "    dict(input_format='NCTHW_Heatmap', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "train_cfg = dict(\n",
      "    max_epochs=24, type='EpochBasedTrainLoop', val_begin=1, val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_size=4,\n",
      "    dataset=dict(\n",
      "        dataset=dict(\n",
      "            ann_file='data/skeleton/ciis.pkl',\n",
      "            pipeline=[\n",
      "                dict(clip_len=12, type='UniformSampleFrames'),\n",
      "                dict(type='PoseDecode'),\n",
      "                dict(allow_imgpad=True, hw_ratio=1.0, type='PoseCompact'),\n",
      "                dict(scale=(\n",
      "                    -1,\n",
      "                    64,\n",
      "                ), type='Resize'),\n",
      "                dict(area_range=(\n",
      "                    0.56,\n",
      "                    1.0,\n",
      "                ), type='RandomResizedCrop'),\n",
      "                dict(keep_ratio=False, scale=(\n",
      "                    56,\n",
      "                    56,\n",
      "                ), type='Resize'),\n",
      "                dict(\n",
      "                    flip_ratio=0.5,\n",
      "                    left_kp=[\n",
      "                        1,\n",
      "                        3,\n",
      "                        5,\n",
      "                        7,\n",
      "                        9,\n",
      "                        11,\n",
      "                        13,\n",
      "                        15,\n",
      "                    ],\n",
      "                    right_kp=[\n",
      "                        2,\n",
      "                        4,\n",
      "                        6,\n",
      "                        8,\n",
      "                        10,\n",
      "                        12,\n",
      "                        14,\n",
      "                        16,\n",
      "                    ],\n",
      "                    type='Flip'),\n",
      "                dict(\n",
      "                    sigma=0.6,\n",
      "                    type='GeneratePoseTarget',\n",
      "                    use_score=True,\n",
      "                    with_kp=True,\n",
      "                    with_limb=False),\n",
      "                dict(input_format='NCTHW_Heatmap', type='FormatShape'),\n",
      "                dict(type='PackActionInputs'),\n",
      "            ],\n",
      "            split='xsub_train',\n",
      "            type='PoseDataset'),\n",
      "        times=10,\n",
      "        type='RepeatDataset'),\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(clip_len=12, type='UniformSampleFrames'),\n",
      "    dict(type='PoseDecode'),\n",
      "    dict(allow_imgpad=True, hw_ratio=1.0, type='PoseCompact'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        64,\n",
      "    ), type='Resize'),\n",
      "    dict(area_range=(\n",
      "        0.56,\n",
      "        1.0,\n",
      "    ), type='RandomResizedCrop'),\n",
      "    dict(keep_ratio=False, scale=(\n",
      "        56,\n",
      "        56,\n",
      "    ), type='Resize'),\n",
      "    dict(\n",
      "        flip_ratio=0.5,\n",
      "        left_kp=[\n",
      "            1,\n",
      "            3,\n",
      "            5,\n",
      "            7,\n",
      "            9,\n",
      "            11,\n",
      "            13,\n",
      "            15,\n",
      "        ],\n",
      "        right_kp=[\n",
      "            2,\n",
      "            4,\n",
      "            6,\n",
      "            8,\n",
      "            10,\n",
      "            12,\n",
      "            14,\n",
      "            16,\n",
      "        ],\n",
      "        type='Flip'),\n",
      "    dict(\n",
      "        sigma=0.6,\n",
      "        type='GeneratePoseTarget',\n",
      "        use_score=True,\n",
      "        with_kp=True,\n",
      "        with_limb=False),\n",
      "    dict(input_format='NCTHW_Heatmap', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=4,\n",
      "    dataset=dict(\n",
      "        ann_file='data/skeleton/ciis.pkl',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                clip_len=12,\n",
      "                num_clips=1,\n",
      "                test_mode=True,\n",
      "                type='UniformSampleFrames'),\n",
      "            dict(type='PoseDecode'),\n",
      "            dict(allow_imgpad=True, hw_ratio=1.0, type='PoseCompact'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                64,\n",
      "            ), type='Resize'),\n",
      "            dict(crop_size=64, type='CenterCrop'),\n",
      "            dict(\n",
      "                sigma=0.6,\n",
      "                type='GeneratePoseTarget',\n",
      "                use_score=True,\n",
      "                with_kp=True,\n",
      "                with_limb=False),\n",
      "            dict(input_format='NCTHW_Heatmap', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        split='xsub_val',\n",
      "        test_mode=True,\n",
      "        type='PoseDataset'),\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = [\n",
      "    dict(type='AccMetric'),\n",
      "]\n",
      "val_pipeline = [\n",
      "    dict(clip_len=12, num_clips=1, test_mode=True, type='UniformSampleFrames'),\n",
      "    dict(type='PoseDecode'),\n",
      "    dict(allow_imgpad=True, hw_ratio=1.0, type='PoseCompact'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        64,\n",
      "    ), type='Resize'),\n",
      "    dict(crop_size=64, type='CenterCrop'),\n",
      "    dict(\n",
      "        sigma=0.6,\n",
      "        type='GeneratePoseTarget',\n",
      "        use_score=True,\n",
      "        with_kp=True,\n",
      "        with_limb=False),\n",
      "    dict(input_format='NCTHW_Heatmap', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    type='ActionVisualizer', vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = 'work_dirs/ciis'\n",
      "\n",
      "03/13 11:59:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "03/13 11:59:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "03/13 11:59:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 6333 videos remain after valid thresholding\n",
      "03/13 11:59:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 6333 videos remain after valid thresholding\n",
      "03/13 11:59:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: https://download.openmmlab.com/mmaction/skeleton/posec3d/posec3d_ava.pth\n",
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmaction/skeleton/posec3d/posec3d_ava.pth\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: conv1\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: bn1\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer1.0.conv1\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer1.0.bn1\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer1.0.conv2\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer1.0.bn2\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer1.0.conv3\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer1.0.bn3\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer1.0.downsample.0\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer1.0.downsample.1\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer1.1.conv1\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer1.1.bn1\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer1.1.conv2\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer1.1.bn2\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer1.1.conv3\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer1.1.bn3\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer1.2.conv1\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer1.2.bn1\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer1.2.conv2\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer1.2.bn2\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer1.2.conv3\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer1.2.bn3\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer1.3.conv1\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer1.3.bn1\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer1.3.conv2\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer1.3.bn2\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer1.3.conv3\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer1.3.bn3\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.0.conv1\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.0.bn1\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.0.conv2\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.0.bn2\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.0.conv3\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.0.bn3\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.0.downsample.0\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.0.downsample.1\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.1.conv1\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.1.bn1\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.1.conv2\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.1.bn2\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.1.conv3\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.1.bn3\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.2.conv1\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.2.bn1\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.2.conv2\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.2.bn2\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.2.conv3\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.2.bn3\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.3.conv1\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.3.bn1\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.3.conv2\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.3.bn2\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.3.conv3\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.3.bn3\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.4.conv1\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.4.bn1\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.4.conv2\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.4.bn2\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.4.conv3\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.4.bn3\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.5.conv1\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.5.bn1\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.5.conv2\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.5.bn2\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.5.conv3\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer2.5.bn3\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer3.0.conv1\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer3.0.bn1\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer3.0.conv2\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer3.0.bn2\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer3.0.conv3\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer3.0.bn3\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer3.0.downsample.0\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer3.0.downsample.1\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer3.1.conv1\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer3.1.bn1\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer3.1.conv2\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer3.1.bn2\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer3.1.conv3\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer3.1.bn3\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer3.2.conv1\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer3.2.bn1\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer3.2.conv2\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer3.2.bn2\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer3.2.conv3\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Module not exist in the state_dict_r2d: layer3.2.bn3\n",
      "03/13 11:59:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - These parameters in the 2d checkpoint are not loaded: {'backbone.layer1.2.conv2.bn.weight', 'backbone.layer2.4.conv1.bn.bias', 'backbone.layer2.5.conv2.bn.weight', 'backbone.layer1.3.conv3.bn.running_mean', 'backbone.layer3.0.conv3.bn.weight', 'backbone.layer2.5.conv2.bn.running_var', 'backbone.layer2.4.conv3.bn.weight', 'backbone.layer2.0.conv3.bn.running_var', 'backbone.layer2.4.conv2.conv.weight', 'backbone.layer2.5.conv1.bn.num_batches_tracked', 'backbone.layer1.3.conv3.bn.weight', 'backbone.layer2.0.conv3.bn.bias', 'backbone.layer2.0.conv2.bn.running_var', 'backbone.layer2.1.conv2.bn.weight', 'backbone.layer2.4.conv1.bn.weight', 'backbone.layer2.4.conv3.bn.running_mean', 'backbone.layer2.4.conv2.bn.running_mean', 'backbone.layer1.1.conv3.bn.num_batches_tracked', 'backbone.layer2.1.conv1.bn.running_mean', 'backbone.layer1.1.conv2.bn.num_batches_tracked', 'backbone.layer1.0.downsample.bn.num_batches_tracked', 'backbone.layer2.1.conv2.bn.running_mean', 'backbone.layer3.1.conv2.bn.running_var', 'backbone.layer2.1.conv3.bn.running_mean', 'backbone.layer1.2.conv3.bn.num_batches_tracked', 'backbone.layer1.3.conv1.bn.running_var', 'backbone.layer1.3.conv2.bn.num_batches_tracked', 'backbone.layer2.5.conv2.bn.running_mean', 'backbone.layer2.3.conv2.bn.running_var', 'backbone.layer3.2.conv2.bn.running_mean', 'backbone.layer2.3.conv1.bn.running_var', 'backbone.conv1.bn.running_var', 'backbone.layer1.3.conv3.bn.running_var', 'backbone.layer2.5.conv2.conv.weight', 'backbone.layer1.0.conv2.bn.num_batches_tracked', 'backbone.layer1.0.conv1.bn.weight', 'backbone.layer2.1.conv1.bn.bias', 'backbone.layer1.2.conv3.conv.weight', 'backbone.layer1.2.conv2.bn.num_batches_tracked', 'backbone.layer2.3.conv1.bn.bias', 'backbone.layer2.5.conv3.bn.weight', 'backbone.layer3.2.conv2.bn.num_batches_tracked', 'backbone.layer1.3.conv1.bn.weight', 'backbone.layer3.0.conv2.bn.running_var', 'backbone.layer3.2.conv2.bn.bias', 'backbone.layer2.5.conv3.bn.bias', 'backbone.layer3.1.conv2.bn.weight', 'backbone.conv1.bn.weight', 'backbone.layer3.1.conv3.bn.running_mean', 'backbone.layer1.1.conv3.bn.running_mean', 'backbone.layer2.4.conv2.bn.bias', 'backbone.layer3.2.conv3.bn.weight', 'backbone.layer1.3.conv2.conv.weight', 'backbone.layer3.0.downsample.bn.num_batches_tracked', 'backbone.layer3.2.conv2.bn.running_var', 'backbone.layer3.0.downsample.bn.bias', 'backbone.layer1.0.conv3.conv.weight', 'backbone.layer3.0.conv2.bn.running_mean', 'backbone.layer2.0.conv2.conv.weight', 'backbone.layer3.1.conv1.bn.bias', 'backbone.layer2.3.conv3.conv.weight', 'backbone.layer1.2.conv3.bn.bias', 'backbone.layer2.0.conv3.bn.num_batches_tracked', 'backbone.layer2.3.conv1.conv.weight', 'backbone.layer2.1.conv1.bn.num_batches_tracked', 'backbone.layer2.0.downsample.bn.bias', 'backbone.layer2.2.conv3.conv.weight', 'backbone.layer3.1.conv1.bn.running_mean', 'backbone.layer3.2.conv1.bn.num_batches_tracked', 'backbone.layer3.1.conv2.bn.num_batches_tracked', 'backbone.layer2.2.conv3.bn.weight', 'backbone.layer2.1.conv3.bn.bias', 'backbone.layer1.0.downsample.bn.bias', 'backbone.layer2.4.conv1.bn.running_var', 'backbone.layer2.1.conv2.bn.num_batches_tracked', 'backbone.layer3.0.conv2.bn.weight', 'backbone.layer2.4.conv3.bn.num_batches_tracked', 'cls_head.fc_cls.weight', 'backbone.layer2.5.conv2.bn.bias', 'backbone.layer1.1.conv2.bn.running_mean', 'backbone.layer2.0.conv1.bn.bias', 'backbone.layer2.4.conv3.conv.weight', 'backbone.layer1.1.conv1.bn.bias', 'backbone.layer2.2.conv3.bn.running_var', 'backbone.layer1.0.conv2.conv.weight', 'backbone.layer2.0.conv3.bn.running_mean', 'backbone.layer3.1.conv1.bn.weight', 'backbone.layer1.1.conv1.bn.num_batches_tracked', 'backbone.layer1.2.conv1.bn.weight', 'backbone.layer2.0.conv2.bn.running_mean', 'backbone.layer2.1.conv3.bn.num_batches_tracked', 'backbone.layer3.0.downsample.bn.weight', 'backbone.layer2.1.conv2.bn.bias', 'backbone.layer1.3.conv1.conv.weight', 'backbone.layer2.0.downsample.bn.num_batches_tracked', 'backbone.layer2.2.conv1.bn.bias', 'backbone.conv1.conv.weight', 'backbone.layer1.0.conv2.bn.bias', 'backbone.layer2.2.conv2.bn.bias', 'backbone.layer1.1.conv1.bn.running_mean', 'backbone.layer3.2.conv1.conv.weight', 'backbone.layer1.2.conv1.conv.weight', 'backbone.layer1.2.conv2.conv.weight', 'backbone.layer2.0.downsample.bn.running_mean', 'backbone.layer1.1.conv1.bn.weight', 'backbone.layer2.4.conv3.bn.running_var', 'backbone.layer3.0.conv1.bn.running_var', 'backbone.layer2.5.conv3.conv.weight', 'backbone.layer3.1.conv3.bn.num_batches_tracked', 'backbone.layer2.0.conv1.bn.weight', 'backbone.layer3.1.conv3.bn.running_var', 'backbone.layer2.2.conv3.bn.running_mean', 'backbone.layer2.2.conv1.bn.num_batches_tracked', 'backbone.layer3.1.conv1.bn.num_batches_tracked', 'backbone.layer1.3.conv1.bn.num_batches_tracked', 'backbone.layer3.1.conv1.conv.weight', 'backbone.layer1.2.conv1.bn.running_mean', 'backbone.layer2.5.conv2.bn.num_batches_tracked', 'backbone.layer1.1.conv3.bn.bias', 'backbone.layer3.1.conv2.conv.weight', 'backbone.layer3.1.conv2.bn.running_mean', 'backbone.layer2.3.conv3.bn.weight', 'backbone.layer1.3.conv2.bn.running_mean', 'backbone.layer2.1.conv1.conv.weight', 'backbone.layer3.0.conv1.bn.num_batches_tracked', 'backbone.layer3.0.conv3.bn.running_var', 'backbone.layer1.0.conv3.bn.running_mean', 'backbone.layer1.1.conv3.bn.weight', 'backbone.layer3.2.conv3.conv.weight', 'backbone.layer3.0.conv3.conv.weight', 'backbone.layer1.0.downsample.bn.weight', 'backbone.layer2.0.conv1.conv.weight', 'backbone.layer1.2.conv2.bn.running_mean', 'backbone.layer1.3.conv3.bn.num_batches_tracked', 'backbone.layer2.5.conv3.bn.num_batches_tracked', 'backbone.layer2.3.conv1.bn.running_mean', 'backbone.layer1.3.conv1.bn.bias', 'backbone.layer2.1.conv3.bn.weight', 'backbone.layer3.0.conv2.bn.num_batches_tracked', 'backbone.layer2.2.conv2.bn.weight', 'backbone.layer2.2.conv2.bn.running_var', 'backbone.layer1.3.conv2.bn.running_var', 'backbone.layer2.2.conv3.bn.bias', 'backbone.layer1.0.downsample.bn.running_mean', 'backbone.layer3.0.conv1.bn.bias', 'backbone.layer3.0.downsample.bn.running_var', 'backbone.layer3.1.conv1.bn.running_var', 'backbone.layer1.2.conv2.bn.bias', 'backbone.layer2.3.conv1.bn.weight', 'backbone.layer1.0.conv3.bn.num_batches_tracked', 'backbone.layer3.1.conv3.bn.bias', 'backbone.layer3.0.conv3.bn.num_batches_tracked', 'backbone.layer1.1.conv2.bn.weight', 'backbone.layer2.5.conv1.bn.running_mean', 'backbone.layer1.2.conv1.bn.num_batches_tracked', 'backbone.layer3.2.conv3.bn.bias', 'backbone.layer3.0.conv2.conv.weight', 'backbone.layer2.4.conv2.bn.weight', 'backbone.layer2.5.conv1.bn.running_var', 'backbone.layer2.0.conv3.conv.weight', 'backbone.layer1.0.downsample.conv.weight', 'backbone.layer2.3.conv3.bn.bias', 'backbone.layer3.2.conv1.bn.running_var', 'backbone.layer2.1.conv2.bn.running_var', 'backbone.layer2.5.conv1.conv.weight', 'backbone.conv1.bn.bias', 'backbone.layer1.0.conv1.bn.num_batches_tracked', 'backbone.layer2.0.conv2.bn.weight', 'backbone.layer3.2.conv2.conv.weight', 'backbone.layer2.3.conv2.conv.weight', 'backbone.layer2.4.conv2.bn.num_batches_tracked', 'backbone.layer2.4.conv1.bn.running_mean', 'backbone.layer1.1.conv2.conv.weight', 'backbone.layer1.0.conv1.bn.bias', 'backbone.layer3.2.conv2.bn.weight', 'backbone.layer1.0.conv1.bn.running_var', 'backbone.layer2.1.conv3.bn.running_var', 'backbone.layer1.0.conv1.conv.weight', 'backbone.layer3.1.conv2.bn.bias', 'backbone.layer2.3.conv3.bn.running_mean', 'backbone.layer1.2.conv2.bn.running_var', 'backbone.layer2.3.conv3.bn.running_var', 'backbone.layer3.0.conv1.conv.weight', 'backbone.layer2.3.conv2.bn.num_batches_tracked', 'backbone.layer2.2.conv1.bn.running_var', 'backbone.layer2.4.conv1.conv.weight', 'backbone.layer2.3.conv2.bn.running_mean', 'backbone.layer2.2.conv1.bn.running_mean', 'backbone.layer1.1.conv2.bn.running_var', 'backbone.layer1.1.conv1.conv.weight', 'backbone.layer1.1.conv1.bn.running_var', 'backbone.layer1.3.conv3.conv.weight', 'backbone.layer2.0.conv1.bn.num_batches_tracked', 'backbone.layer3.0.conv1.bn.weight', 'backbone.layer1.3.conv2.bn.weight', 'backbone.layer3.2.conv3.bn.running_mean', 'backbone.layer2.5.conv1.bn.weight', 'backbone.layer2.5.conv3.bn.running_var', 'backbone.layer1.0.conv3.bn.running_var', 'backbone.layer2.2.conv2.bn.num_batches_tracked', 'backbone.layer1.0.downsample.bn.running_var', 'backbone.layer3.0.downsample.bn.running_mean', 'backbone.layer3.2.conv3.bn.running_var', 'backbone.layer2.3.conv1.bn.num_batches_tracked', 'backbone.layer2.0.conv2.bn.num_batches_tracked', 'backbone.layer2.1.conv3.conv.weight', 'backbone.layer3.0.conv3.bn.running_mean', 'backbone.layer2.4.conv1.bn.num_batches_tracked', 'backbone.layer3.2.conv1.bn.running_mean', 'cls_head.fc_cls.bias', 'backbone.layer2.5.conv3.bn.running_mean', 'backbone.layer2.3.conv2.bn.weight', 'backbone.conv1.bn.running_mean', 'backbone.layer2.0.conv3.bn.weight', 'backbone.layer3.0.downsample.conv.weight', 'backbone.layer2.0.conv1.bn.running_mean', 'backbone.layer3.0.conv3.bn.bias', 'backbone.layer3.2.conv3.bn.num_batches_tracked', 'backbone.layer1.2.conv3.bn.running_var', 'backbone.layer1.0.conv2.bn.running_mean', 'backbone.layer2.3.conv2.bn.bias', 'backbone.layer1.3.conv3.bn.bias', 'backbone.layer1.0.conv1.bn.running_mean', 'backbone.layer1.1.conv3.bn.running_var', 'backbone.layer3.2.conv1.bn.bias', 'backbone.layer3.0.conv2.bn.bias', 'backbone.layer3.1.conv3.conv.weight', 'backbone.layer2.1.conv2.conv.weight', 'backbone.layer1.2.conv1.bn.bias', 'backbone.layer2.2.conv2.bn.running_mean', 'backbone.layer1.2.conv1.bn.running_var', 'backbone.layer2.1.conv1.bn.running_var', 'backbone.layer1.1.conv2.bn.bias', 'backbone.layer2.0.downsample.bn.running_var', 'backbone.layer2.2.conv1.bn.weight', 'backbone.layer2.1.conv1.bn.weight', 'backbone.layer2.2.conv2.conv.weight', 'backbone.layer1.2.conv3.bn.weight', 'backbone.layer1.1.conv3.conv.weight', 'backbone.layer1.0.conv3.bn.weight', 'backbone.layer1.2.conv3.bn.running_mean', 'backbone.layer2.2.conv3.bn.num_batches_tracked', 'backbone.layer3.2.conv1.bn.weight', 'backbone.layer1.0.conv2.bn.weight', 'backbone.layer2.0.downsample.bn.weight', 'backbone.layer2.0.conv1.bn.running_var', 'backbone.conv1.bn.num_batches_tracked', 'backbone.layer2.0.downsample.conv.weight', 'backbone.layer2.2.conv1.conv.weight', 'backbone.layer2.4.conv2.bn.running_var', 'backbone.layer1.0.conv3.bn.bias', 'backbone.layer2.5.conv1.bn.bias', 'backbone.layer1.0.conv2.bn.running_var', 'backbone.layer2.3.conv3.bn.num_batches_tracked', 'backbone.layer1.3.conv2.bn.bias', 'backbone.layer3.0.conv1.bn.running_mean', 'backbone.layer2.0.conv2.bn.bias', 'backbone.layer3.1.conv3.bn.weight', 'backbone.layer2.4.conv3.bn.bias', 'backbone.layer1.3.conv1.bn.running_mean'}\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "03/13 11:59:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "03/13 11:59:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /home/aldy/Documents/skripsi/posec3d-video-structuralize/work_dirs/ciis.\n",
      "03/13 11:59:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   20/15833]  lr: 2.0000e-01  eta: 18:44:57  time: 0.1776  data_time: 0.0201  memory: 751  grad_norm: 27.6099  loss: 24.5902  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 24.5902\n",
      "03/13 11:59:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   40/15833]  lr: 2.0000e-01  eta: 17:05:47  time: 0.1463  data_time: 0.0043  memory: 751  grad_norm: 7.2931  loss: 11.8580  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 11.8580\n",
      "03/13 11:59:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   60/15833]  lr: 2.0000e-01  eta: 16:33:09  time: 0.1466  data_time: 0.0041  memory: 751  grad_norm: 2.2797  loss: 3.7539  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 3.7539\n",
      "03/13 11:59:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][   80/15833]  lr: 2.0000e-01  eta: 16:16:58  time: 0.1467  data_time: 0.0040  memory: 751  grad_norm: 3.4287  loss: 3.2390  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 3.2390\n",
      "03/13 12:00:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  100/15833]  lr: 2.0000e-01  eta: 16:07:37  time: 0.1470  data_time: 0.0040  memory: 751  grad_norm: 2.6269  loss: 2.8563  top1_acc: 0.0000  top5_acc: 0.7500  loss_cls: 2.8563\n",
      "03/13 12:00:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  120/15833]  lr: 2.0000e-01  eta: 16:01:32  time: 0.1471  data_time: 0.0042  memory: 751  grad_norm: 1.3233  loss: 2.5995  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 2.5995\n",
      "03/13 12:00:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  140/15833]  lr: 2.0000e-01  eta: 15:57:23  time: 0.1474  data_time: 0.0044  memory: 751  grad_norm: 0.7763  loss: 1.8643  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 1.8643\n",
      "03/13 12:00:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  160/15833]  lr: 2.0000e-01  eta: 15:55:22  time: 0.1487  data_time: 0.0048  memory: 751  grad_norm: 0.8383  loss: 2.3069  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.3069\n",
      "03/13 12:00:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  180/15833]  lr: 2.0000e-01  eta: 15:53:46  time: 0.1487  data_time: 0.0047  memory: 751  grad_norm: 0.7097  loss: 2.0891  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 2.0891\n",
      "03/13 12:00:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  200/15833]  lr: 2.0000e-01  eta: 15:51:50  time: 0.1477  data_time: 0.0042  memory: 751  grad_norm: 0.7045  loss: 2.2404  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 2.2404\n",
      "03/13 12:00:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  220/15833]  lr: 2.0000e-01  eta: 15:50:37  time: 0.1483  data_time: 0.0046  memory: 751  grad_norm: 0.5700  loss: 2.2626  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 2.2626\n",
      "03/13 12:00:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  240/15833]  lr: 2.0000e-01  eta: 15:49:41  time: 0.1485  data_time: 0.0043  memory: 751  grad_norm: 0.5371  loss: 2.0849  top1_acc: 0.7500  top5_acc: 0.7500  loss_cls: 2.0849\n",
      "03/13 12:00:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  260/15833]  lr: 2.0000e-01  eta: 15:48:45  time: 0.1483  data_time: 0.0042  memory: 751  grad_norm: 0.5344  loss: 2.0738  top1_acc: 0.7500  top5_acc: 0.7500  loss_cls: 2.0738\n",
      "03/13 12:00:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  280/15833]  lr: 2.0000e-01  eta: 15:47:42  time: 0.1477  data_time: 0.0046  memory: 751  grad_norm: 0.4702  loss: 1.7567  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 1.7567\n",
      "03/13 12:00:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  300/15833]  lr: 2.0000e-01  eta: 15:47:22  time: 0.1491  data_time: 0.0046  memory: 751  grad_norm: 0.6605  loss: 2.2293  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.2293\n",
      "03/13 12:00:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  320/15833]  lr: 2.0000e-01  eta: 15:46:55  time: 0.1487  data_time: 0.0043  memory: 751  grad_norm: 0.6219  loss: 2.1520  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 2.1520\n",
      "03/13 12:00:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  340/15833]  lr: 2.0000e-01  eta: 15:46:23  time: 0.1484  data_time: 0.0043  memory: 751  grad_norm: 0.5683  loss: 2.3149  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 2.3149\n",
      "03/13 12:00:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  360/15833]  lr: 2.0000e-01  eta: 15:46:19  time: 0.1495  data_time: 0.0046  memory: 751  grad_norm: 0.5245  loss: 1.9466  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 1.9466\n",
      "03/13 12:00:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  380/15833]  lr: 2.0000e-01  eta: 15:45:52  time: 0.1484  data_time: 0.0040  memory: 751  grad_norm: 0.5002  loss: 1.9991  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 1.9991\n",
      "03/13 12:00:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  400/15833]  lr: 2.0000e-01  eta: 15:45:38  time: 0.1489  data_time: 0.0043  memory: 751  grad_norm: 0.5249  loss: 2.0832  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 2.0832\n",
      "03/13 12:00:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  420/15833]  lr: 2.0000e-01  eta: 15:45:31  time: 0.1492  data_time: 0.0044  memory: 751  grad_norm: 0.5335  loss: 2.0917  top1_acc: 0.7500  top5_acc: 0.7500  loss_cls: 2.0917\n",
      "03/13 12:00:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  440/15833]  lr: 2.0000e-01  eta: 15:45:09  time: 0.1483  data_time: 0.0040  memory: 751  grad_norm: 0.5727  loss: 2.2888  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 2.2888\n",
      "03/13 12:00:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  460/15833]  lr: 2.0000e-01  eta: 15:44:55  time: 0.1488  data_time: 0.0041  memory: 751  grad_norm: 0.5230  loss: 2.1232  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 2.1232\n",
      "03/13 12:00:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  480/15833]  lr: 2.0000e-01  eta: 15:44:51  time: 0.1493  data_time: 0.0043  memory: 751  grad_norm: 0.5212  loss: 2.0974  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 2.0974\n",
      "03/13 12:01:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  500/15833]  lr: 2.0000e-01  eta: 15:45:56  time: 0.1539  data_time: 0.0069  memory: 751  grad_norm: 0.4624  loss: 1.9954  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 1.9954\n",
      "03/13 12:01:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  520/15833]  lr: 2.0000e-01  eta: 15:46:07  time: 0.1505  data_time: 0.0054  memory: 751  grad_norm: 0.5232  loss: 1.9418  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 1.9418\n",
      "03/13 12:01:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  540/15833]  lr: 2.0000e-01  eta: 15:46:05  time: 0.1497  data_time: 0.0048  memory: 751  grad_norm: 0.5946  loss: 2.2091  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 2.2091\n",
      "03/13 12:01:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  560/15833]  lr: 2.0000e-01  eta: 15:46:07  time: 0.1499  data_time: 0.0050  memory: 751  grad_norm: 0.5486  loss: 2.1406  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 2.1406\n",
      "03/13 12:01:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  580/15833]  lr: 2.0000e-01  eta: 15:46:24  time: 0.1512  data_time: 0.0053  memory: 751  grad_norm: 0.5734  loss: 2.2573  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 2.2573\n",
      "03/13 12:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  600/15833]  lr: 2.0000e-01  eta: 15:46:19  time: 0.1495  data_time: 0.0046  memory: 751  grad_norm: 0.5453  loss: 2.0500  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 2.0500\n",
      "03/13 12:01:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  620/15833]  lr: 2.0000e-01  eta: 15:46:13  time: 0.1494  data_time: 0.0045  memory: 751  grad_norm: 0.4833  loss: 2.0331  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 2.0331\n",
      "03/13 12:01:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  640/15833]  lr: 2.0000e-01  eta: 15:46:12  time: 0.1498  data_time: 0.0047  memory: 751  grad_norm: 0.5464  loss: 1.9818  top1_acc: 0.0000  top5_acc: 0.7500  loss_cls: 1.9818\n",
      "03/13 12:01:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  660/15833]  lr: 2.0000e-01  eta: 15:46:03  time: 0.1491  data_time: 0.0046  memory: 751  grad_norm: 0.5699  loss: 2.1826  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 2.1826\n",
      "03/13 12:01:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  680/15833]  lr: 2.0000e-01  eta: 15:45:57  time: 0.1494  data_time: 0.0047  memory: 751  grad_norm: 0.5755  loss: 2.2439  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 2.2439\n",
      "03/13 12:01:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  700/15833]  lr: 2.0000e-01  eta: 15:45:59  time: 0.1501  data_time: 0.0049  memory: 751  grad_norm: 0.5698  loss: 2.1354  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.1354\n",
      "03/13 12:01:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  720/15833]  lr: 2.0000e-01  eta: 15:45:56  time: 0.1497  data_time: 0.0047  memory: 751  grad_norm: 0.5946  loss: 2.2210  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.2210\n",
      "03/13 12:01:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  740/15833]  lr: 2.0000e-01  eta: 15:45:53  time: 0.1496  data_time: 0.0047  memory: 751  grad_norm: 0.4536  loss: 1.8510  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8510\n",
      "03/13 12:01:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  760/15833]  lr: 2.0000e-01  eta: 15:46:00  time: 0.1507  data_time: 0.0056  memory: 751  grad_norm: 0.5856  loss: 2.3268  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 2.3268\n",
      "03/13 12:01:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  780/15833]  lr: 2.0000e-01  eta: 15:46:15  time: 0.1515  data_time: 0.0056  memory: 751  grad_norm: 0.5594  loss: 2.1865  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.1865\n",
      "03/13 12:01:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  800/15833]  lr: 2.0000e-01  eta: 15:46:26  time: 0.1512  data_time: 0.0052  memory: 751  grad_norm: 0.5310  loss: 1.9213  top1_acc: 0.7500  top5_acc: 0.7500  loss_cls: 1.9213\n",
      "03/13 12:01:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  820/15833]  lr: 2.0000e-01  eta: 15:46:28  time: 0.1502  data_time: 0.0048  memory: 751  grad_norm: 0.6744  loss: 2.0734  top1_acc: 0.7500  top5_acc: 0.7500  loss_cls: 2.0734\n",
      "03/13 12:01:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  840/15833]  lr: 2.0000e-01  eta: 15:46:25  time: 0.1498  data_time: 0.0048  memory: 751  grad_norm: 0.5094  loss: 1.9963  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 1.9963\n",
      "03/13 12:01:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  860/15833]  lr: 2.0000e-01  eta: 15:46:28  time: 0.1504  data_time: 0.0053  memory: 751  grad_norm: 0.5749  loss: 2.1672  top1_acc: 0.7500  top5_acc: 0.7500  loss_cls: 2.1672\n",
      "03/13 12:01:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  880/15833]  lr: 2.0000e-01  eta: 15:46:26  time: 0.1499  data_time: 0.0051  memory: 751  grad_norm: 0.5292  loss: 2.0058  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 2.0058\n",
      "03/13 12:02:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  900/15833]  lr: 2.0000e-01  eta: 15:46:26  time: 0.1501  data_time: 0.0048  memory: 751  grad_norm: 0.5866  loss: 2.1390  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 2.1390\n",
      "03/13 12:02:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  920/15833]  lr: 2.0000e-01  eta: 15:46:28  time: 0.1504  data_time: 0.0050  memory: 751  grad_norm: 0.5635  loss: 2.1975  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 2.1975\n",
      "03/13 12:02:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  940/15833]  lr: 2.0000e-01  eta: 15:46:26  time: 0.1500  data_time: 0.0049  memory: 751  grad_norm: 0.6365  loss: 2.2595  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 2.2595\n",
      "03/13 12:02:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  960/15833]  lr: 2.0000e-01  eta: 15:46:29  time: 0.1506  data_time: 0.0052  memory: 751  grad_norm: 0.5560  loss: 2.2208  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 2.2208\n",
      "03/13 12:02:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  980/15833]  lr: 2.0000e-01  eta: 15:46:30  time: 0.1503  data_time: 0.0051  memory: 751  grad_norm: 0.5781  loss: 1.9926  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 1.9926\n",
      "03/13 12:02:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: ciis_20240313_115942\n",
      "03/13 12:02:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1000/15833]  lr: 2.0000e-01  eta: 15:46:42  time: 0.1518  data_time: 0.0060  memory: 751  grad_norm: 0.5189  loss: 2.0952  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 2.0952\n",
      "03/13 12:02:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1020/15833]  lr: 2.0000e-01  eta: 15:46:43  time: 0.1505  data_time: 0.0053  memory: 751  grad_norm: 0.5492  loss: 2.0922  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.0922\n",
      "03/13 12:02:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1040/15833]  lr: 2.0000e-01  eta: 15:46:38  time: 0.1496  data_time: 0.0048  memory: 751  grad_norm: 0.5521  loss: 2.1304  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 2.1304\n",
      "03/13 12:02:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1060/15833]  lr: 2.0000e-01  eta: 15:46:30  time: 0.1491  data_time: 0.0046  memory: 751  grad_norm: 0.5755  loss: 2.1718  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.1718\n",
      "03/13 12:02:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1080/15833]  lr: 2.0000e-01  eta: 15:46:23  time: 0.1493  data_time: 0.0046  memory: 751  grad_norm: 0.5718  loss: 2.0225  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.0225\n",
      "03/13 12:02:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1100/15833]  lr: 2.0000e-01  eta: 15:46:36  time: 0.1522  data_time: 0.0060  memory: 751  grad_norm: 0.5486  loss: 2.0739  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 2.0739\n",
      "03/13 12:02:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1120/15833]  lr: 2.0000e-01  eta: 15:46:32  time: 0.1497  data_time: 0.0048  memory: 751  grad_norm: 0.5237  loss: 2.1374  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.1374\n",
      "03/13 12:02:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1140/15833]  lr: 2.0000e-01  eta: 15:46:41  time: 0.1518  data_time: 0.0054  memory: 751  grad_norm: 0.5962  loss: 2.2269  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 2.2269\n",
      "03/13 12:02:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1160/15833]  lr: 2.0000e-01  eta: 15:46:41  time: 0.1504  data_time: 0.0052  memory: 751  grad_norm: 0.5675  loss: 2.1583  top1_acc: 0.0000  top5_acc: 0.7500  loss_cls: 2.1583\n",
      "03/13 12:02:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1180/15833]  lr: 2.0000e-01  eta: 15:46:36  time: 0.1495  data_time: 0.0047  memory: 751  grad_norm: 0.5963  loss: 2.2975  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 2.2975\n",
      "03/13 12:02:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1200/15833]  lr: 2.0000e-01  eta: 15:46:37  time: 0.1506  data_time: 0.0053  memory: 751  grad_norm: 0.5583  loss: 2.0896  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 2.0896\n",
      "03/13 12:02:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1220/15833]  lr: 1.9999e-01  eta: 15:46:25  time: 0.1485  data_time: 0.0043  memory: 751  grad_norm: 0.5430  loss: 2.0634  top1_acc: 0.0000  top5_acc: 0.7500  loss_cls: 2.0634\n",
      "03/13 12:02:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1240/15833]  lr: 1.9999e-01  eta: 15:46:31  time: 0.1513  data_time: 0.0056  memory: 751  grad_norm: 0.5449  loss: 1.7860  top1_acc: 0.7500  top5_acc: 0.7500  loss_cls: 1.7860\n",
      "03/13 12:02:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1260/15833]  lr: 1.9999e-01  eta: 15:46:29  time: 0.1501  data_time: 0.0049  memory: 751  grad_norm: 0.6427  loss: 2.0696  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 2.0696\n",
      "03/13 12:02:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1280/15833]  lr: 1.9999e-01  eta: 15:46:18  time: 0.1487  data_time: 0.0044  memory: 751  grad_norm: 0.5770  loss: 1.9856  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 1.9856\n",
      "03/13 12:03:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1300/15833]  lr: 1.9999e-01  eta: 15:46:10  time: 0.1491  data_time: 0.0045  memory: 751  grad_norm: 0.5582  loss: 2.2094  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.2094\n",
      "03/13 12:03:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1320/15833]  lr: 1.9999e-01  eta: 15:46:03  time: 0.1492  data_time: 0.0042  memory: 751  grad_norm: 0.5138  loss: 1.9911  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 1.9911\n",
      "03/13 12:03:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1340/15833]  lr: 1.9999e-01  eta: 15:45:56  time: 0.1492  data_time: 0.0044  memory: 751  grad_norm: 0.5899  loss: 2.1310  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 2.1310\n",
      "03/13 12:03:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1360/15833]  lr: 1.9999e-01  eta: 15:45:48  time: 0.1489  data_time: 0.0043  memory: 751  grad_norm: 0.4950  loss: 2.1459  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 2.1459\n",
      "03/13 12:03:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1380/15833]  lr: 1.9999e-01  eta: 15:45:40  time: 0.1490  data_time: 0.0044  memory: 751  grad_norm: 0.5178  loss: 1.9183  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.9183\n",
      "03/13 12:03:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1400/15833]  lr: 1.9999e-01  eta: 15:45:33  time: 0.1490  data_time: 0.0043  memory: 751  grad_norm: 0.5203  loss: 1.8282  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 1.8282\n",
      "03/13 12:03:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1420/15833]  lr: 1.9999e-01  eta: 15:45:33  time: 0.1505  data_time: 0.0046  memory: 751  grad_norm: 0.6379  loss: 2.1822  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.1822\n",
      "03/13 12:03:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1440/15833]  lr: 1.9999e-01  eta: 15:45:39  time: 0.1514  data_time: 0.0054  memory: 751  grad_norm: 0.5885  loss: 1.9399  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 1.9399\n",
      "03/13 12:03:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1460/15833]  lr: 1.9999e-01  eta: 15:45:31  time: 0.1489  data_time: 0.0043  memory: 751  grad_norm: 0.6552  loss: 2.2564  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 2.2564\n",
      "03/13 12:03:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1480/15833]  lr: 1.9999e-01  eta: 15:45:25  time: 0.1494  data_time: 0.0044  memory: 751  grad_norm: 0.6743  loss: 2.1145  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 2.1145\n",
      "03/13 12:03:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1500/15833]  lr: 1.9999e-01  eta: 15:45:20  time: 0.1493  data_time: 0.0045  memory: 751  grad_norm: 0.6001  loss: 2.0358  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 2.0358\n",
      "03/13 12:03:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1520/15833]  lr: 1.9999e-01  eta: 15:45:12  time: 0.1489  data_time: 0.0044  memory: 751  grad_norm: 0.5027  loss: 1.9525  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 1.9525\n",
      "03/13 12:03:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1540/15833]  lr: 1.9999e-01  eta: 15:45:07  time: 0.1494  data_time: 0.0046  memory: 751  grad_norm: 0.6049  loss: 2.1588  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 2.1588\n",
      "03/13 12:03:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1560/15833]  lr: 1.9999e-01  eta: 15:45:05  time: 0.1501  data_time: 0.0049  memory: 751  grad_norm: 0.5552  loss: 2.1529  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 2.1529\n",
      "03/13 12:03:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1580/15833]  lr: 1.9999e-01  eta: 15:44:59  time: 0.1492  data_time: 0.0046  memory: 751  grad_norm: 0.5978  loss: 2.2031  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 2.2031\n",
      "03/13 12:03:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1600/15833]  lr: 1.9999e-01  eta: 15:44:52  time: 0.1491  data_time: 0.0045  memory: 751  grad_norm: 0.5546  loss: 2.0719  top1_acc: 0.0000  top5_acc: 0.7500  loss_cls: 2.0719\n",
      "03/13 12:03:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1620/15833]  lr: 1.9999e-01  eta: 15:44:46  time: 0.1492  data_time: 0.0044  memory: 751  grad_norm: 0.6219  loss: 2.1371  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 2.1371\n",
      "03/13 12:03:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1640/15833]  lr: 1.9999e-01  eta: 15:44:41  time: 0.1492  data_time: 0.0045  memory: 751  grad_norm: 0.5402  loss: 2.1506  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 2.1506\n",
      "03/13 12:03:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1660/15833]  lr: 1.9999e-01  eta: 15:44:36  time: 0.1495  data_time: 0.0045  memory: 751  grad_norm: 0.5994  loss: 1.9804  top1_acc: 0.7500  top5_acc: 0.7500  loss_cls: 1.9804\n",
      "03/13 12:03:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1680/15833]  lr: 1.9999e-01  eta: 15:44:30  time: 0.1491  data_time: 0.0044  memory: 751  grad_norm: 0.5418  loss: 1.8360  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8360\n",
      "03/13 12:04:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1700/15833]  lr: 1.9999e-01  eta: 15:44:25  time: 0.1493  data_time: 0.0046  memory: 751  grad_norm: 0.5828  loss: 1.9648  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 1.9648\n",
      "03/13 12:04:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1720/15833]  lr: 1.9999e-01  eta: 15:44:20  time: 0.1494  data_time: 0.0046  memory: 751  grad_norm: 0.5831  loss: 2.0181  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 2.0181\n",
      "03/13 12:04:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1740/15833]  lr: 1.9999e-01  eta: 15:44:13  time: 0.1489  data_time: 0.0042  memory: 751  grad_norm: 0.5147  loss: 2.0351  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 2.0351\n",
      "03/13 12:04:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1760/15833]  lr: 1.9999e-01  eta: 15:44:04  time: 0.1484  data_time: 0.0043  memory: 751  grad_norm: 0.5352  loss: 1.9265  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 1.9265\n",
      "03/13 12:04:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1780/15833]  lr: 1.9999e-01  eta: 15:43:58  time: 0.1489  data_time: 0.0043  memory: 751  grad_norm: 0.6723  loss: 2.2360  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 2.2360\n",
      "03/13 12:04:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1800/15833]  lr: 1.9999e-01  eta: 15:43:52  time: 0.1491  data_time: 0.0044  memory: 751  grad_norm: 0.5462  loss: 1.8685  top1_acc: 0.7500  top5_acc: 0.7500  loss_cls: 1.8685\n",
      "03/13 12:04:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1820/15833]  lr: 1.9999e-01  eta: 15:43:46  time: 0.1490  data_time: 0.0045  memory: 751  grad_norm: 0.5668  loss: 2.1121  top1_acc: 0.0000  top5_acc: 0.7500  loss_cls: 2.1121\n",
      "03/13 12:04:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1840/15833]  lr: 1.9999e-01  eta: 15:43:41  time: 0.1492  data_time: 0.0043  memory: 751  grad_norm: 0.6422  loss: 2.0414  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.0414\n",
      "03/13 12:04:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1860/15833]  lr: 1.9999e-01  eta: 15:43:36  time: 0.1493  data_time: 0.0044  memory: 751  grad_norm: 0.6182  loss: 2.1614  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 2.1614\n",
      "03/13 12:04:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1880/15833]  lr: 1.9999e-01  eta: 15:43:30  time: 0.1491  data_time: 0.0043  memory: 751  grad_norm: 0.6303  loss: 2.0490  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 2.0490\n",
      "03/13 12:04:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1900/15833]  lr: 1.9999e-01  eta: 15:43:25  time: 0.1491  data_time: 0.0045  memory: 751  grad_norm: 0.5978  loss: 1.9400  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.9400\n",
      "03/13 12:04:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1920/15833]  lr: 1.9999e-01  eta: 15:43:21  time: 0.1496  data_time: 0.0047  memory: 751  grad_norm: 0.6139  loss: 2.1822  top1_acc: 0.0000  top5_acc: 0.7500  loss_cls: 2.1822\n",
      "03/13 12:04:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1940/15833]  lr: 1.9999e-01  eta: 15:43:19  time: 0.1500  data_time: 0.0053  memory: 751  grad_norm: 0.6429  loss: 2.1548  top1_acc: 0.0000  top5_acc: 0.7500  loss_cls: 2.1548\n",
      "03/13 12:04:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1960/15833]  lr: 1.9999e-01  eta: 15:43:15  time: 0.1494  data_time: 0.0047  memory: 751  grad_norm: 0.6111  loss: 2.1929  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 2.1929\n",
      "03/13 12:04:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 1980/15833]  lr: 1.9999e-01  eta: 15:43:10  time: 0.1490  data_time: 0.0045  memory: 751  grad_norm: 0.5889  loss: 2.0900  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 2.0900\n",
      "03/13 12:04:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: ciis_20240313_115942\n",
      "03/13 12:04:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2000/15833]  lr: 1.9999e-01  eta: 15:43:04  time: 0.1489  data_time: 0.0043  memory: 751  grad_norm: 0.6260  loss: 2.1084  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.1084\n",
      "03/13 12:04:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2020/15833]  lr: 1.9999e-01  eta: 15:42:55  time: 0.1483  data_time: 0.0041  memory: 751  grad_norm: 0.5454  loss: 1.8491  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 1.8491\n",
      "03/13 12:04:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2040/15833]  lr: 1.9999e-01  eta: 15:42:49  time: 0.1486  data_time: 0.0043  memory: 751  grad_norm: 0.6565  loss: 2.1755  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.1755\n",
      "03/13 12:04:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2060/15833]  lr: 1.9999e-01  eta: 15:42:44  time: 0.1493  data_time: 0.0048  memory: 751  grad_norm: 0.6212  loss: 2.0564  top1_acc: 0.7500  top5_acc: 0.7500  loss_cls: 2.0564\n",
      "03/13 12:04:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2080/15833]  lr: 1.9999e-01  eta: 15:42:37  time: 0.1484  data_time: 0.0043  memory: 751  grad_norm: 0.6770  loss: 2.1199  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 2.1199\n",
      "03/13 12:04:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2100/15833]  lr: 1.9998e-01  eta: 15:42:30  time: 0.1487  data_time: 0.0045  memory: 751  grad_norm: 0.7522  loss: 2.2265  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 2.2265\n",
      "03/13 12:05:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2120/15833]  lr: 1.9998e-01  eta: 15:42:28  time: 0.1497  data_time: 0.0047  memory: 751  grad_norm: 0.6231  loss: 2.1132  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 2.1132\n",
      "03/13 12:05:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2140/15833]  lr: 1.9998e-01  eta: 15:42:21  time: 0.1486  data_time: 0.0044  memory: 751  grad_norm: 0.5381  loss: 1.8522  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 1.8522\n",
      "03/13 12:05:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2160/15833]  lr: 1.9998e-01  eta: 15:42:17  time: 0.1493  data_time: 0.0047  memory: 751  grad_norm: 0.5115  loss: 1.7604  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 1.7604\n",
      "03/13 12:05:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2180/15833]  lr: 1.9998e-01  eta: 15:42:12  time: 0.1490  data_time: 0.0043  memory: 751  grad_norm: 0.6022  loss: 2.1569  top1_acc: 0.7500  top5_acc: 0.7500  loss_cls: 2.1569\n",
      "03/13 12:05:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2200/15833]  lr: 1.9998e-01  eta: 15:42:07  time: 0.1492  data_time: 0.0046  memory: 751  grad_norm: 0.6160  loss: 1.7336  top1_acc: 0.7500  top5_acc: 0.7500  loss_cls: 1.7336\n",
      "03/13 12:05:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2220/15833]  lr: 1.9998e-01  eta: 15:42:02  time: 0.1489  data_time: 0.0044  memory: 751  grad_norm: 1.0916  loss: 1.9387  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 1.9387\n",
      "03/13 12:05:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2240/15833]  lr: 1.9998e-01  eta: 15:41:58  time: 0.1492  data_time: 0.0045  memory: 751  grad_norm: 0.6005  loss: 2.2165  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 2.2165\n",
      "03/13 12:05:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2260/15833]  lr: 1.9998e-01  eta: 15:41:53  time: 0.1491  data_time: 0.0045  memory: 751  grad_norm: 0.5565  loss: 1.9819  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 1.9819\n",
      "03/13 12:05:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2280/15833]  lr: 1.9998e-01  eta: 15:41:47  time: 0.1486  data_time: 0.0043  memory: 751  grad_norm: 0.5760  loss: 2.0087  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 2.0087\n",
      "03/13 12:05:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2300/15833]  lr: 1.9998e-01  eta: 15:41:42  time: 0.1491  data_time: 0.0045  memory: 751  grad_norm: 0.5617  loss: 1.9635  top1_acc: 0.7500  top5_acc: 0.7500  loss_cls: 1.9635\n",
      "03/13 12:05:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2320/15833]  lr: 1.9998e-01  eta: 15:41:38  time: 0.1492  data_time: 0.0045  memory: 751  grad_norm: 0.4733  loss: 2.1320  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.1320\n",
      "03/13 12:05:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2340/15833]  lr: 1.9998e-01  eta: 15:41:35  time: 0.1498  data_time: 0.0048  memory: 751  grad_norm: 0.5089  loss: 2.0791  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 2.0791\n",
      "03/13 12:05:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2360/15833]  lr: 1.9998e-01  eta: 15:41:31  time: 0.1492  data_time: 0.0044  memory: 751  grad_norm: 0.5850  loss: 2.0237  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 2.0237\n",
      "03/13 12:05:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2380/15833]  lr: 1.9998e-01  eta: 15:41:27  time: 0.1493  data_time: 0.0044  memory: 751  grad_norm: 0.7211  loss: 2.2351  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.2351\n",
      "03/13 12:05:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2400/15833]  lr: 1.9998e-01  eta: 15:41:27  time: 0.1504  data_time: 0.0051  memory: 751  grad_norm: 0.4789  loss: 2.1467  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 2.1467\n",
      "03/13 12:05:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2420/15833]  lr: 1.9998e-01  eta: 15:41:23  time: 0.1494  data_time: 0.0045  memory: 751  grad_norm: 0.4928  loss: 2.0076  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.0076\n",
      "03/13 12:05:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2440/15833]  lr: 1.9998e-01  eta: 15:41:18  time: 0.1488  data_time: 0.0044  memory: 751  grad_norm: 0.5414  loss: 2.2023  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 2.2023\n",
      "03/13 12:05:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2460/15833]  lr: 1.9998e-01  eta: 15:41:15  time: 0.1496  data_time: 0.0047  memory: 751  grad_norm: 0.5433  loss: 2.2513  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 2.2513\n",
      "03/13 12:05:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2480/15833]  lr: 1.9998e-01  eta: 15:41:13  time: 0.1500  data_time: 0.0048  memory: 751  grad_norm: 0.6335  loss: 1.9462  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 1.9462\n",
      "03/13 12:05:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2500/15833]  lr: 1.9998e-01  eta: 15:41:15  time: 0.1514  data_time: 0.0064  memory: 751  grad_norm: 0.6105  loss: 2.1992  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 2.1992\n",
      "03/13 12:06:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2520/15833]  lr: 1.9998e-01  eta: 15:41:13  time: 0.1497  data_time: 0.0045  memory: 751  grad_norm: 0.5928  loss: 2.2116  top1_acc: 0.7500  top5_acc: 0.7500  loss_cls: 2.2116\n",
      "03/13 12:06:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2540/15833]  lr: 1.9998e-01  eta: 15:41:08  time: 0.1492  data_time: 0.0044  memory: 751  grad_norm: 0.4789  loss: 1.8559  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 1.8559\n",
      "03/13 12:06:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2560/15833]  lr: 1.9998e-01  eta: 15:41:06  time: 0.1498  data_time: 0.0047  memory: 751  grad_norm: 0.5071  loss: 2.0634  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 2.0634\n",
      "03/13 12:06:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2580/15833]  lr: 1.9998e-01  eta: 15:41:03  time: 0.1496  data_time: 0.0046  memory: 751  grad_norm: 0.5932  loss: 2.2327  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.2327\n",
      "03/13 12:06:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2600/15833]  lr: 1.9998e-01  eta: 15:41:00  time: 0.1497  data_time: 0.0049  memory: 751  grad_norm: 0.6296  loss: 2.2647  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.2647\n",
      "03/13 12:06:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2620/15833]  lr: 1.9998e-01  eta: 15:40:59  time: 0.1502  data_time: 0.0052  memory: 751  grad_norm: 0.5050  loss: 1.9842  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 1.9842\n",
      "03/13 12:06:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2640/15833]  lr: 1.9998e-01  eta: 15:40:55  time: 0.1494  data_time: 0.0045  memory: 751  grad_norm: 0.5517  loss: 2.1976  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 2.1976\n",
      "03/13 12:06:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2660/15833]  lr: 1.9998e-01  eta: 15:40:51  time: 0.1494  data_time: 0.0045  memory: 751  grad_norm: 0.5155  loss: 1.8754  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 1.8754\n",
      "03/13 12:06:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2680/15833]  lr: 1.9998e-01  eta: 15:40:47  time: 0.1491  data_time: 0.0045  memory: 751  grad_norm: 0.6807  loss: 2.1050  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.1050\n",
      "03/13 12:06:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2700/15833]  lr: 1.9998e-01  eta: 15:40:50  time: 0.1517  data_time: 0.0066  memory: 751  grad_norm: 0.4548  loss: 1.9595  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 1.9595\n",
      "03/13 12:06:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2720/15833]  lr: 1.9997e-01  eta: 15:40:43  time: 0.1483  data_time: 0.0044  memory: 751  grad_norm: 0.5346  loss: 1.8173  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 1.8173\n",
      "03/13 12:06:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2740/15833]  lr: 1.9997e-01  eta: 15:40:38  time: 0.1488  data_time: 0.0043  memory: 751  grad_norm: 0.5694  loss: 1.8940  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 1.8940\n",
      "03/13 12:06:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2760/15833]  lr: 1.9997e-01  eta: 15:40:33  time: 0.1489  data_time: 0.0046  memory: 751  grad_norm: 0.5211  loss: 1.9764  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 1.9764\n",
      "03/13 12:06:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2780/15833]  lr: 1.9997e-01  eta: 15:40:29  time: 0.1493  data_time: 0.0047  memory: 751  grad_norm: 0.6408  loss: 2.1375  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 2.1375\n",
      "03/13 12:06:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2800/15833]  lr: 1.9997e-01  eta: 15:40:25  time: 0.1492  data_time: 0.0046  memory: 751  grad_norm: 0.5942  loss: 2.0626  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 2.0626\n",
      "03/13 12:06:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2820/15833]  lr: 1.9997e-01  eta: 15:40:21  time: 0.1491  data_time: 0.0045  memory: 751  grad_norm: 0.5596  loss: 1.9586  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 1.9586\n",
      "03/13 12:06:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2840/15833]  lr: 1.9997e-01  eta: 15:40:15  time: 0.1485  data_time: 0.0043  memory: 751  grad_norm: 0.5522  loss: 2.1768  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 2.1768\n",
      "03/13 12:06:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2860/15833]  lr: 1.9997e-01  eta: 15:40:11  time: 0.1492  data_time: 0.0047  memory: 751  grad_norm: 0.5409  loss: 2.0185  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 2.0185\n",
      "03/13 12:06:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2880/15833]  lr: 1.9997e-01  eta: 15:40:07  time: 0.1493  data_time: 0.0045  memory: 751  grad_norm: 0.6446  loss: 2.2205  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.2205\n",
      "03/13 12:06:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2900/15833]  lr: 1.9997e-01  eta: 15:40:03  time: 0.1490  data_time: 0.0045  memory: 751  grad_norm: 0.5830  loss: 1.9130  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 1.9130\n",
      "03/13 12:07:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2920/15833]  lr: 1.9997e-01  eta: 15:39:58  time: 0.1487  data_time: 0.0043  memory: 751  grad_norm: 0.5974  loss: 1.7842  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7842\n",
      "03/13 12:07:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2940/15833]  lr: 1.9997e-01  eta: 15:39:55  time: 0.1495  data_time: 0.0045  memory: 751  grad_norm: 0.6501  loss: 2.1282  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.1282\n",
      "03/13 12:07:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2960/15833]  lr: 1.9997e-01  eta: 15:39:57  time: 0.1515  data_time: 0.0055  memory: 751  grad_norm: 0.6088  loss: 1.9426  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 1.9426\n",
      "03/13 12:07:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 2980/15833]  lr: 1.9997e-01  eta: 15:39:55  time: 0.1501  data_time: 0.0048  memory: 751  grad_norm: 0.6418  loss: 2.1923  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 2.1923\n",
      "03/13 12:07:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: ciis_20240313_115942\n",
      "03/13 12:07:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 3000/15833]  lr: 1.9997e-01  eta: 15:39:51  time: 0.1494  data_time: 0.0048  memory: 751  grad_norm: 0.8769  loss: 2.3569  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 2.3569\n",
      "03/13 12:07:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 3020/15833]  lr: 1.9997e-01  eta: 15:39:47  time: 0.1490  data_time: 0.0046  memory: 751  grad_norm: 0.5294  loss: 2.1979  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.1979\n",
      "03/13 12:07:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 3040/15833]  lr: 1.9997e-01  eta: 15:39:40  time: 0.1481  data_time: 0.0042  memory: 751  grad_norm: 0.5431  loss: 2.0743  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 2.0743\n",
      "03/13 12:07:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 3060/15833]  lr: 1.9997e-01  eta: 15:39:35  time: 0.1486  data_time: 0.0043  memory: 751  grad_norm: 0.5260  loss: 2.0644  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.0644\n",
      "03/13 12:07:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 3080/15833]  lr: 1.9997e-01  eta: 15:39:31  time: 0.1493  data_time: 0.0046  memory: 751  grad_norm: 0.5435  loss: 2.0777  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 2.0777\n",
      "03/13 12:07:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 3100/15833]  lr: 1.9997e-01  eta: 15:39:27  time: 0.1489  data_time: 0.0046  memory: 751  grad_norm: 0.4970  loss: 2.1588  top1_acc: 0.7500  top5_acc: 0.7500  loss_cls: 2.1588\n",
      "03/13 12:07:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 3120/15833]  lr: 1.9997e-01  eta: 15:39:25  time: 0.1502  data_time: 0.0061  memory: 751  grad_norm: 0.6014  loss: 2.1714  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.1714\n",
      "03/13 12:07:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 3140/15833]  lr: 1.9997e-01  eta: 15:39:20  time: 0.1486  data_time: 0.0043  memory: 751  grad_norm: 0.5436  loss: 2.0309  top1_acc: 0.0000  top5_acc: 0.7500  loss_cls: 2.0309\n",
      "03/13 12:07:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 3160/15833]  lr: 1.9997e-01  eta: 15:39:15  time: 0.1488  data_time: 0.0043  memory: 751  grad_norm: 0.5754  loss: 2.2753  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 2.2753\n",
      "03/13 12:07:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 3180/15833]  lr: 1.9997e-01  eta: 15:39:11  time: 0.1491  data_time: 0.0044  memory: 751  grad_norm: 0.5434  loss: 1.9513  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 1.9513\n",
      "03/13 12:07:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 3200/15833]  lr: 1.9997e-01  eta: 15:39:07  time: 0.1492  data_time: 0.0045  memory: 751  grad_norm: 0.6756  loss: 2.3600  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 2.3600\n",
      "03/13 12:07:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 3220/15833]  lr: 1.9996e-01  eta: 15:39:03  time: 0.1487  data_time: 0.0044  memory: 751  grad_norm: 0.6088  loss: 1.9746  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 1.9746\n",
      "03/13 12:07:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 3240/15833]  lr: 1.9996e-01  eta: 15:38:58  time: 0.1489  data_time: 0.0043  memory: 751  grad_norm: 0.5504  loss: 1.9377  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 1.9377\n",
      "03/13 12:07:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 3260/15833]  lr: 1.9996e-01  eta: 15:38:55  time: 0.1494  data_time: 0.0044  memory: 751  grad_norm: 0.7460  loss: 2.1824  top1_acc: 0.7500  top5_acc: 0.7500  loss_cls: 2.1824\n",
      "03/13 12:07:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 3280/15833]  lr: 1.9996e-01  eta: 15:38:51  time: 0.1491  data_time: 0.0044  memory: 751  grad_norm: 0.5905  loss: 1.9845  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 1.9845\n",
      "03/13 12:07:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 3300/15833]  lr: 1.9996e-01  eta: 15:38:47  time: 0.1493  data_time: 0.0046  memory: 751  grad_norm: 0.6358  loss: 2.0628  top1_acc: 0.2500  top5_acc: 0.2500  loss_cls: 2.0628\n",
      "03/13 12:08:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 3320/15833]  lr: 1.9996e-01  eta: 15:38:44  time: 0.1495  data_time: 0.0046  memory: 751  grad_norm: 0.6434  loss: 2.1689  top1_acc: 0.7500  top5_acc: 0.7500  loss_cls: 2.1689\n",
      "03/13 12:08:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 3340/15833]  lr: 1.9996e-01  eta: 15:38:40  time: 0.1490  data_time: 0.0043  memory: 751  grad_norm: 0.6302  loss: 2.1258  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.1258\n",
      "03/13 12:08:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 3360/15833]  lr: 1.9996e-01  eta: 15:38:36  time: 0.1490  data_time: 0.0043  memory: 751  grad_norm: 1.9379  loss: 1.9234  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9234\n",
      "03/13 12:08:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 3380/15833]  lr: 1.9996e-01  eta: 15:38:36  time: 0.1511  data_time: 0.0066  memory: 751  grad_norm: 1.0109  loss: 2.2192  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.2192\n",
      "03/13 12:08:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 3400/15833]  lr: 1.9996e-01  eta: 15:38:32  time: 0.1491  data_time: 0.0044  memory: 751  grad_norm: 0.7123  loss: 2.2159  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 2.2159\n",
      "03/13 12:08:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 3420/15833]  lr: 1.9996e-01  eta: 15:38:27  time: 0.1486  data_time: 0.0042  memory: 751  grad_norm: 0.5125  loss: 2.0229  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 2.0229\n",
      "03/13 12:08:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 3440/15833]  lr: 1.9996e-01  eta: 15:38:23  time: 0.1490  data_time: 0.0043  memory: 751  grad_norm: 0.5863  loss: 1.9084  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 1.9084\n",
      "03/13 12:08:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 3460/15833]  lr: 1.9996e-01  eta: 15:38:19  time: 0.1490  data_time: 0.0044  memory: 751  grad_norm: 0.7121  loss: 2.0503  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 2.0503\n",
      "03/13 12:08:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 3480/15833]  lr: 1.9996e-01  eta: 15:38:14  time: 0.1485  data_time: 0.0042  memory: 751  grad_norm: 0.7054  loss: 2.1829  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 2.1829\n",
      "03/13 12:08:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 3500/15833]  lr: 1.9996e-01  eta: 15:38:09  time: 0.1486  data_time: 0.0043  memory: 751  grad_norm: 0.5646  loss: 2.0915  top1_acc: 0.5000  top5_acc: 0.7500  loss_cls: 2.0915\n",
      "03/13 12:08:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 3520/15833]  lr: 1.9996e-01  eta: 15:38:04  time: 0.1488  data_time: 0.0044  memory: 751  grad_norm: 0.6334  loss: 1.9722  top1_acc: 0.2500  top5_acc: 0.7500  loss_cls: 1.9722\n",
      "03/13 12:08:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 3540/15833]  lr: 1.9996e-01  eta: 15:37:59  time: 0.1486  data_time: 0.0043  memory: 751  grad_norm: 0.6941  loss: 1.9536  top1_acc: 0.0000  top5_acc: 0.2500  loss_cls: 1.9536\n",
      "03/13 12:08:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 3560/15833]  lr: 1.9996e-01  eta: 15:37:54  time: 0.1483  data_time: 0.0042  memory: 751  grad_norm: 0.7093  loss: 2.1870  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.1870\n",
      "03/13 12:08:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 3580/15833]  lr: 1.9996e-01  eta: 15:37:49  time: 0.1488  data_time: 0.0043  memory: 751  grad_norm: 0.5516  loss: 2.0740  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 2.0740\n",
      "03/13 12:08:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 3600/15833]  lr: 1.9996e-01  eta: 15:37:46  time: 0.1493  data_time: 0.0047  memory: 751  grad_norm: 0.7276  loss: 2.2037  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.2037\n",
      "03/13 12:08:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 3620/15833]  lr: 1.9996e-01  eta: 15:37:43  time: 0.1496  data_time: 0.0048  memory: 751  grad_norm: 0.6124  loss: 2.0931  top1_acc: 0.0000  top5_acc: 0.7500  loss_cls: 2.0931\n",
      "03/13 12:08:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 3640/15833]  lr: 1.9995e-01  eta: 15:37:40  time: 0.1494  data_time: 0.0046  memory: 751  grad_norm: 0.5241  loss: 2.1497  top1_acc: 0.2500  top5_acc: 0.5000  loss_cls: 2.1497\n"
     ]
    }
   ],
   "source": [
    "!python mmaction2/tools/train.py mmaction2/configs/skeleton/posec3d/ciis.py \\\n",
    "    --work-dir work_dirs/ciis \\\n",
    "    --seed 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6244f32-9406-4f93-b9c6-6cdc7557dccf",
   "metadata": {},
   "source": [
    "## Training from python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
